{
    "directed": false,
    "multigraph": false,
    "graph": {
        "name": "SciVis_graph"
    },
    "nodes": [
        {
            "title": "Fixed-Rate Compressed Floating-Point Arrays",
            "data": "Current compression schemes for floating-point data commonly take fixed-precision values and compress them to a variable-length bit stream, complicating memory management and random access. We present a fixed-rate, near-lossless compression scheme that maps small blocks of 4&lt;sup&gt;d&lt;/sup&gt; values in d dimensions to a fixed, user-specified number of bits per block, thereby allowing read and write random access to compressed floating-point data at block granularity. Our approach is inspired by fixed-rate texture compression methods widely adopted in graphics hardware, but has been tailored to the high dynamic range and precision demands of scientific applications. Our compressor is based on a new, lifted, orthogonal block transform and embedded coding, allowing each per-block bit stream to be truncated at any point if desired, thus facilitating bit rate selection using a single compression scheme. To avoid compression or decompression upon every data access, we employ a software write-back cache of uncompressed blocks. Our compressor has been designed with computational simplicity and speed in mind to allow for the possibility of a hardware implementation, and uses only a small number of fixed-point arithmetic operations per compressed value. We demonstrate the viability and benefits of lossy compression in several applications, including visualization, quantitative data analysis, and numerical simulation.",
            "url": "http://dx.doi.org/10.1109/TVCG.2014.2346458",
            "id": "r_0",
            "s_ids": [
                "s_255"
            ],
            "type": "rich",
            "x": 9.222713470458984,
            "y": 7.890132427215576
        },
        {
            "title": "A Systematic Review on the Practice of Evaluating Visualization",
            "data": "We present an assessment of the state and historic development of evaluation practices as reported in papers published at the IEEE Visualization conference. Our goal is to reflect on a meta-level about evaluation in our community through a systematic understanding of the characteristics and goals of presented evaluations. For this purpose we conducted a systematic review of ten years of evaluations in the published papers using and extending a coding scheme previously established by Lam et al. [2012]. The results of our review include an overview of the most common evaluation goals in the community, how they evolved over time, and how they contrast or align to those of the IEEE Information Visualization conference. In particular, we found that evaluations specific to assessing resulting images and algorithm performance are the most prevalent (with consistently 80-90% of all papers since 1997). However, especially over the last six years there is a steady increase in evaluation methods that include participants, either by evaluating their performances and subjective feedback or by evaluating their work practices and their improved analysis and reasoning capabilities using visual tools. Up to 2010, this trend in the IEEE Visualization conference was much more pronounced than in the IEEE Information Visualization conference which only showed an increasing percentage of evaluation through user performance and experience testing. Since 2011, however, also papers in IEEE Information Visualization show such an increase of evaluations of work practices and analysis as well as reasoning using visual tools. Further, we found that generally the studies reporting requirements analyses and domain-specific work practices are too informally reported which hinders cross-comparison and lowers external validity.",
            "url": "http://dx.doi.org/10.1109/TVCG.2013.126",
            "id": "r_1",
            "s_ids": [
                "s_429",
                "s_269",
                "s_350",
                "s_57",
                "s_636"
            ],
            "type": "rich",
            "x": 11.856539726257324,
            "y": 4.723494052886963
        },
        {
            "title": "Contour Boxplots: A Method for Characterizing Uncertainty in Feature Sets from Simulation Ensembles",
            "data": "Ensembles of numerical simulations are used in a variety of applications, such as meteorology or computational solid mechanics, in order to quantify the uncertainty or possible error in a model or simulation. Deriving robust statistics and visualizing the variability of an ensemble is a challenging task and is usually accomplished through direct visualization of ensemble members or by providing aggregate representations such as an average or pointwise probabilities. In many cases, the interesting quantities in a simulation are not dense fields, but are sets of features that are often represented as thresholds on physical or derived quantities. In this paper, we introduce a generalization of boxplots, called contour boxplots, for visualization and exploration of ensembles of contours or level sets of functions. Conventional boxplots have been widely used as an exploratory or communicative tool for data analysis, and they typically show the median, mean, confidence intervals, and outliers of a population. The proposed contour boxplots are a generalization of functional boxplots, which build on the notion of data depth. Data depth approximates the extent to which a particular sample is centrally located within its density function. This produces a center-outward ordering that gives rise to the statistical quantities that are essential to boxplots. Here we present a generalization of functional data depth to contours and demonstrate methods for displaying the resulting boxplots for two-dimensional simulation data in weather forecasting and computational fluid dynamics.",
            "url": "http://dx.doi.org/10.1109/TVCG.2013.143",
            "id": "r_2",
            "s_ids": [
                "s_341",
                "s_16",
                "s_453"
            ],
            "type": "rich",
            "x": 10.773049354553223,
            "y": 6.690449237823486
        },
        {
            "title": "The Topology ToolKit",
            "data": "This system paper presents the Topology ToolKit (TTK), a software platform designed for the topological analysis of scalar data in scientific visualization. While topological data analysis has gained in popularity over the last two decades, it has not yet been widely adopted as a standard data analysis tool for end users or developers. TTK aims at addressing this problem by providing a unified, generic, efficient, and robust implementation of key algorithms for the topological analysis of scalar data, including: critical points, integral lines, persistence diagrams, persistence curves, merge trees, contour trees, Morse-Smale complexes, fiber surfaces, continuous scatterplots, Jacobi sets, Reeb spaces, and more. TTK is easily accessible to end users due to a tight integration with ParaView. It is also easily accessible to developers through a variety of bindings (Python, VTK/C++) for fast prototyping or through direct, dependency-free, C++, to ease integration into pre-existing complex systems. While developing TTK, we faced several algorithmic and software engineering challenges, which we document in this paper. In particular, we present an algorithm for the construction of a discrete gradient that complies to the critical points extracted in the piecewise-linear setting. This algorithm guarantees a combinatorial consistency across the topological abstractions supported by TTK, and importantly, a unified implementation of topological data simplification for multi-scale exploration and analysis. We also present a cached triangulation data structure, that supports time efficient and generic traversals, which self-adjusts its memory usage on demand for input simplicial meshes and which implicitly emulates a triangulation for regular grids with no memory overhead. Finally, we describe an original software architecture, which guarantees memory efficient and direct accesses to TTK features, while still allowing for researchers powerful and easy bindings and extensions. TTK is open source (BSD license) and its code. online documentation and video tutorials are available on TTK's website [108].",
            "url": "http://dx.doi.org/10.1109/TVCG.2017.2743938",
            "id": "r_3",
            "s_ids": [
                "s_572",
                "s_191",
                "s_577",
                "s_10",
                "s_481"
            ],
            "type": "rich",
            "x": 9.504298210144043,
            "y": 7.175880432128906
        },
        {
            "title": "Curve Boxplot: Generalization of Boxplot for Ensembles of Curves",
            "data": "In simulation science, computational scientists often study the behavior of their simulations by repeated solutions with variations in parameters and/or boundary values or initial conditions. Through such simulation ensembles, one can try to understand or quantify the variability or uncertainty in a solution as a function of the various inputs or model assumptions. In response to a growing interest in simulation ensembles, the visualization community has developed a suite of methods for allowing users to observe and understand the properties of these ensembles in an efficient and effective manner. An important aspect of visualizing simulations is the analysis of derived features, often represented as points, surfaces, or curves. In this paper, we present a novel, nonparametric method for summarizing ensembles of 2D and 3D curves. We propose an extension of a method from descriptive statistics, data depth, to curves. We also demonstrate a set of rendering and visualization strategies for showing rank statistics of an ensemble of curves, which is a generalization of traditional whisker plots or boxplots to multidimensional curves. Results are presented for applications in neuroimaging, hurricane forecasting and fluid dynamics.",
            "url": "http://dx.doi.org/10.1109/TVCG.2014.2346455",
            "id": "r_4",
            "s_ids": [
                "s_16",
                "s_341",
                "s_453"
            ],
            "type": "rich",
            "x": 11.080997467041016,
            "y": 6.284158706665039
        },
        {
            "title": "OSPRay - A CPU Ray Tracing Framework for Scientific Visualization",
            "data": "Scientific data is continually increasing in complexity, variety and size, making efficient visualization and specifically rendering an ongoing challenge. Traditional rasterization-based visualization approaches encounter performance and quality limitations, particularly in HPC environments without dedicated rendering hardware. In this paper, we present OSPRay, a turn-key CPU ray tracing framework oriented towards production-use scientific visualization which can utilize varying SIMD widths and multiple device backends found across diverse HPC resources. This framework provides a high-quality, efficient CPU-based solution for typical visualization workloads, which has already been integrated into several prevalent visualization packages. We show that this system delivers the performance, high-level API simplicity, and modular device support needed to provide a compelling new rendering framework for implementing efficient scientific visualization workflows.",
            "url": "http://dx.doi.org/10.1109/TVCG.2016.2599041",
            "id": "r_5",
            "s_ids": [
                "s_632",
                "s_243",
                "s_597",
                "s_322",
                "s_665",
                "s_528",
                "s_467",
                "s_619"
            ],
            "type": "rich",
            "x": 11.234898567199707,
            "y": 4.302945137023926
        },
        {
            "title": "Streamline Variability Plots for Characterizing the Uncertainty in Vector Field Ensembles",
            "data": "We present a new method to visualize from an ensemble of flow fields the statistical properties of streamlines passing through a selected location. We use principal component analysis to transform the set of streamlines into a low-dimensional Euclidean space. In this space the streamlines are clustered into major trends, and each cluster is in turn approximated by a multivariate Gaussian distribution. This yields a probabilistic mixture model for the streamline distribution, from which confidence regions can be derived in which the streamlines are most likely to reside. This is achieved by transforming the Gaussian random distributions from the low-dimensional Euclidean space into a streamline distribution that follows the statistical model, and by visualizing confidence regions in this distribution via iso-contours. We further make use of the principal component representation to introduce a new concept of streamline-median, based on existing median concepts in multidimensional Euclidean spaces. We demonstrate the potential of our method in a number of real-world examples, and we compare our results to alternative clustering approaches for particle trajectories as well as curve boxplots.",
            "url": "http://dx.doi.org/10.1109/TVCG.2015.2467204",
            "id": "r_6",
            "s_ids": [
                "s_473",
                "s_616",
                "s_102"
            ],
            "type": "rich",
            "x": 7.680285453796387,
            "y": 5.90753698348999
        },
        {
            "title": "StreetVizor: Visual Exploration of Human-Scale Urban Forms Based on Street Views",
            "data": "Urban forms at human-scale, i.e., urban environments that individuals can sense (e.g., sight, smell, and touch) in their daily lives, can provide unprecedented insights on a variety of applications, such as urban planning and environment auditing. The analysis of urban forms can help planners develop high-quality urban spaces through evidence-based design. However, such analysis is complex because of the involvement of spatial, multi-scale (i.e., city, region, and street), and multivariate (e.g., greenery and sky ratios) natures of urban forms. In addition, current methods either lack quantitative measurements or are limited to a small area. The primary contribution of this work is the design of StreetVizor, an interactive visual analytics system that helps planners leverage their domain knowledge in exploring human-scale urban forms based on street view images. Our system presents two-stage visual exploration: 1) an AOI Explorer for the visual comparison of spatial distributions and quantitative measurements in two areas-of-interest (AOIs) at city- and region-scales; 2) and a Street Explorer with a novel parallel coordinate plot for the exploration of the fine-grained details of the urban forms at the street-scale. We integrate visualization techniques with machine learning models to facilitate the detection of street view patterns. We illustrate the applicability of our approach with case studies on the real-world datasets of four cities, i.e., Hong Kong, Singapore, Greater London and New York City. Interviews with domain experts demonstrate the effectiveness of our system in facilitating various analytical tasks.",
            "url": "http://dx.doi.org/10.1109/TVCG.2017.2744159",
            "id": "r_7",
            "s_ids": [
                "s_628",
                "s_518",
                "s_83",
                "s_210",
                "s_258",
                "s_260",
                "s_129"
            ],
            "type": "rich",
            "x": 12.077192306518555,
            "y": 6.150039196014404
        },
        {
            "title": "Urban Pulse: Capturing the Rhythm of Cities",
            "data": "Cities are inherently dynamic. Interesting patterns of behavior typically manifest at several key areas of a city over multiple temporal resolutions. Studying these patterns can greatly help a variety of experts ranging from city planners and architects to human behavioral experts. Recent technological innovations have enabled the collection of enormous amounts of data that can help in these studies. However, techniques using these data sets typically focus on understanding the data in the context of the city, thus failing to capture the dynamic aspects of the city. The goal of this work is to instead understand the city in the context of multiple urban data sets. To do so, we define the concept of an \u201curban pulse\u201d which captures the spatio-temporal activity in a city across multiple temporal resolutions. The prominent pulses in a city are obtained using the topology of the data sets, and are characterized as a set of beats. The beats are then used to analyze and compare different pulses. We also design a visual exploration framework that allows users to explore the pulses within and across multiple cities under different conditions. Finally, we present three case studies carried out by experts from two different domains that demonstrate the utility of our framework.",
            "url": "http://dx.doi.org/10.1109/TVCG.2016.2598585",
            "id": "r_8",
            "s_ids": [
                "s_426",
                "s_27",
                "s_165",
                "s_200",
                "s_603",
                "s_33",
                "s_568",
                "s_344"
            ],
            "type": "rich",
            "x": 12.079547882080078,
            "y": 6.148656845092773
        },
        {
            "title": "Area-Preservation Mapping using Optimal Mass Transport",
            "data": "We present a novel area-preservation mapping/flattening method using the optimal mass transport technique, based on the Monge-Brenier theory. Our optimal transport map approach is rigorous and solid in theory, efficient and parallel in computation, yet general for various applications. By comparison with the conventional Monge-Kantorovich approach, our method reduces the number of variables from O(n&lt;sup&gt;2&lt;/sup&gt;) to O(n), and converts the optimal mass transport problem to a convex optimization problem, which can now be efficiently carried out by Newton's method. Furthermore, our framework includes the area weighting strategy that enables users to completely control and adjust the size of areas everywhere in an accurate and quantitative way. Our method significantly reduces the complexity of the problem, and improves the efficiency, flexibility and scalability during visualization. Our framework, by combining conformal mapping and optimal mass transport mapping, serves as a powerful tool for a broad range of applications in visualization and graphics, especially for medical imaging. We provide a variety of experimental results to demonstrate the efficiency, robustness and efficacy of our novel framework.",
            "url": "http://dx.doi.org/10.1109/TVCG.2013.135",
            "id": "r_9",
            "s_ids": [
                "s_221",
                "s_381",
                "s_285",
                "s_13",
                "s_342",
                "s_281",
                "s_330"
            ],
            "type": "rich",
            "x": 9.550971984863281,
            "y": 6.565341472625732
        },
        {
            "title": "Time-Hierarchical Clustering and Visualization of Weather Forecast Ensembles",
            "data": "We propose a new approach for analyzing the temporal growth of the uncertainty in ensembles of weather forecasts which are started from perturbed but similar initial conditions. As an alternative to traditional approaches in meteorology, which use juxtaposition and animation of spaghetti plots of iso-contours, we make use of contour clustering and provide means to encode forecast dynamics and spread in one single visualization. Based on a given ensemble clustering in a specified time window, we merge clusters in time-reversed order to indicate when and where forecast trajectories start to diverge. We present and compare different visualizations of the resulting time-hierarchical grouping, including space-time surfaces built by connecting cluster representatives over time, and stacked contour variability plots. We demonstrate the effectiveness of our visual encodings with forecast examples of the European Centre for Medium-Range Weather Forecasts, which convey the evolution of specific features in the data as well as the temporally increasing spatial variability.",
            "url": "http://dx.doi.org/10.1109/TVCG.2016.2598868",
            "id": "r_10",
            "s_ids": [
                "s_473",
                "s_93",
                "s_595",
                "s_102"
            ],
            "type": "rich",
            "x": 10.634483337402344,
            "y": 6.0569748878479
        },
        {
            "title": "TelCoVis: Visual Exploration of Co-occurrence in Urban Human Mobility Based on Telco Data",
            "data": "Understanding co-occurrence in urban human mobility (i.e. people from two regions visit an urban place during the same time span) is of great value in a variety of applications, such as urban planning, business intelligence, social behavior analysis, as well as containing contagious diseases. In recent years, the widespread use of mobile phones brings an unprecedented opportunity to capture large-scale and fine-grained data to study co-occurrence in human mobility. However, due to the lack of systematic and efficient methods, it is challenging for analysts to carry out in-depth analyses and extract valuable information. In this paper, we present TelCoVis, an interactive visual analytics system, which helps analysts leverage their domain knowledge to gain insight into the co-occurrence in urban human mobility based on telco data. Our system integrates visualization techniques with new designs and combines them in a novel way to enhance analysts' perception for a comprehensive exploration. In addition, we propose to study the correlations in co-occurrence (i.e. people from multiple regions visit different places during the same time span) by means of biclustering techniques that allow analysts to better explore coordinated relationships among different regions and identify interesting patterns. The case studies based on a real-world dataset and interviews with domain experts have demonstrated the effectiveness of our system in gaining insights into co-occurrence and facilitating various analytical tasks.",
            "url": "http://dx.doi.org/10.1109/TVCG.2015.2467194",
            "id": "r_11",
            "s_ids": [
                "s_223",
                "s_378",
                "s_292",
                "s_227",
                "s_129",
                "s_355",
                "s_672",
                "s_248"
            ],
            "type": "rich",
            "x": 12.0700044631958,
            "y": 6.137913227081299
        },
        {
            "title": "The Good, the Bad, and the Ugly: A Theoretical Framework for the Assessment of Continuous Colormaps",
            "data": "A myriad of design rules for what constitutes a \u201cgood\u201d colormap can be found in the literature. Some common rules include order, uniformity, and high discriminative power. However, the meaning of many of these terms is often ambiguous or open to interpretation. At times, different authors may use the same term to describe different concepts or the same rule is described by varying nomenclature. These ambiguities stand in the way of collaborative work, the design of experiments to assess the characteristics of colormaps, and automated colormap generation. In this paper, we review current and historical guidelines for colormap design. We propose a specified taxonomy and provide unambiguous mathematical definitions for the most common design rules.",
            "url": "http://dx.doi.org/10.1109/TVCG.2017.2743978",
            "id": "r_12",
            "s_ids": [
                "s_24",
                "s_271",
                "s_170",
                "s_333",
                "s_69",
                "s_299"
            ],
            "type": "rich",
            "x": 11.693486213684082,
            "y": 5.291536331176758
        },
        {
            "title": "A Virtual Reality Visualization Tool for Neuron Tracing",
            "data": "Tracing neurons in large-scale microscopy data is crucial to establishing a wiring diagram of the brain, which is needed to understand how neural circuits in the brain process information and generate behavior. Automatic techniques often fail for large and complex datasets, and connectomics researchers may spend weeks or months manually tracing neurons using 2D image stacks. We present a design study of a new virtual reality (VR) system, developed in collaboration with trained neuroanatomists, to trace neurons in microscope scans of the visual cortex of primates. We hypothesize that using consumer-grade VR technology to interact with neurons directly in 3D will help neuroscientists better resolve complex cases and enable them to trace neurons faster and with less physical and mental strain. We discuss both the design process and technical challenges in developing an interactive system to navigate and manipulate terabyte-sized image volumes in VR. Using a number of different datasets, we demonstrate that, compared to widely used commercial software, consumer-grade VR presents a promising alternative for scientists.",
            "url": "http://dx.doi.org/10.1109/TVCG.2017.2744079",
            "id": "r_13",
            "s_ids": [
                "s_576",
                "s_72",
                "s_272",
                "s_392",
                "s_665",
                "s_525",
                "s_486",
                "s_273"
            ],
            "type": "rich",
            "x": 11.220353126525879,
            "y": 3.2113137245178223
        },
        {
            "title": "Interactive Volume Exploration of Petascale Microscopy Data Streams Using a Visualization-Driven Virtual Memory Approach",
            "data": "This paper presents the first volume visualization system that scales to petascale volumes imaged as a continuous stream of high-resolution electron microscopy images. Our architecture scales to dense, anisotropic petascale volumes because it: (1) decouples construction of the 3D multi-resolution representation required for visualization from data acquisition, and (2) decouples sample access time during ray-casting from the size of the multi-resolution hierarchy. Our system is designed around a scalable multi-resolution virtual memory architecture that handles missing data naturally, does not pre-compute any 3D multi-resolution representation such as an octree, and can accept a constant stream of 2D image tiles from the microscopes. A novelty of our system design is that it is visualization-driven: we restrict most computations to the visible volume data. Leveraging the virtual memory architecture, missing data are detected during volume ray-casting as cache misses, which are propagated backwards for on-demand out-of-core processing. 3D blocks of volume data are only constructed from 2D microscope image tiles when they have actually been accessed during ray-casting. We extensively evaluate our system design choices with respect to scalability and performance, compare to previous best-of-breed systems, and illustrate the effectiveness of our system for real microscopy data from neuroscience.",
            "url": "http://dx.doi.org/10.1109/TVCG.2012.240",
            "id": "r_14",
            "s_ids": [
                "s_300",
                "s_557",
                "s_352",
                "s_561"
            ],
            "type": "rich",
            "x": 10.047074317932129,
            "y": 4.448229789733887
        },
        {
            "title": "Characterizing Molecular Interactions in Chemical Systems",
            "data": "Interactions between atoms have a major influence on the chemical properties of molecular systems. While covalent interactions impose the structural integrity of molecules, noncovalent interactions govern more subtle phenomena such as protein folding, bonding or self assembly. The understanding of these types of interactions is necessary for the interpretation of many biological processes and chemical design tasks. While traditionally the electron density is analyzed to interpret the quantum chemistry of a molecular system, noncovalent interactions are characterized by low electron densities and only slight variations of them - challenging their extraction and characterization. Recently, the signed electron density and the reduced gradient, two scalar fields derived from the electron density, have drawn much attention in quantum chemistry since they enable a qualitative visualization of these interactions even in complex molecular systems and experimental measurements. In this work, we present the first combinatorial algorithm for the automated extraction and characterization of covalent and noncovalent interactions in molecular systems. The proposed algorithm is based on a joint topological analysis of the signed electron density and the reduced gradient. Combining the connectivity information of the critical points of these two scalar fields enables to visualize, enumerate, classify and investigate molecular interactions in a robust manner. Experiments on a variety of molecular systems, from simple dimers to proteins or DNA, demonstrate the ability of our technique to robustly extract these interactions and to reveal their structural relations to the atoms and bonds forming the molecules. For simple systems, our analysis corroborates the observations made by the chemists while it provides new visual and quantitative insights on chemical interactions for larger molecular systems.",
            "url": "http://dx.doi.org/10.1109/TVCG.2014.2346403",
            "id": "r_15",
            "s_ids": [
                "s_254",
                "s_178",
                "s_43",
                "s_246",
                "s_572"
            ],
            "type": "rich",
            "x": 12.332874298095703,
            "y": 3.4666783809661865
        },
        {
            "title": "An Information-Aware Framework for Exploring Multivariate Data Sets",
            "data": "Information theory provides a theoretical framework for measuring information content for an observed variable, and has attracted much attention from visualization researchers for its ability to quantify saliency and similarity among variables. In this paper, we present a new approach towards building an exploration framework based on information theory to guide the users through the multivariate data exploration process. In our framework, we compute the total entropy of the multivariate data set and identify the contribution of individual variables to the total entropy. The variables are classified into groups based on a novel graph model where a node represents a variable and the links encode the mutual information shared between the variables. The variables inside the groups are analyzed for their representativeness and an information based importance is assigned. We exploit specific information metrics to analyze the relationship between the variables and use the metrics to choose isocontours of selected variables. For a chosen group of points, parallel coordinates plots (PCP) are used to show the states of the variables and provide an interface for the user to select values of interest. Experiments with different data sets reveal the effectiveness of our proposed framework in depicting the interesting regions of the data sets taking into account the interaction among the variables.",
            "url": "http://dx.doi.org/10.1109/TVCG.2013.133",
            "id": "r_16",
            "s_ids": [
                "s_70",
                "s_521",
                "s_318",
                "s_608"
            ],
            "type": "rich",
            "x": 10.507092475891113,
            "y": 6.890668869018555
        },
        {
            "title": "Multi-Charts for Comparative 3D Ensemble Visualization",
            "data": "A comparative visualization of multiple volume data sets is challenging due to the inherent occlusion effects, yet it is important to effectively reveal uncertainties, correlations and reliable trends in 3D ensemble fields. In this paper we present bidirectional linking of multi-charts and volume visualization as a means to analyze visually 3D scalar ensemble fields at the data level. Multi-charts are an extension of conventional bar and line charts: They linearize the 3D data points along a space-filling curve and draw them as multiple charts in the same plot area. The bar charts encode statistical information on ensemble members, such as histograms and probability densities, and line charts are overlayed to allow comparing members against the ensemble. Alternative linearizations based on histogram similarities or ensemble variation allow clustering of spatial locations depending on data distribution. Multi-charts organize the data at multiple scales to quickly provide overviews and enable users to select regions exhibiting interesting behavior interactively. They are further put into a spatial context by allowing the user to brush or query value intervals and specific distributions, and to simultaneously visualize the corresponding spatial points via volume rendering. By providing a picking mechanism in 3D and instantly highlighting the corresponding data points in the chart, the user can go back and forth between the abstract and the 3D view to focus the analysis.",
            "url": "http://dx.doi.org/10.1109/TVCG.2014.2346448",
            "id": "r_17",
            "s_ids": [
                "s_420",
                "s_23",
                "s_102"
            ],
            "type": "rich",
            "x": 10.631356239318848,
            "y": 6.770925998687744
        },
        {
            "title": "ConnectomeExplorer: Query-Guided Visual Analysis of Large Volumetric Neuroscience Data",
            "data": "This paper presents ConnectomeExplorer, an application for the interactive exploration and query-guided visual analysis of large volumetric electron microscopy (EM) data sets in connectomics research. Our system incorporates a knowledge-based query algebra that supports the interactive specification of dynamically evaluated queries, which enable neuroscientists to pose and answer domain-specific questions in an intuitive manner. Queries are built step by step in a visual query builder, building more complex queries from combinations of simpler queries. Our application is based on a scalable volume visualization framework that scales to multiple volumes of several teravoxels each, enabling the concurrent visualization and querying of the original EM volume, additional segmentation volumes, neuronal connectivity, and additional meta data comprising a variety of neuronal data attributes. We evaluate our application on a data set of roughly one terabyte of EM data and 750 GB of segmentation data, containing over 4,000 segmented structures and 1,000 synapses. We demonstrate typical use-case scenarios of our collaborators in neuroscience, where our system has enabled them to answer specific scientific questions using interactive querying and analysis on the full-size data for the first time.",
            "url": "http://dx.doi.org/10.1109/TVCG.2013.142",
            "id": "r_18",
            "s_ids": [
                "s_557",
                "s_544",
                "s_82",
                "s_274",
                "s_561",
                "s_300"
            ],
            "type": "rich",
            "x": 11.417295455932617,
            "y": 3.267385959625244
        },
        {
            "title": "Comparative Visual Analysis of Lagrangian Transport in CFD Ensembles",
            "data": "Sets of simulation runs based on parameter and model variation, so-called ensembles, are increasingly used to model physical behaviors whose parameter space is too large or complex to be explored automatically. Visualization plays a key role in conveying important properties in ensembles, such as the degree to which members of the ensemble agree or disagree in their behavior. For ensembles of time-varying vector fields, there are numerous challenges for providing an expressive comparative visualization, among which is the requirement to relate the effect of individual flow divergence to joint transport characteristics of the ensemble. Yet, techniques developed for scalar ensembles are of little use in this context, as the notion of transport induced by a vector field cannot be modeled using such tools. We develop a Lagrangian framework for the comparison of flow fields in an ensemble. Our techniques evaluate individual and joint transport variance and introduce a classification space that facilitates incorporation of these properties into a common ensemble visualization. Variances of Lagrangian neighborhoods are computed using pathline integration and Principal Components Analysis. This allows for an inclusion of uncertainty measurements into the visualization and analysis approach. Our results demonstrate the usefulness and expressiveness of the presented method on several practical examples.",
            "url": "http://dx.doi.org/10.1109/TVCG.2013.141",
            "id": "r_19",
            "s_ids": [
                "s_639",
                "s_646",
                "s_220",
                "s_332"
            ],
            "type": "rich",
            "x": 11.122188568115234,
            "y": 6.574613094329834
        },
        {
            "title": "Gaze Stripes: Image-Based Visualization of Eye Tracking Data",
            "data": "We present a new visualization approach for displaying eye tracking data from multiple participants. We aim to show the spatio-temporal data of the gaze points in the context of the underlying image or video stimulus without occlusion. Our technique, denoted as gaze stripes, does not require the explicit definition of areas of interest but directly uses the image data around the gaze points, similar to thumbnails for images. A gaze stripe consists of a sequence of such gaze point images, oriented along a horizontal timeline. By displaying multiple aligned gaze stripes, it is possible to analyze and compare the viewing behavior of the participants over time. Since the analysis is carried out directly on the image data, expensive post-processing or manual annotation are not required. Therefore, not only patterns and outliers in the participants' scanpaths can be detected, but the context of the stimulus is available as well. Furthermore, our approach is especially well suited for dynamic stimuli due to the non-aggregated temporal mapping. Complementary views, i.e., markers, notes, screenshots, histograms, and results from automatic clustering, can be added to the visualization to display analysis results. We illustrate the usefulness of our technique on static and dynamic stimuli. Furthermore, we discuss the limitations and scalability of our approach in comparison to established visualization techniques.",
            "url": "http://dx.doi.org/10.1109/TVCG.2015.2468091",
            "id": "r_20",
            "s_ids": [
                "s_657",
                "s_533",
                "s_55",
                "s_553",
                "s_277",
                "s_130"
            ],
            "type": "rich",
            "x": 10.081083297729492,
            "y": 3.169290065765381
        },
        {
            "title": "Semi-Automatic Vortex Extraction in 4D PC-MRI Cardiac Blood Flow Data using Line Predicates",
            "data": "Cardiovascular diseases (CVD) are the leading cause of death worldwide. Their initiation and evolution depends strongly on the blood flow characteristics. In recent years, advances in 4D PC-MRI acquisition enable reliable and time-resolved 3D flow measuring, which allows a qualitative and quantitative analysis of the patient-specific hemodynamics. Currently, medical researchers investigate the relation between characteristic flow patterns like vortices and different pathologies. The manual extraction and evaluation is tedious and requires expert knowledge. Standardized, (semi-)automatic and reliable techniques are necessary to make the analysis of 4D PC-MRI applicable for the clinical routine. In this work, we present an approach for the extraction of vortex flow in the aorta and pulmonary artery incorporating line predicates. We provide an extensive comparison of existent vortex extraction methods to determine the most suitable vortex criterion for cardiac blood flow and apply our approach to ten datasets with different pathologies like coarctations, Tetralogy of Fallot and aneurysms. For two cases we provide a detailed discussion how our results are capable to complement existent diagnosis information. To ensure real-time feedback for the domain experts we implement our method completely on the GPU.",
            "url": "http://dx.doi.org/10.1109/TVCG.2013.189",
            "id": "r_21",
            "s_ids": [
                "s_325",
                "s_290",
                "s_59",
                "s_653",
                "s_335",
                "s_585"
            ],
            "type": "rich",
            "x": 7.481903553009033,
            "y": 4.430104732513428
        },
        {
            "title": "A Lightweight Tangible 3D Interface for Interactive Visualization of Thin fiber Structures",
            "data": "We present a prop-based, tangible interface for 3D interactive visualization of thin fiber structures. These data are commonly found in current bioimaging datasets, for example second-harmonic generation microscopy of collagen fibers in tissue. Our approach uses commodity visualization technologies such as a depth sensing camera and low-cost 3D display. Unlike most current uses of these emerging technologies in the games and graphics communities, we employ the depth sensing camera to create a fish-tank sterePoscopic virtual reality system at the scientist's desk that supports tracking of small-scale gestures with objects already found in the work space. We apply the new interface to the problem of interactive exploratory visualization of three-dimensional thin fiber data. A critical task for the visual analysis of these data is understanding patterns in fiber orientation throughout a volume.The interface enables a new, fluid style of data exploration and fiber orientation analysis by using props to provide needed passive-haptic feedback, making 3D interactions with these fiber structures more controlled. We also contribute a low-level algorithm for extracting fiber centerlines from volumetric imaging. The system was designed and evaluated with two biophotonic experts who currently use it in their lab. As compared to typical practice within their field, the new visualization system provides a more effective way to examine and understand the 3D bioimaging datasets they collect.",
            "url": "http://dx.doi.org/10.1109/TVCG.2013.121",
            "id": "r_22",
            "s_ids": [
                "s_375",
                "s_418",
                "s_655",
                "s_80",
                "s_421"
            ],
            "type": "rich",
            "x": 9.859582901000977,
            "y": 4.024712085723877
        },
        {
            "title": "Visualization as Seen through its Research Paper Keywords",
            "data": "We present the results of a comprehensive multi-pass analysis of visualization paper keywords supplied by authors for their papers published in the IEEE Visualization conference series (now called IEEE VIS) between 1990-2015. From this analysis we derived a set of visualization topics that we discuss in the context of the current taxonomy that is used to categorize papers and assign reviewers in the IEEE VIS reviewing process. We point out missing and overemphasized topics in the current taxonomy and start a discussion on the importance of establishing common visualization terminology. Our analysis of research topics in visualization can, thus, serve as a starting point to (a) help create a common vocabulary to improve communication among different visualization sub-groups, (b) facilitate the process of understanding differences and commonalities of the various research sub-fields in visualization, (c) provide an understanding of emerging new research trends, (d) facilitate the crucial step of finding the right reviewers for research submissions, and (e) it can eventually lead to a comprehensive taxonomy of visualization research. One additional tangible outcome of our work is an online query tool (http://keyvis.org/) that allows visualization researchers to easily browse the 3952 keywords used for IEEE VIS papers since 1990 to find related work or make informed keyword choices.",
            "url": "http://dx.doi.org/10.1109/TVCG.2016.2598827",
            "id": "r_23",
            "s_ids": [
                "s_269",
                "s_429",
                "s_57",
                "s_350",
                "s_636"
            ],
            "type": "rich",
            "x": 11.792940139770508,
            "y": 4.743659496307373
        },
        {
            "title": "Using Topological Analysis to Support Event-Guided Exploration in Urban Data",
            "data": "The explosion in the volume of data about urban environments has opened up opportunities to inform both policy and administration and thereby help governments improve the lives of their citizens, increase the efficiency of public services, and reduce the environmental harms of development. However, cities are complex systems and exploring the data they generate is challenging. The interaction between the various components in a city creates complex dynamics where interesting facts occur at multiple scales, requiring users to inspect a large number of data slices over time and space. Manual exploration of these slices is ineffective, time consuming, and in many cases impractical. In this paper, we propose a technique that supports event-guided exploration of large, spatio-temporal urban data. We model the data as time-varying scalar functions and use computational topology to automatically identify events in different data slices. To handle a potentially large number of events, we develop an algorithm to group and index them, thus allowing users to interactively explore and query event patterns on the fly. A visual exploration interface helps guide users towards data slices that display interesting events and trends. We demonstrate the effectiveness of our technique on two different data sets from New York City (NYC): data about taxi trips and subway service. We also report on the feedback we received from analysts at different NYC agencies.",
            "url": "http://dx.doi.org/10.1109/TVCG.2014.2346449",
            "id": "r_24",
            "s_ids": [
                "s_27",
                "s_600",
                "s_104",
                "s_592",
                "s_344"
            ],
            "type": "rich",
            "x": 12.044306755065918,
            "y": 6.121316909790039
        },
        {
            "title": "Isosurface Visualization of Data with Nonparametric Models for Uncertainty",
            "data": "The problem of isosurface extraction in uncertain data is an important research problem and may be approached in two ways. One can extract statistics (e.g., mean) from uncertain data points and visualize the extracted field. Alternatively, data uncertainty, characterized by probability distributions, can be propagated through the isosurface extraction process. We analyze the impact of data uncertainty on topology and geometry extraction algorithms. A novel, edge-crossing probability based approach is proposed to predict underlying isosurface topology for uncertain data. We derive a probabilistic version of the midpoint decider that resolves ambiguities that arise in identifying topological configurations. Moreover, the probability density function characterizing positional uncertainty in isosurfaces is derived analytically for a broad class of nonparametric distributions. This analytic characterization can be used for efficient closed-form computation of the expected value and variation in geometry. Our experiments show the computational advantages of our analytic approach over Monte-Carlo sampling for characterizing positional uncertainty. We also show the advantage of modeling underlying error densities in a nonparametric statistical framework as opposed to a parametric statistical framework through our experiments on ensemble datasets and uncertain scalar fields.",
            "url": "http://dx.doi.org/10.1109/TVCG.2015.2467958",
            "id": "r_25",
            "s_ids": [
                "s_669",
                "s_89",
                "s_152"
            ],
            "type": "rich",
            "x": 10.997556686401367,
            "y": 7.676204204559326
        },
        {
            "title": "In Situ Eddy Analysis in a High-Resolution Ocean Climate Model",
            "data": "An eddy is a feature associated with a rotating body of fluid, surrounded by a ring of shearing fluid. In the ocean, eddies are 10 to 150 km in diameter, are spawned by boundary currents and baroclinic instabilities, may live for hundreds of days, and travel for hundreds of kilometers. Eddies are important in climate studies because they transport heat, salt, and nutrients through the world's oceans and are vessels of biological productivity. The study of eddies in global ocean-climate models requires large-scale, high-resolution simulations. This poses a problem for feasible (timely) eddy analysis, as ocean simulations generate massive amounts of data, causing a bottleneck for traditional analysis workflows. To enable eddy studies, we have developed an in situ workflow for the quantitative and qualitative analysis of MPAS-Ocean, a high-resolution ocean climate model, in collaboration with the ocean model research and development process. Planned eddy analysis at high spatial and temporal resolutions will not be possible with a postprocessing workflow due to various constraints, such as storage size and I/O time, but the in situ workflow enables it and scales well to ten-thousand processing elements.",
            "url": "http://dx.doi.org/10.1109/TVCG.2015.2467411",
            "id": "r_26",
            "s_ids": [
                "s_608",
                "s_236",
                "s_510",
                "s_374",
                "s_299",
                "s_365"
            ],
            "type": "rich",
            "x": 10.49360179901123,
            "y": 5.669396877288818
        },
        {
            "title": "Design by Dragging: An Interface for Creative Forward and Inverse Design with Simulation Ensembles",
            "data": "We present an interface for exploring large design spaces as encountered in simulation-based engineering, design of visual effects, and other tasks that require tuning parameters of computationally-intensive simulations and visually evaluating results. The goal is to enable a style of design with simulations that feels as-direct-as-possible so users can concentrate on creative design tasks. The approach integrates forward design via direct manipulation of simulation inputs (e.g., geometric properties, applied forces) in the same visual space with inverse design via 'tugging' and reshaping simulation outputs (e.g., scalar fields from finite element analysis (FEA) or computational fluid dynamics (CFD)). The interface includes algorithms for interpreting the intent of users' drag operations relative to parameterized models, morphing arbitrary scalar fields output from FEA and CFD simulations, and in-place interactive ensemble visualization. The inverse design strategy can be extended to use multi-touch input in combination with an as-rigid-as-possible shape manipulation to support rich visual queries. The potential of this new design approach is confirmed via two applications: medical device engineering of a vacuum-assisted biopsy device and visual effects design using a physically based flame simulation.",
            "url": "http://dx.doi.org/10.1109/TVCG.2013.147",
            "id": "r_27",
            "s_ids": [
                "s_415",
                "s_437",
                "s_487",
                "s_421"
            ],
            "type": "rich",
            "x": 11.206650733947754,
            "y": 5.000423908233643
        },
        {
            "title": "Efficient Structure-Aware Selection Techniques for 3D Point Cloud Visualizations with 2DOF Input",
            "data": "Data selection is a fundamental task in visualization because it serves as a pre-requisite to many follow-up interactions. Efficient spatial selection in 3D point cloud datasets consisting of thousands or millions of particles can be particularly challenging. We present two new techniques, TeddySelection and CloudLasso, that support the selection of subsets in large particle 3D datasets in an interactive and visually intuitive manner. Specifically, we describe how to spatially select a subset of a 3D particle cloud by simply encircling the target particles on screen using either the mouse or direct-touch input. Based on the drawn lasso, our techniques automatically determine a bounding selection surface around the encircled particles based on their density. This kind of selection technique can be applied to particle datasets in several application domains. TeddySelection and CloudLasso reduce, and in some cases even eliminate, the need for complex multi-step selection processes involving Boolean operations. This was confirmed in a formal, controlled user study in which we compared the more flexible CloudLasso technique to the standard cylinder-based selection technique. This study showed that the former is consistently more efficient than the latter - in several cases the CloudLasso selection time was half that of the corresponding cylinder-based selection.",
            "url": "http://dx.doi.org/10.1109/TVCG.2012.217",
            "id": "r_28",
            "s_ids": [
                "s_387",
                "s_324",
                "s_269",
                "s_429"
            ],
            "type": "rich",
            "x": 11.422698020935059,
            "y": 5.57735013961792
        },
        {
            "title": "Hybrid Tactile/Tangible Interaction for 3D Data Exploration",
            "data": "We present the design and evaluation of an interface that combines tactile and tangible paradigms for 3D visualization. While studies have demonstrated that both tactile and tangible input can be efficient for a subset of 3D manipulation tasks, we reflect here on the possibility to combine the two complementary input types. Based on a field study and follow-up interviews, we present a conceptual framework of the use of these different interaction modalities for visualization both separately and combined-focusing on free exploration as well as precise control. We present a prototypical application of a subset of these combined mappings for fluid dynamics data visualization using a portable, position-aware device which offers both tactile input and tangible sensing. We evaluate our approach with domain experts and report on their qualitative feedback.",
            "url": "http://dx.doi.org/10.1109/TVCG.2016.2599217",
            "id": "r_29",
            "s_ids": [
                "s_52",
                "s_609",
                "s_506",
                "s_429"
            ],
            "type": "rich",
            "x": 11.156147956848145,
            "y": 4.571768760681152
        },
        {
            "title": "In Situ Distribution Guided Analysis and Visualization of Transonic Jet Engine Simulations",
            "data": "Study of flow instability in turbine engine compressors is crucial to understand the inception and evolution of engine stall. Aerodynamics experts have been working on detecting the early signs of stall in order to devise novel stall suppression technologies. A state-of-the-art Navier-Stokes based, time-accurate computational fluid dynamics simulator, TURBO, has been developed in NASA to enhance the understanding of flow phenomena undergoing rotating stall. Despite the proven high modeling accuracy of TURBO, the excessive simulation data prohibits post-hoc analysis in both storage and I/O time. To address these issues and allow the expert to perform scalable stall analysis, we have designed an in situ distribution guided stall analysis technique. Our method summarizes statistics of important properties of the simulation data in situ using a probabilistic data modeling scheme. This data summarization enables statistical anomaly detection for flow instability in post analysis, which reveals the spatiotemporal trends of rotating stall for the expert to conceive new hypotheses. Furthermore, the verification of the hypotheses and exploratory visualization using the summarized data are realized using probabilistic visualization techniques such as uncertain isocontouring. Positive feedback from the domain scientist has indicated the efficacy of our system in exploratory stall analysis.",
            "url": "http://dx.doi.org/10.1109/TVCG.2016.2598604",
            "id": "r_30",
            "s_ids": [
                "s_521",
                "s_529",
                "s_606",
                "s_318",
                "s_345"
            ],
            "type": "rich",
            "x": 8.676315307617188,
            "y": 5.144198894500732
        },
        {
            "title": "On the Interpolation of Data with Normally Distributed Uncertainty for Visualization",
            "data": "In many fields of science or engineering, we are confronted with uncertain data. For that reason, the visualization of uncertainty received a lot of attention, especially in recent years. In the majority of cases, Gaussian distributions are used to describe uncertain behavior, because they are able to model many phenomena encountered in science. Therefore, in most applications uncertain data is (or is assumed to be) Gaussian distributed. If such uncertain data is given on fixed positions, the question of interpolation arises for many visualization approaches. In this paper, we analyze the effects of the usual linear interpolation schemes for visualization of Gaussian distributed data. In addition, we demonstrate that methods known in geostatistics and machine learning have favorable properties for visualization purposes in this case.",
            "url": "http://dx.doi.org/10.1109/TVCG.2012.249",
            "id": "r_31",
            "s_ids": [
                "s_208",
                "s_472",
                "s_116"
            ],
            "type": "rich",
            "x": 11.016633987426758,
            "y": 7.623682022094727
        },
        {
            "title": "CAST: Effective and Efficient User Interaction for Context-Aware Selection in 3D Particle Clouds",
            "data": "We present a family of three interactive Context-Aware Selection Techniques (CAST) for the analysis of large 3D particle datasets. For these datasets, spatial selection is an essential prerequisite to many other analysis tasks. Traditionally, such interactive target selection has been particularly challenging when the data subsets of interest were implicitly defined in the form of complicated structures of thousands of particles. Our new techniques SpaceCast, TraceCast, and PointCast improve usability and speed of spatial selection in point clouds through novel context-aware algorithms. They are able to infer a user's subtle selection intention from gestural input, can deal with complex situations such as partially occluded point clusters or multiple cluster layers, and can all be fine-tuned after the selection interaction has been completed. Together, they provide an effective and efficient tool set for the fast exploratory analysis of large datasets. In addition to presenting Cast, we report on a formal user study that compares our new techniques not only to each other but also to existing state-of-the-art selection methods. Our results show that Cast family members are virtually always faster than existing methods without tradeoffs in accuracy. In addition, qualitative feedback shows that PointCast and TraceCast were strongly favored by our participants for intuitiveness and efficiency.",
            "url": "http://dx.doi.org/10.1109/TVCG.2015.2467202",
            "id": "r_32",
            "s_ids": [
                "s_387",
                "s_324",
                "s_269",
                "s_429"
            ],
            "type": "rich",
            "x": 11.48548698425293,
            "y": 5.614589214324951
        },
        {
            "title": "Coupled Ensemble Flow Line Advection and Analysis",
            "data": "Ensemble run simulations are becoming increasingly widespread. In this work, we couple particle advection with pathline analysis to visualize and reveal the differences among the flow fields of ensemble runs. Our method first constructs a variation field using a Lagrangian-based distance metric. The variation field characterizes the variation between vector fields of the ensemble runs, by extracting and visualizing the variation of pathlines within ensemble. Parallelism in a MapReduce style is leveraged to handle data processing and computing at scale. Using our prototype system, we demonstrate how scientists can effectively explore and investigate differences within ensemble simulations.",
            "url": "http://dx.doi.org/10.1109/TVCG.2013.144",
            "id": "r_33",
            "s_ids": [
                "s_136",
                "s_434",
                "s_364",
                "s_228"
            ],
            "type": "rich",
            "x": 11.174348831176758,
            "y": 6.667314052581787
        },
        {
            "title": "An Adaptive Prediction-Based Approach to Lossless Compression of Floating-Point Volume Data",
            "data": "In this work, we address the problem of lossless compression of scientific and medical floating-point volume data. We propose two prediction-based compression methods that share a common framework, which consists of a switched prediction scheme wherein the best predictor out of a preset group of linear predictors is selected. Such a scheme is able to adapt to different datasets as well as to varying statistics within the data. The first method, called APE (Adaptive Polynomial Encoder), uses a family of structured interpolating polynomials for prediction, while the second method, which we refer to as ACE (Adaptive Combined Encoder), combines predictors from previous work with the polynomial predictors to yield a more flexible, powerful encoder that is able to effectively decorrelate a wide range of data. In addition, in order to facilitate efficient visualization of compressed data, our scheme provides an option to partition floating-point values in such a way as to provide a progressive representation. We compare our two compressors to existing state-of-the-art lossless floating-point compressors for scientific data, with our data suite including both computer simulations and observational measurements. The results demonstrate that our polynomial predictor, APE, is comparable to previous approaches in terms of speed but achieves better compression rates on average. ACE, our combined predictor, while somewhat slower, is able to achieve the best compression rate on all datasets, with significantly better rates on most of the datasets.",
            "url": "http://dx.doi.org/10.1109/TVCG.2012.194",
            "id": "r_34",
            "s_ids": [
                "s_28",
                "s_647"
            ],
            "type": "rich",
            "x": 9.263254165649414,
            "y": 7.909811019897461
        },
        {
            "title": "Clique Community Persistence: A Topological Visual Analysis Approach for Complex Networks",
            "data": "Complex networks require effective tools and visualizations for their analysis and comparison. Clique communities have been recognized as a powerful concept for describing cohesive structures in networks. We propose an approach that extends the computation of clique communities by considering persistent homology, a topological paradigm originally introduced to characterize and compare the global structure of shapes. Our persistence-based algorithm is able to detect clique communities and to keep track of their evolution according to different edge weight thresholds. We use this information to define comparison metrics and a new centrality measure, both reflecting the relevance of the clique communities inherent to the network. Moreover, we propose an interactive visualization tool based on nested graphs that is capable of compactly representing the evolving relationships between communities for different thresholds and clique degrees. We demonstrate the effectiveness of our approach on various network types.",
            "url": "http://dx.doi.org/10.1109/TVCG.2017.2744321",
            "id": "r_35",
            "s_ids": [
                "s_47",
                "s_573",
                "s_30",
                "s_35"
            ],
            "type": "rich",
            "x": 10.213842391967773,
            "y": 7.132859230041504
        },
        {
            "title": "Abstractocyte: A Visual Tool for Exploring Nanoscale Astroglial Cells",
            "data": "This paper presents Abstractocyte, a system for the visual analysis of astrocytes and their relation to neurons, in nanoscale volumes of brain tissue. Astrocytes are glial cells, i.e., non-neuronal cells that support neurons and the nervous system. The study of astrocytes has immense potential for understanding brain function. However, their complex and widely-branching structure requires high-resolution electron microscopy imaging and makes visualization and analysis challenging. Furthermore, the structure and function of astrocytes is very different from neurons, and therefore requires the development of new visualization and analysis tools. With Abstractocyte, biologists can explore the morphology of astrocytes using various visual abstraction levels, while simultaneously analyzing neighboring neurons and their connectivity. We define a novel, conceptual 2D abstraction space for jointly visualizing astrocytes and neurons. Neuroscientists can choose a specific joint visualization as a point in this space. Interactively moving this point allows them to smoothly transition between different abstraction levels in an intuitive manner. In contrast to simply switching between different visualizations, this preserves the visual context and correlations throughout the transition. Users can smoothly navigate from concrete, highly-detailed 3D views to simplified and abstracted 2D views. In addition to investigating astrocytes, neurons, and their relationships, we enable the interactive analysis of the distribution of glycogen, which is of high importance to neuroscientists. We describe the design of Abstractocyte, and present three case studies in which neuroscientists have successfully used our system to assess astrocytic coverage of synapses, glycogen distribution in relation to synapses, and astrocytic-mitochondria coverage.",
            "url": "http://dx.doi.org/10.1109/TVCG.2017.2744278",
            "id": "r_36",
            "s_ids": [
                "s_88",
                "s_544",
                "s_557",
                "s_622",
                "s_327",
                "s_561",
                "s_300"
            ],
            "type": "rich",
            "x": 11.295099258422852,
            "y": 3.2402255535125732
        },
        {
            "title": "Design and Evaluation of Interactive Proofreading Tools for Connectomics",
            "data": "Proofreading refers to the manual correction of automatic segmentations of image data. In connectomics, electron microscopy data is acquired at nanometer-scale resolution and results in very large image volumes of brain tissue that require fully automatic segmentation algorithms to identify cell boundaries. However, these algorithms require hundreds of corrections per cubic micron of tissue. Even though this task is time consuming, it is fairly easy for humans to perform corrections through splitting, merging, and adjusting segments during proofreading. In this paper we present the design and implementation of Mojo, a fully-featured single-user desktop application for proofreading, and Dojo, a multi-user web-based application for collaborative proofreading. We evaluate the accuracy and speed of Mojo, Dojo, and Raveler, a proofreading tool from Janelia Farm, through a quantitative user study. We designed a between-subjects experiment and asked non-experts to proofread neurons in a publicly available connectomics dataset. Our results show a significant improvement of corrections using web-based Dojo, when given the same amount of time. In addition, all participants using Dojo reported better usability. We discuss our findings and provide an analysis of requirements for designing visual proofreading software.",
            "url": "http://dx.doi.org/10.1109/TVCG.2014.2346371",
            "id": "r_37",
            "s_ids": [
                "s_390",
                "s_394",
                "s_461",
                "s_557",
                "s_82",
                "s_274",
                "s_561"
            ],
            "type": "rich",
            "x": 11.515854835510254,
            "y": 3.2373809814453125
        },
        {
            "title": "Computing Morse-Smale Complexes with Accurate Geometry",
            "data": "Topological techniques have proven highly successful in analyzing and visualizing scientific data. As a result, significant efforts have been made to compute structures like the Morse-Smale complex as robustly and efficiently as possible. However, the resulting algorithms, while topologically consistent, often produce incorrect connectivity as well as poor geometry. These problems may compromise or even invalidate any subsequent analysis. Moreover, such techniques may fail to improve even when the resolution of the domain mesh is increased, thus producing potentially incorrect results even for highly resolved functions. To address these problems we introduce two new algorithms: (i) a randomized algorithm to compute the discrete gradient of a scalar field that converges under refinement; and (ii) a deterministic variant which directly computes accurate geometry and thus correct connectivity of the MS complex. The first algorithm converges in the sense that on average it produces the correct result and its standard deviation approaches zero with increasing mesh resolution. The second algorithm uses two ordered traversals of the function to integrate the probabilities of the first to extract correct (near optimal) geometry and connectivity. We present an extensive empirical study using both synthetic and real-world data and demonstrates the advantages of our algorithms in comparison with several popular approaches.",
            "url": "http://dx.doi.org/10.1109/TVCG.2012.209",
            "id": "r_38",
            "s_ids": [
                "s_660",
                "s_392",
                "s_273"
            ],
            "type": "rich",
            "x": 8.9357271194458,
            "y": 6.956623554229736
        },
        {
            "title": "Uncertainty Quantification in Linear Interpolation for Isosurface Extraction",
            "data": "We present a study of linear interpolation when applied to uncertain data. Linear interpolation is a key step for isosurface extraction algorithms, and the uncertainties in the data lead to non-linear variations in the geometry of the extracted isosurface. We present an approach for deriving the probability density function of a random variable modeling the positional uncertainty in the isosurface extraction. When the uncertainty is quantified by a uniform distribution, our approach provides a closed-form characterization of the mentioned random variable. This allows us to derive, in closed form, the expected value as well as the variance of the level-crossing position. While the former quantity is used for constructing a stable isosurface for uncertain data, the latter is used for visualizing the positional uncertainties in the expected isosurface level crossings on the underlying grid.",
            "url": "http://dx.doi.org/10.1109/TVCG.2013.208",
            "id": "r_39",
            "s_ids": [
                "s_669",
                "s_152"
            ],
            "type": "rich",
            "x": 10.995327949523926,
            "y": 7.664634704589844
        },
        {
            "title": "Generalized Topological Simplification of Scalar fields on Surfaces",
            "data": "We present a combinatorial algorithm for the general topological simplification of scalar fields on surfaces. Given a scalar field f, our algorithm generates a simplified field g that provably admits only critical points from a constrained subset of the singularities of f, while guaranteeing a small distance ||f - g||<sub>\u221e</sub>for data-fitting purpose. In contrast to previous algorithms, our approach is oblivious to the strategy used for selecting features of interest and allows critical points to be removed arbitrarily. When topological persistence is used to select the features of interest, our algorithm produces a standard \u03f5-simplification. Our approach is based on a new iterative algorithm for the constrained reconstruction of sub- and sur-level sets. Extensive experiments show that the number of iterations required for our algorithm to converge is rarely greater than 2 and never greater than 5, yielding O(n log(n)) practical time performances. The algorithm handles triangulated surfaces with or without boundary and is robust to the presence of multi-saddles in the input. It is simple to implement, fast in practice and more general than previous techniques. Practically, our approach allows a user to arbitrarily simplify the topology of an input function and robustly generate the corresponding simplified function. An appealing application area of our algorithm is in scalar field design since it enables, without any threshold parameter, the robust pruning of topological noise as selected by the user. This is needed for example to get rid of inaccuracies introduced by numerical solvers, thereby providing topological guarantees needed for certified geometry processing. Experiments show this ability to eliminate numerical noise as well as validate the time efficiency and accuracy of our algorithm. We provide a lightweight C++ implementation as supplemental material that can be used for topological cleaning on surface meshes.",
            "url": "http://dx.doi.org/10.1109/TVCG.2012.228",
            "id": "r_40",
            "s_ids": [
                "s_572",
                "s_273"
            ],
            "type": "rich",
            "x": 8.985969543457031,
            "y": 7.067393779754639
        },
        {
            "title": "Activity-Centered Domain Characterization for Problem-Driven Scientific Visualization",
            "data": "Although visualization design models exist in the literature in the form of higher-level methodological frameworks, these models do not present a clear methodological prescription for the domain characterization step. This work presents a framework and end-to-end model for requirements engineering in problem-driven visualization application design. The framework and model are based on the activity-centered design paradigm, which is an enhancement of human-centered design. The proposed activity-centered approach focuses on user tasks and activities, and allows an explicit link between the requirements engineering process with the abstraction stage - and its evaluation - of existing, higher-level visualization design models. In a departure from existing visualization design models, the resulting model: assigns value to a visualization based on user activities; ranks user tasks before the user data; partitions requirements in activity-related capabilities and nonfunctional characteristics and constraints; and explicitly incorporates the user workflows into the requirements process. A further merit of this model is its explicit integration of functional specifications, a concept this work adapts from the software engineering literature, into the visualization design nested model. A quantitative evaluation using two sets of interdisciplinary projects supports the merits of the activity-centered model. The result is a practical roadmap to the domain characterization step of visualization design for problem-driven data visualization. Following this domain characterization model can help remove a number of pitfalls that have been identified multiple times in the visualization design literature.",
            "url": "http://dx.doi.org/10.1109/TVCG.2017.2744459",
            "id": "r_41",
            "s_ids": [
                "s_410"
            ],
            "type": "rich",
            "x": 11.503060340881348,
            "y": 5.031372547149658
        },
        {
            "title": "Augmented Topological Descriptors of Pore Networks for Material Science",
            "data": "One potential solution to reduce the concentration of carbon dioxide in the atmosphere is the geologic storage of captured CO&lt;sub&gt;2&lt;/sub&gt; in underground rock formations, also known as carbon sequestration. There is ongoing research to guarantee that this process is both efficient and safe. We describe tools that provide measurements of media porosity, and permeability estimates, including visualization of pore structures. Existing standard algorithms make limited use of geometric information in calculating permeability of complex microstructures. This quantity is important for the analysis of biomineralization, a subsurface process that can affect physical properties of porous media. This paper introduces geometric and topological descriptors that enhance the estimation of material permeability. Our analysis framework includes the processing of experimental data, segmentation, and feature extraction and making novel use of multiscale topological analysis to quantify maximum flow through porous networks. We illustrate our results using synchrotron-based X-ray computed microtomography of glass beads during biomineralization. We also benchmark the proposed algorithms using simulated data sets modeling jammed packed bead beds of a monodispersive material.",
            "url": "http://dx.doi.org/10.1109/TVCG.2012.200",
            "id": "r_42",
            "s_ids": [
                "s_571",
                "s_161",
                "s_190",
                "s_62",
                "s_537",
                "s_237"
            ],
            "type": "rich",
            "x": 9.268465042114258,
            "y": 5.183141231536865
        },
        {
            "title": "SparseLeap: Efficient Empty Space Skipping for Large-Scale Volume Rendering",
            "data": "Recent advances in data acquisition produce volume data of very high resolution and large size, such as terabyte-sized microscopy volumes. These data often contain many fine and intricate structures, which pose huge challenges for volume rendering, and make it particularly important to efficiently skip empty space. This paper addresses two major challenges: (1) The complexity of large volumes containing fine structures often leads to highly fragmented space subdivisions that make empty regions hard to skip efficiently. (2) The classification of space into empty and non-empty regions changes frequently, because the user or the evaluation of an interactive query activate a different set of objects, which makes it unfeasible to pre-compute a well-adapted space subdivision. We describe the novel SparseLeap method for efficient empty space skipping in very large volumes, even around fine structures. The main performance characteristic of SparseLeap is that it moves the major cost of empty space skipping out of the ray-casting stage. We achieve this via a hybrid strategy that balances the computational load between determining empty ray segments in a rasterization (object-order) stage, and sampling non-empty volume data in the ray-casting (image-order) stage. Before ray-casting, we exploit the fast hardware rasterization of GPUs to create a ray segment list for each pixel, which identifies non-empty regions along the ray. The ray-casting stage then leaps over empty space without hierarchy traversal. Ray segment lists are created by rasterizing a set of fine-grained, view-independent bounding boxes. Frame coherence is exploited by re-using the same bounding boxes unless the set of active objects changes. We show that SparseLeap scales better to large, sparse data than standard octree empty space skipping.",
            "url": "http://dx.doi.org/10.1109/TVCG.2017.2744238",
            "id": "r_43",
            "s_ids": [
                "s_300",
                "s_544",
                "s_557",
                "s_578",
                "s_561"
            ],
            "type": "rich",
            "x": 9.277585983276367,
            "y": 7.573193073272705
        },
        {
            "title": "Glyph-Based Comparative Visualization for Diffusion Tensor Fields",
            "data": "Diffusion Tensor Imaging (DTI) is a magnetic resonance imaging modality that enables the in-vivo reconstruction and visualization of fibrous structures. To inspect the local and individual diffusion tensors, glyph-based visualizations are commonly used since they are able to effectively convey full aspects of the diffusion tensor. For several applications it is necessary to compare tensor fields, e.g., to study the effects of acquisition parameters, or to investigate the influence of pathologies on white matter structures. This comparison is commonly done by extracting scalar information out of the tensor fields and then comparing these scalar fields, which leads to a loss of information. If the glyph representation is kept, simple juxtaposition or superposition can be used. However, neither facilitates the identification and interpretation of the differences between the tensor fields. Inspired by the checkerboard style visualization and the superquadric tensor glyph, we design a new glyph to locally visualize differences between two diffusion tensors by combining juxtaposition and explicit encoding. Because tensor scale, anisotropy type, and orientation are related to anatomical information relevant for DTI applications, we focus on visualizing tensor differences in these three aspects. As demonstrated in a user study, our new glyph design allows users to efficiently and effectively identify the tensor differences. We also apply our new glyphs to investigate the differences between DTI datasets of the human brain in two different contexts using different b-values, and to compare datasets from a healthy and HIV-infected subject.",
            "url": "http://dx.doi.org/10.1109/TVCG.2015.2467435",
            "id": "r_44",
            "s_ids": [
                "s_610",
                "s_558",
                "s_658",
                "s_134",
                "s_372"
            ],
            "type": "rich",
            "x": 8.500031471252441,
            "y": 6.283479690551758
        },
        {
            "title": "Association Analysis for Visual Exploration of Multivariate Scientific Data Sets",
            "data": "The heterogeneity and complexity of multivariate characteristics poses a unique challenge to visual exploration of multivariate scientific data sets, as it requires investigating the usually hidden associations between different variables and specific scalar values to understand the data's multi-faceted properties. In this paper, we present a novel association analysis method that guides visual exploration of scalar-level associations in the multivariate context. We model the directional interactions between scalars of different variables as information flows based on association rules. We introduce the concepts of informativeness and uniqueness to describe how information flows between scalars of different variables and how they are associated with each other in the multivariate domain. Based on scalar-level associations represented by a probabilistic association graph, we propose the Multi-Scalar Informativeness-Uniqueness (MSIU) algorithm to evaluate the informativeness and uniqueness of scalars. We present an exploration framework with multiple interactive views to explore the scalars of interest with confident associations in the multivariate spatial domain, and provide guidelines for visual exploration using our framework. We demonstrate the effectiveness and usefulness of our approach through case studies using three representative multivariate scientific data sets.",
            "url": "http://dx.doi.org/10.1109/TVCG.2015.2467431",
            "id": "r_45",
            "s_ids": [
                "s_422",
                "s_318"
            ],
            "type": "rich",
            "x": 10.496941566467285,
            "y": 6.88934326171875
        },
        {
            "title": "Efficient Local Statistical Analysis via Integral Histograms with Discrete Wavelet Transform",
            "data": "Histograms computed from local regions are commonly used in many visualization applications, and allowing the user to query histograms interactively in regions of arbitrary locations and sizes plays an important role in feature identification and tracking. Computing histograms in regions with arbitrary location and size, nevertheless, can be time consuming for large data sets since it involves expensive I/O and scan of data elements. To achieve both performance- and storage-efficient query of local histograms, we present a new algorithm called WaveletSAT, which utilizes integral histograms, an extension of the summed area tables (SAT), and discrete wavelet transform (DWT). Similar to SAT, an integral histogram is the histogram computed from the area between each grid point and the grid origin, which can be be pre-computed to support fast query. Nevertheless, because one histogram contains multiple bins, it will be very expensive to store one integral histogram at each grid point. To reduce the storage cost for large integral histograms, WaveletSAT treats the integral histograms of all grid points as multiple SATs, each of which can be converted into a sparse representation via DWT, allowing the reconstruction of axis-aligned region histograms of arbitrary sizes from a limited number of wavelet coefficients. Besides, we present an efficient wavelet transform algorithm for SATs that can operate on each grid point separately in logarithmic time complexity, which can be extended to parallel GPU-based implementation. With theoretical and empirical demonstration, we show that WaveletSAT can achieve fast preprocessing and smaller storage overhead than the conventional integral histogram approach with close query performance.",
            "url": "http://dx.doi.org/10.1109/TVCG.2013.152",
            "id": "r_46",
            "s_ids": [
                "s_252",
                "s_318"
            ],
            "type": "rich",
            "x": 9.650074005126953,
            "y": 7.513702869415283
        },
        {
            "title": "Multivariate Data Analysis Using Persistence-Based filtering and Topological Signatures",
            "data": "The extraction of significant structures in arbitrary high-dimensional data sets is a challenging task. Moreover, classifying data points as noise in order to reduce a data set bears special relevance for many application domains. Standard methods such as clustering serve to reduce problem complexity by providing the user with classes of similar entities. However, they usually do not highlight relations between different entities and require a stopping criterion, e.g. the number of clusters to be detected. In this paper, we present a visualization pipeline based on recent advancements in algebraic topology. More precisely, we employ methods from persistent homology that enable topological data analysis on high-dimensional data sets. Our pipeline inherently copes with noisy data and data sets of arbitrary dimensions. It extracts central structures of a data set in a hierarchical manner by using a persistence-based filtering algorithm that is theoretically well-founded. We furthermore introduce persistence rings, a novel visualization technique for a class of topological features-the persistence intervals-of large data sets. Persistence rings provide a unique topological signature of a data set, which helps in recognizing similarities. In addition, we provide interactive visualization techniques that assist the user in evaluating the parameter space of our method in order to extract relevant structures. We describe and evaluate our analysis pipeline by means of two very distinct classes of data sets: First, a class of synthetic data sets containing topological objects is employed to highlight the interaction capabilities of our method. Second, in order to affirm the utility of our technique, we analyse a class of high-dimensional real-world data sets arising from current research in cultural heritage.",
            "url": "http://dx.doi.org/10.1109/TVCG.2012.248",
            "id": "r_47",
            "s_ids": [
                "s_47",
                "s_297",
                "s_35"
            ],
            "type": "rich",
            "x": 9.946340560913086,
            "y": 7.179619312286377
        },
        {
            "title": "InSituNet: Deep Image Synthesis for Parameter Space Exploration of Ensemble Simulations",
            "data": "We propose InSituNet, a deep learning based surrogate model to support parameter space exploration for ensemble simulations that are visualized in situ. In situ visualization, generating visualizations at simulation time, is becoming prevalent in handling large-scale simulations because of the I/O and storage constraints. However, in situ visualization approaches limit the flexibility of post-hoc exploration because the raw simulation data are no longer available. Although multiple image-based approaches have been proposed to mitigate this limitation, those approaches lack the ability to explore the simulation parameters. Our approach allows flexible exploration of parameter space for large-scale ensemble simulations by taking advantage of the recent advances in deep learning. Specifically, we design InSituNet as a convolutional regression model to learn the mapping from the simulation and visualization parameters to the visualization results. With the trained model, users can generate new images for different simulation parameters under various visualization settings, which enables in-depth analysis of the underlying ensemble simulations. We demonstrate the effectiveness of InSituNet in combustion, cosmology, and ocean simulations through quantitative and qualitative evaluations.",
            "url": "http://dx.doi.org/10.1109/TVCG.2019.2934312",
            "id": "r_48",
            "s_ids": [
                "s_247",
                "s_44",
                "s_136",
                "s_320",
                "s_318",
                "s_388",
                "s_625",
                "s_9"
            ],
            "type": "rich",
            "x": 11.178451538085938,
            "y": 6.172502517700195
        },
        {
            "title": "Instant Construction and Visualization of Crowded Biological Environments",
            "data": "We present the first approach to integrative structural modeling of the biological mesoscale within an interactive visual environment. These complex models can comprise up to millions of molecules with defined atomic structures, locations, and interactions. Their construction has previously been attempted only within a non-visual and non-interactive environment. Our solution unites the modeling and visualization aspect, enabling interactive construction of atomic resolution mesoscale models of large portions of a cell. We present a novel set of GPU algorithms that build the basis for the rapid construction of complex biological structures. These structures consist of multiple membrane-enclosed compartments including both soluble molecules and fibrous structures. The compartments are defined using volume voxelization of triangulated meshes. For membranes, we present an extension of the Wang Tile concept that populates the bilayer with individual lipids. Soluble molecules are populated within compartments distributed according to a Halton sequence. Fibrous structures, such as RNA or actin filaments, are created by self-avoiding random walks. Resulting overlaps of molecules are resolved by a forced-based system. Our approach opens new possibilities to the world of interactive construction of cellular compartments. We demonstrate its effectiveness by showcasing scenes of different scale and complexity that comprise blood plasma, mycoplasma, and HIV.",
            "url": "http://dx.doi.org/10.1109/TVCG.2017.2744258",
            "id": "r_49",
            "s_ids": [
                "s_402",
                "s_283",
                "s_448",
                "s_454",
                "s_119",
                "s_474",
                "s_395"
            ],
            "type": "rich",
            "x": 11.97082233428955,
            "y": 3.3876423835754395
        },
        {
            "title": "Visualization of Time-Varying Weather Ensembles across Multiple Resolutions",
            "data": "Uncertainty quantification in climate ensembles is an important topic for the domain scientists, especially for decision making in the real-world scenarios. With powerful computers, simulations now produce time-varying and multi-resolution ensemble data sets. It is of extreme importance to understand the model sensitivity given the input parameters such that more computation power can be allocated to the parameters with higher influence on the output. Also, when ensemble data is produced at different resolutions, understanding the accuracy of different resolutions helps the total time required to produce a desired quality solution with improved storage and computation cost. In this work, we propose to tackle these non-trivial problems on the Weather Research and Forecasting (WRF) model output. We employ a moment independent sensitivity measure to quantify and analyze parameter sensitivity across spatial regions and time domain. A comparison of clustering structures across three resolutions enables the users to investigate the sensitivity variation over the spatial regions of the five input parameters. The temporal trend in the sensitivity values is explored via an MDS view linked with a line chart for interactive brushing. The spatial and temporal views are connected to provide a full exploration system for complete spatio-temporal sensitivity analysis. To analyze the accuracy across varying resolutions, we formulate a Bayesian approach to identify which regions are better predicted at which resolutions compared to the observed precipitation. This information is aggregated over the time domain and finally encoded in an output image through a custom color map that guides the domain experts towards an adaptive grid implementation given a cost model. Users can select and further analyze the spatial and temporal error patterns for multi-resolution accuracy analysis via brushing and linking on the produced image. In this work, we collaborate with a domain expert whose feedback shows the effectiveness of our proposed exploration work-flow.",
            "url": "http://dx.doi.org/10.1109/TVCG.2016.2598869",
            "id": "r_50",
            "s_ids": [
                "s_70",
                "s_196",
                "s_422",
                "s_318"
            ],
            "type": "rich",
            "x": 10.91222095489502,
            "y": 6.26889705657959
        },
        {
            "title": "NeuroBlocks - Visual Tracking of Segmentation and Proofreading for Large Connectomics Projects",
            "data": "In the field of connectomics, neuroscientists acquire electron microscopy volumes at nanometer resolution in order to reconstruct a detailed wiring diagram of the neurons in the brain. The resulting image volumes, which often are hundreds of terabytes in size, need to be segmented to identify cell boundaries, synapses, and important cell organelles. However, the segmentation process of a single volume is very complex, time-intensive, and usually performed using a diverse set of tools and many users. To tackle the associated challenges, this paper presents NeuroBlocks, which is a novel visualization system for tracking the state, progress, and evolution of very large volumetric segmentation data in neuroscience. NeuroBlocks is a multi-user web-based application that seamlessly integrates the diverse set of tools that neuroscientists currently use for manual and semi-automatic segmentation, proofreading, visualization, and analysis. NeuroBlocks is the first system that integrates this heterogeneous tool set, providing crucial support for the management, provenance, accountability, and auditing of large-scale segmentations. We describe the design of NeuroBlocks, starting with an analysis of the domain-specific tasks, their inherent challenges, and our subsequent task abstraction and visual representation. We demonstrate the utility of our design based on two case studies that focus on different user roles and their respective requirements for performing and tracking the progress of segmentation and proofreading in a large real-world connectomics project.",
            "url": "http://dx.doi.org/10.1109/TVCG.2015.2467441",
            "id": "r_51",
            "s_ids": [
                "s_544",
                "s_557",
                "s_390",
                "s_82",
                "s_274",
                "s_561",
                "s_300"
            ],
            "type": "rich",
            "x": 11.359683990478516,
            "y": 3.232149839401245
        },
        {
            "title": "Distribution Driven Extraction and Tracking of Features for Time-varying Data Analysis",
            "data": "Effective analysis of features in time-varying data is essential in numerous scientific applications. Feature extraction and tracking are two important tasks scientists rely upon to get insights about the dynamic nature of the large scale time-varying data. However, often the complexity of the scientific phenomena only allows scientists to vaguely define their feature of interest. Furthermore, such features can have varying motion patterns and dynamic evolution over time. As a result, automatic extraction and tracking of features becomes a non-trivial task. In this work, we investigate these issues and propose a distribution driven approach which allows us to construct novel algorithms for reliable feature extraction and tracking with high confidence in the absence of accurate feature definition. We exploit two key properties of an object, motion and similarity to the target feature, and fuse the information gained from them to generate a robust feature-aware classification field at every time step. Tracking of features is done using such classified fields which enhances the accuracy and robustness of the proposed algorithm. The efficacy of our method is demonstrated by successfully applying it on several scientific data sets containing a wide range of dynamic time-varying features.",
            "url": "http://dx.doi.org/10.1109/TVCG.2015.2467436",
            "id": "r_52",
            "s_ids": [
                "s_521",
                "s_318"
            ],
            "type": "rich",
            "x": 9.849995613098145,
            "y": 6.328359603881836
        },
        {
            "title": "Cluster Analysis of Vortical Flow in Simulations of Cerebral Aneurysm Hemodynamics",
            "data": "Computational fluid dynamic (CFD) simulations of blood flow provide new insights into the hemodynamics of vascular pathologies such as cerebral aneurysms. Understanding the relations between hemodynamics and aneurysm initiation, progression, and risk of rupture is crucial in diagnosis and treatment. Recent studies link the existence of vortices in the blood flow pattern to aneurysm rupture and report observations of embedded vortices - a larger vortex encloses a smaller one flowing in the opposite direction - whose implications are unclear. We present a clustering-based approach for the visual analysis of vortical flow in simulated cerebral aneurysm hemodynamics. We show how embedded vortices develop at saddle-node bifurcations on vortex core lines and convey the participating flow at full manifestation of the vortex by a fast and smart grouping of streamlines and the visualization of group representatives. The grouping result may be refined based on spectral clustering generating a more detailed visualization of the flow pattern, especially further off the core lines. We aim at supporting CFD engineers researching the biological implications of embedded vortices.",
            "url": "http://dx.doi.org/10.1109/TVCG.2015.2467203",
            "id": "r_53",
            "s_ids": [
                "s_484",
                "s_612",
                "s_559",
                "s_585"
            ],
            "type": "rich",
            "x": 7.416557312011719,
            "y": 4.407098770141602
        },
        {
            "title": "Rotation Invariant Vortices for Flow Visualization",
            "data": "We propose a new class of vortex definitions for flows that are induced by rotating mechanical parts, such as stirring devices, helicopters, hydrocyclones, centrifugal pumps, or ventilators. Instead of a Galilean invariance, we enforce a rotation invariance, i.e., the invariance of a vortex under a uniform-speed rotation of the underlying coordinate system around a fixed axis. We provide a general approach to transform a Galilean invariant vortex concept to a rotation invariant one by simply adding a closed form matrix to the Jacobian. In particular, we present rotation invariant versions of the well-known Sujudi-Haimes, Lambda-2, and Q vortex criteria. We apply them to a number of artificial and real rotating flows, showing that for these cases rotation invariant vortices give better results than their Galilean invariant counterparts.",
            "url": "http://dx.doi.org/10.1109/TVCG.2015.2467200",
            "id": "r_54",
            "s_ids": [
                "s_443",
                "s_545",
                "s_653"
            ],
            "type": "rich",
            "x": 7.530010223388672,
            "y": 5.222029209136963
        },
        {
            "title": "Conforming Morse-Smale Complexes",
            "data": "Morse-Smale (MS) complexes have been gaining popularity as a tool for feature-driven data analysis and visualization. However, the quality of their geometric embedding and the sole dependence on the input scalar field data can limit their applicability when expressing application-dependent features. In this paper we introduce a new combinatorial technique to compute an MS complex that conforms to both an input scalar field and an additional, prior segmentation of the domain. The segmentation constrains the MS complex computation guaranteeing that boundaries in the segmentation are captured as separatrices of the MS complex. We demonstrate the utility and versatility of our approach with two applications. First, we use streamline integration to determine numerically computed basins/mountains and use the resulting segmentation as an input to our algorithm. This strategy enables the incorporation of prior flow path knowledge, effectively resulting in an MS complex that is as geometrically accurate as the employed numerical integration. Our second use case is motivated by the observation that often the data itself does not explicitly contain features known to be present by a domain expert. We introduce edit operations for MS complexes so that a user can directly modify their features while maintaining all the advantages of a robust topology-based representation.",
            "url": "http://dx.doi.org/10.1109/TVCG.2014.2346434",
            "id": "r_55",
            "s_ids": [
                "s_660",
                "s_254",
                "s_577",
                "s_572",
                "s_273"
            ],
            "type": "rich",
            "x": 9.28204345703125,
            "y": 6.7093377113342285
        },
        {
            "title": "Multiscale Symmetry Detection in Scalar Fields by Clustering Contours",
            "data": "The complexity in visualizing volumetric data often limits the scope of direct exploration of scalar fields. Isocontour extraction is a popular method for exploring scalar fields because of its simplicity in presenting features in the data. In this paper, we present a novel representation of contours with the aim of studying the similarity relationship between the contours. The representation maps contours to points in a high-dimensional transformation-invariant descriptor space. We leverage the power of this representation to design a clustering based algorithm for detecting symmetric regions in a scalar field. Symmetry detection is a challenging problem because it demands both segmentation of the data and identification of transformation invariant segments. While the former task can be addressed using topological analysis of scalar fields, the latter requires geometry based solutions. Our approach combines the two by utilizing the contour tree for segmenting the data and the descriptor space for determining transformation invariance. We discuss two applications, query driven exploration and asymmetry visualization, that demonstrate the effectiveness of the approach.",
            "url": "http://dx.doi.org/10.1109/TVCG.2014.2346332",
            "id": "r_56",
            "s_ids": [
                "s_385",
                "s_629"
            ],
            "type": "rich",
            "x": 8.919781684875488,
            "y": 6.4842987060546875
        },
        {
            "title": "An Exploration Framework to Identify and Track Movement of Cloud Systems",
            "data": "We describe a framework to explore and visualize the movement of cloud systems. Using techniques from computational topology and computer vision, our framework allows the user to study this movement at various scales in space and time. Such movements could have large temporal and spatial scales such as the Madden Julian Oscillation (MJO), which has a spatial scale ranging from 1000 km to 10000 km and time of oscillation of around 40 days. Embedded within these larger scale oscillations are a hierarchy of cloud clusters which could have smaller spatial and temporal scales such as the Nakazawa cloud clusters. These smaller cloud clusters, while being part of the equatorial MJO, sometimes move at speeds different from the larger scale and in a direction opposite to that of the MJO envelope. Hitherto, one could only speculate about such movements by selectively analysing data and a priori knowledge of such systems. Our framework automatically delineates such cloud clusters and does not depend on the prior experience of the user to define cloud clusters. Analysis using our framework also shows that most tropical systems such as cyclones also contain multi-scale interactions between clouds and cloud systems. We show the effectiveness of our framework to track organized cloud system during one such rainfall event which happened at Mumbai, India in July 2005 and for cyclone Aila which occurred in Bay of Bengal during May 2009.",
            "url": "http://dx.doi.org/10.1109/TVCG.2013.131",
            "id": "r_57",
            "s_ids": [
                "s_27",
                "s_629",
                "s_543"
            ],
            "type": "rich",
            "x": 10.616813659667969,
            "y": 5.81190824508667
        },
        {
            "title": "LassoNet: Deep Lasso-Selection of 3D Point Clouds",
            "data": "Selection is a fundamental task in exploratory analysis and visualization of 3D point clouds. Prior researches on selection methods were developed mainly based on heuristics such as local point density, thus limiting their applicability in general data. Specific challenges root in the great variabilities implied by point clouds (e.g., dense vs. sparse), viewpoint (e.g., occluded vs. non-occluded), and lasso (e.g., small vs. large). In this work, we introduce LassoNet, a new deep neural network for lasso selection of 3D point clouds, attempting to learn a latent mapping from viewpoint and lasso to point cloud regions. To achieve this, we couple user-target points with viewpoint and lasso information through 3D coordinate transform and naive selection, and improve the method scalability via an intention filtering and farthest point sampling. A hierarchical network is trained using a dataset with over 30K lasso-selection records on two different point cloud data. We conduct a formal user study to compare LassoNet with two state-of-the-art lasso-selection methods. The evaluations confirm that our approach improves the selection effectiveness and efficiency across different combinations of 3D point clouds, viewpoints, and lasso selections. Project Website: https://LassoNet.github.io",
            "url": "http://dx.doi.org/10.1109/TVCG.2019.2934332",
            "id": "r_58",
            "s_ids": [
                "s_652",
                "s_518",
                "s_202",
                "s_150",
                "s_554",
                "s_129"
            ],
            "type": "rich",
            "x": 11.355864524841309,
            "y": 5.678099632263184
        },
        {
            "title": "Shared-Memory Parallel Computation of Morse-Smale Complexes with Improved Accuracy",
            "data": "Topological techniques have proven to be a powerful tool in the analysis and visualization of large-scale scientific data. In particular, the Morse-Smale complex and its various components provide a rich framework for robust feature definition and computation. Consequently, there now exist a number of approaches to compute Morse-Smale complexes for large-scale data in parallel. However, existing techniques are based on discrete concepts which produce the correct topological structure but are known to introduce grid artifacts in the resulting geometry. Here, we present a new approach that combines parallel streamline computation with combinatorial methods to construct a high-quality discrete Morse-Smale complex. In addition to being invariant to the orientation of the underlying grid, this algorithm allows users to selectively build a subset of features using high-quality geometry. In particular, a user may specifically select which ascending/descending manifolds are reconstructed with improved accuracy, focusing computational effort where it matters for subsequent analysis. This approach computes Morse-Smale complexes for larger data than previously feasible with significant speedups. We demonstrate and validate our approach using several examples from a variety of different scientific domains, and evaluate the performance of our method.",
            "url": "http://dx.doi.org/10.1109/TVCG.2018.2864848",
            "id": "r_59",
            "s_ids": [
                "s_660",
                "s_392",
                "s_273"
            ],
            "type": "rich",
            "x": 8.920732498168945,
            "y": 6.913393020629883
        },
        {
            "title": "Visualizing Nuclear Scission through a Multifield Extension of Topological Analysis",
            "data": "In nuclear science, density functional theory (DFT) is a powerful tool to model the complex interactions within the atomic nucleus, and is the primary theoretical approach used by physicists seeking a better understanding of fission. However DFT simulations result in complex multivariate datasets in which it is difficult to locate the crucial `scission' point at which one nucleus fragments into two, and to identify the precursors to scission. The Joint Contour Net (JCN) has recently been proposed as a new data structure for the topological analysis of multivariate scalar fields, analogous to the contour tree for univariate fields. This paper reports the analysis of DFT simulations using the JCN, the first application of the JCN technique to real data. It makes three contributions to visualization: (i) a set of practical methods for visualizing the JCN, (ii) new insight into the detection of nuclear scission, and (iii) an analysis of aesthetic criteria to drive further work on representing the JCN.",
            "url": "http://dx.doi.org/10.1109/TVCG.2012.287",
            "id": "r_60",
            "s_ids": [
                "s_143",
                "s_445",
                "s_665",
                "s_225",
                "s_339",
                "s_8"
            ],
            "type": "rich",
            "x": 9.687100410461426,
            "y": 5.438337326049805
        },
        {
            "title": "Uncertainty Visualization Using Copula-Based Analysis in Mixed Distribution Models",
            "data": "Distributions are often used to model uncertainty in many scientific datasets. To preserve the correlation among the spatially sampled grid locations in the dataset, various standard multivariate distribution models have been proposed in visualization literature. These models treat each grid location as a univariate random variable which models the uncertainty at that location. Standard multivariate distributions (both parametric and nonparametric) assume that all the univariate marginals are of the same type/family of distribution. But in reality, different grid locations show different statistical behavior which may not be modeled best by the same type of distribution. In this paper, we propose a new multivariate uncertainty modeling strategy to address the needs of uncertainty modeling in scientific datasets. Our proposed method is based on a statistically sound multivariate technique called Copula, which makes it possible to separate the process of estimating the univariate marginals and the process of modeling dependency, unlike the standard multivariate distributions. The modeling flexibility offered by our proposed method makes it possible to design distribution fields which can have different types of distribution (Gaussian, Histogram, KDE etc.) at the grid locations, while maintaining the correlation structure at the same time. Depending on the results of various standard statistical tests, we can choose an optimal distribution representation at each location, resulting in a more cost efficient modeling without significantly sacrificing on the analysis quality. To demonstrate the efficacy of our proposed modeling strategy, we extract and visualize uncertain features like isocontours and vortices in various real world datasets. We also study various modeling criterion to help users in the task of univariate model selection.",
            "url": "http://dx.doi.org/10.1109/TVCG.2017.2744099",
            "id": "r_61",
            "s_ids": [
                "s_125",
                "s_70",
                "s_318"
            ],
            "type": "rich",
            "x": 10.959868431091309,
            "y": 7.290438652038574
        },
        {
            "title": "TopoAngler: Interactive Topology-Based Extraction of Fishes",
            "data": "We present TopoAngler, a visualization framework that enables an interactive user-guided segmentation of fishes contained in a micro-CT scan. The inherent noise in the CT scan coupled with the often disconnected (and sometimes broken) skeletal structure of fishes makes an automatic segmentation of the volume impractical. To overcome this, our framework combines techniques from computational topology with an interactive visual interface, enabling the human-in-the-Ioop to effectively extract fishes from the volume. In the first step, the join tree of the input is used to create a hierarchical segmentation of the volume. Through the use of linked views, the visual interface then allows users to interactively explore this hierarchy, and gather parts of individual fishes into a coherent sub-volume, thus reconstructing entire fishes. Our framework was primarily developed for its application to CT scans of fishes, generated as part of the ScanAllFish project, through close collaboration with their lead scientist. However, we expect it to also be applicable in other biological applications where a single dataset contains multiple specimen; a common routine that is now widely followed in laboratories to increase throughput of expensive CT scanners.",
            "url": "http://dx.doi.org/10.1109/TVCG.2017.2743980",
            "id": "r_62",
            "s_ids": [
                "s_457",
                "s_27",
                "s_128",
                "s_344"
            ],
            "type": "rich",
            "x": 7.95355749130249,
            "y": 4.046621322631836
        },
        {
            "title": "Categorical Colormap Optimization with Visualization Case Studies",
            "data": "Mapping a set of categorical values to different colors is an elementary technique in data visualization. Users of visualization software routinely rely on the default colormaps provided by a system, or colormaps suggested by software such as ColorBrewer. In practice, users often have to select a set of colors in a semantically meaningful way (e.g., based on conventions, color metaphors, and logological associations), and consequently would like to ensure their perceptual differentiation is optimized. In this paper, we present an algorithmic approach for maximizing the perceptual distances among a set of given colors. We address two technical problems in optimization, i.e., (i) the phenomena of local maxima that halt the optimization too soon, and (ii) the arbitrary reassignment of colors that leads to the loss of the original semantic association. We paid particular attention to different types of constraints that users may wish to impose during the optimization process. To demonstrate the effectiveness of this work, we tested this technique in two case studies. To reach out to a wider range of users, we also developed a web application called Colourmap Hospital.",
            "url": "http://dx.doi.org/10.1109/TVCG.2016.2599214",
            "id": "r_63",
            "s_ids": [
                "s_661",
                "s_359",
                "s_301",
                "s_219",
                "s_266",
                "s_249"
            ],
            "type": "rich",
            "x": 11.72203254699707,
            "y": 5.292431354522705
        },
        {
            "title": "Jacobi Fiber Surfaces for Bivariate Reeb Space Computation",
            "data": "This paper presents an efficient algorithm for the computation of the Reeb space of an input bivariate piecewise linear scalar function f defined on a tetrahedral mesh. By extending and generalizing algorithmic concepts from the univariate case to the bivariate one, we report the first practical, output-sensitive algorithm for the exact computation of such a Reeb space. The algorithm starts by identifying the Jacobi set of f, the bivariate analogs of critical points in the univariate case. Next, the Reeb space is computed by segmenting the input mesh along the new notion of Jacobi Fiber Surfaces, the bivariate analog of critical contours in the univariate case. We additionally present a simplification heuristic that enables the progressive coarsening of the Reeb space. Our algorithm is simple to implement and most of its computations can be trivially parallelized. We report performance numbers demonstrating orders of magnitude speedups over previous approaches, enabling for the first time the tractable computation of bivariate Reeb spaces in practice. Moreover, unlike range-based quantization approaches (such as the Joint Contour Net), our algorithm is parameter-free. We demonstrate the utility of our approach by using the Reeb space as a semi-automatic segmentation tool for bivariate data. In particular, we introduce continuous scatterplot peeling, a technique which enables the reduction of the cluttering in the continuous scatterplot, by interactively selecting the features of the Reeb space to project. We provide a VTK-based C++ implementation of our algorithm that can be used for reproduction purposes or for the development of new Reeb space based visualization techniques.",
            "url": "http://dx.doi.org/10.1109/TVCG.2016.2599017",
            "id": "r_64",
            "s_ids": [
                "s_572",
                "s_445"
            ],
            "type": "rich",
            "x": 8.943709373474121,
            "y": 7.213334083557129
        },
        {
            "title": "Occlusion-free Blood Flow Animation with Wall Thickness Visualization",
            "data": "We present the first visualization tool that combines pathlines from blood flow and wall thickness information. Our method uses illustrative techniques to provide occlusion-free visualization of the flow. We thus offer medical researchers an effective visual analysis tool for aneurysm treatment risk assessment. Such aneurysms bear a high risk of rupture and significant treatment-related risks. Therefore, to get a fully informed decision it is essential to both investigate the vessel morphology and the hemodynamic data. Ongoing research emphasizes the importance of analyzing the wall thickness in risk assessment. Our combination of blood flow visualization and wall thickness representation is a significant improvement for the exploration and analysis of aneurysms. As all presented information is spatially intertwined, occlusion problems occur. We solve these occlusion problems by dynamic cutaway surfaces. We combine this approach with a glyph-based blood flow representation and a visual mapping of wall thickness onto the vessel surface. We developed a GPU-based implementation of our visualizations which facilitates wall thickness analysis through real-time rendering and flexible interactive data exploration mechanisms. We designed our techniques in collaboration with domain experts, and we provide details about the evaluation of the technique and tool.",
            "url": "http://dx.doi.org/10.1109/TVCG.2015.2467961",
            "id": "r_65",
            "s_ids": [
                "s_658",
                "s_124",
                "s_372",
                "s_585",
                "s_429"
            ],
            "type": "rich",
            "x": 7.529611110687256,
            "y": 4.208322048187256
        },
        {
            "title": "Ambient Volume Scattering",
            "data": "We present ambient scattering as a preintegration method for scattering on mesoscopic scales in direct volume rendering. Far-range scattering effects usually provide negligible contributions to a given location due to the exponential attenuation with increasing distance. This motivates our approach to preintegrating multiple scattering within a finite spherical region around any given sample point. To this end, we solve the full light transport with a Monte-Carlo simulation within a set of spherical regions, where each region may have different material parameters regarding anisotropy and extinction. This precomputation is independent of the data set and the transfer function, and results in a small preintegration table. During rendering, the look-up table is accessed for each ray sample point with respect to the viewing direction, phase function, and material properties in the spherical neighborhood of the sample. Our rendering technique is efficient and versatile because it readily fits in existing ray marching algorithms and can be combined with local illumination and volumetric ambient occlusion. It provides interactive volumetric scattering and soft shadows, with interactive control of the transfer function, anisotropy parameter of the phase function, lighting conditions, and viewpoint. A GPU implementation demonstrates the benefits of ambient scattering for the visualization of different types of data sets, with respect to spatial perception, high-quality illumination, translucency, and rendering speed.",
            "url": "http://dx.doi.org/10.1109/TVCG.2013.129",
            "id": "r_66",
            "s_ids": [
                "s_147",
                "s_641",
                "s_130"
            ],
            "type": "rich",
            "x": 9.559818267822266,
            "y": 4.423428535461426
        },
        {
            "title": "Globe Browsing: Contextualized Spatio-Temporal Planetary Surface Visualization",
            "data": "Results of planetary mapping are often shared openly for use in scientific research and mission planning. In its raw format, however, the data is not accessible to non-experts due to the difficulty in grasping the context and the intricate acquisition process. We present work on tailoring and integration of multiple data processing and visualization methods to interactively contextualize geospatial surface data of celestial bodies for use in science communication. As our approach handles dynamic data sources, streamed from online repositories, we are significantly shortening the time between discovery and dissemination of data and results. We describe the image acquisition pipeline, the pre-processing steps to derive a 2.5D terrain, and a chunked level-of-detail, out-of-core rendering approach to enable interactive exploration of global maps and high-resolution digital terrain models. The results are demonstrated for three different celestial bodies. The first case addresses high-resolution map data on the surface of Mars. A second case is showing dynamic processes, such as concurrent weather conditions on Earth that require temporal datasets. As a final example we use data from the New Horizons spacecraft which acquired images during a single flyby of Pluto. We visualize the acquisition process as well as the resulting surface data. Our work has been implemented in the OpenSpace software [8], which enables interactive presentations in a range of environments such as immersive dome theaters, interactive touch tables, and virtual reality headsets.",
            "url": "http://dx.doi.org/10.1109/TVCG.2017.2743958",
            "id": "r_67",
            "s_ids": [
                "s_140",
                "s_433",
                "s_126",
                "s_620",
                "s_511",
                "s_457",
                "s_244"
            ],
            "type": "rich",
            "x": 10.655271530151367,
            "y": 4.658353328704834
        },
        {
            "title": "Lighting Design for Globally Illuminated Volume Rendering",
            "data": "With the evolution of graphics hardware, high quality global illumination becomes available for real-time volume rendering. Compared to local illumination, global illumination can produce realistic shading effects which are closer to real world scenes, and has proven useful for enhancing volume data visualization to enable better depth and shape perception. However, setting up optimal lighting could be a nontrivial task for average users. There were lighting design works for volume visualization but they did not consider global light transportation. In this paper, we present a lighting design method for volume visualization employing global illumination. The resulting system takes into account view and transfer-function dependent content of the volume data to automatically generate an optimized three-point lighting environment. Our method fully exploits the back light which is not used by previous volume visualization systems. By also including global shadow and multiple scattering, our lighting system can effectively enhance the depth and shape perception of volumetric features of interest. In addition, we propose an automatic tone mapping operator which recovers visual details from overexposed areas while maintaining sufficient contrast in the dark areas. We show that our method is effective for visualizing volume datasets with complex structures. The structural information is more clearly and correctly presented under the automatically generated light sources.",
            "url": "http://dx.doi.org/10.1109/TVCG.2013.172",
            "id": "r_68",
            "s_ids": [
                "s_286",
                "s_647"
            ],
            "type": "rich",
            "x": 9.57198715209961,
            "y": 4.237558841705322
        },
        {
            "title": "Interactive Patient-Specific Vascular Modeling with Sweep Surfaces",
            "data": "The precise modeling of vascular structures plays a key role in medical imaging applications, such as diagnosis, therapy planning and blood flow simulations. For the simulation of blood flow in particular, high-precision models are required to produce accurate results. It is thus common practice to perform extensive manual data polishing on vascular segmentations prior to simulation. This usually involves a complex tool chain which is highly impractical for clinical on-site application. To close this gap in current blood flow simulation pipelines, we present a novel technique for interactive vascular modeling which is based on implicit sweep surfaces. Our method is able to generate and correct smooth high-quality models based on geometric centerline descriptions on the fly. It supports complex vascular free-form contours and consequently allows for an accurate and fast modeling of pathological structures such as aneurysms or stenoses. We extend the concept of implicit sweep surfaces to achieve increased robustness and applicability as required in the medical field. We finally compare our method to existing techniques and provide case studies that confirm its contribution to current simulation pipelines.",
            "url": "http://dx.doi.org/10.1109/TVCG.2013.169",
            "id": "r_69",
            "s_ids": [
                "s_438",
                "s_416",
                "s_585",
                "s_515"
            ],
            "type": "rich",
            "x": 7.546726226806641,
            "y": 4.204033851623535
        },
        {
            "title": "Historygrams: Enabling Interactive Global Illumination in Direct Volume Rendering using Photon Mapping",
            "data": "In this paper, we enable interactive volumetric global illumination by extending photon mapping techniques to handle interactive transfer function (TF) and material editing in the context of volume rendering. We propose novel algorithms and data structures for finding and evaluating parts of a scene affected by these parameter changes, and thus support efficient updates of the photon map. In direct volume rendering (DVR) the ability to explore volume data using parameter changes, such as editable TFs, is of key importance. Advanced global illumination techniques are in most cases computationally too expensive, as they prevent the desired interactivity. Our technique decreases the amount of computation caused by parameter changes, by introducing Historygrams which allow us to efficiently reuse previously computed photon media interactions. Along the viewing rays, we utilize properties of the light transport equations to subdivide a view-ray into segments and independently update them when invalid. Unlike segments of a view-ray, photon scattering events within the volumetric medium needs to be sequentially updated. Using our Historygram approach, we can identify the first invalid photon interaction caused by a property change, and thus reuse all valid photon interactions. Combining these two novel concepts, supports interactive editing of parameters when using volumetric photon mapping in the context of DVR. As a consequence, we can handle arbitrarily shaped and positioned light sources, arbitrary phase functions, bidirectional reflectance distribution functions and multiple scattering which has previously not been possible in interactive DVR.",
            "url": "http://dx.doi.org/10.1109/TVCG.2012.232",
            "id": "r_70",
            "s_ids": [
                "s_673",
                "s_14",
                "s_183",
                "s_244"
            ],
            "type": "rich",
            "x": 9.420313835144043,
            "y": 4.213506698608398
        },
        {
            "title": "A Structural Average of Labeled Merge Trees for Uncertainty Visualization",
            "data": "Physical phenomena in science and engineering are frequently modeled using scalar fields. In scalar field topology, graph-based topological descriptors such as merge trees, contour trees, and Reeb graphs are commonly used to characterize topological changes in the (sub)level sets of scalar fields. One of the biggest challenges and opportunities to advance topology-based visualization is to understand and incorporate uncertainty into such topological descriptors to effectively reason about their underlying data. In this paper, we study a structural average of a set of labeled merge trees and use it to encode uncertainty in data. Specifically, we compute a 1-center tree that minimizes its maximum distance to any other tree in the set under a well-defined metric called the interleaving distance. We provide heuristic strategies that compute structural averages of merge trees whose labels do not fully agree. We further provide an interactive visualization system that resembles a numerical calculator that takes as input a set of merge trees and outputs a tree as their structural average. We also highlight structural similarities between the input and the average and incorporate uncertainty information for visual exploration. We develop a novel measure of uncertainty, referred to as consistency, via a metric-space view of the input trees. Finally, we demonstrate an application of our framework through merge trees that arise from ensembles of scalar fields. Our work is the first to employ interleaving distances and consistency to study a global, mathematically rigorous, structural average of merge trees in the context of uncertainty visualization.",
            "url": "http://dx.doi.org/10.1109/TVCG.2019.2934242",
            "id": "r_71",
            "s_ids": [
                "s_648",
                "s_31",
                "s_380",
                "s_114",
                "s_3"
            ],
            "type": "rich",
            "x": 10.1434907913208,
            "y": 7.183420181274414
        },
        {
            "title": "Time-Dependent Flow seen through Approximate Observer Killing Fields",
            "data": "Flow fields are usually visualized relative to a global observer, i.e., a single frame of reference. However, often no global frame can depict all flow features equally well. Likewise, objective criteria for detecting features such as vortices often use either a global reference frame, or compute a separate frame for each point in space and time. We propose the first general framework that enables choosing a smooth trade-off between these two extremes. Using global optimization to minimize specific differential geometric properties, we compute a time-dependent observer velocity field that describes the motion of a continuous field of observers adapted to the input flow. This requires developing the novel notion of an observed time derivative. While individual observers are restricted to rigid motions, overall we compute an approximate Killing field, corresponding to almost-rigid motion. This enables continuous transitions between different observers. Instead of focusing only on flow features, we furthermore develop a novel general notion of visualizing how all observers jointly perceive the input field. This in fact requires introducing the concept of an observation time, with respect to which a visualization is computed. We develop the corresponding notions of observed stream, path, streak, and time lines. For efficiency, these characteristic curves can be computed using standard approaches, by first transforming the input field accordingly. Finally, we prove that the input flow perceived by the observer field is objective. This makes derived flow features, such as vortices, objective as well.",
            "url": "http://dx.doi.org/10.1109/TVCG.2018.2864839",
            "id": "r_72",
            "s_ids": [
                "s_300",
                "s_366",
                "s_570",
                "s_145"
            ],
            "type": "rich",
            "x": 8.03162956237793,
            "y": 5.434492588043213
        },
        {
            "title": "Combined Visualization of Vessel Deformation and Hemodynamics in Cerebral Aneurysms",
            "data": "We present the first visualization tool that combines patient-specific hemodynamics with information about the vessel wall deformation and wall thickness in cerebral aneurysms. Such aneurysms bear the risk of rupture, whereas their treatment also carries considerable risks for the patient. For the patient-specific rupture risk evaluation and treatment analysis, both morphological and hemodynamic data have to be investigated. Medical researchers emphasize the importance of analyzing correlations between wall properties such as the wall deformation and thickness, and hemodynamic attributes like the Wall Shear Stress and near-wall flow. Our method uses a linked 2.5D and 3D depiction of the aneurysm together with blood flow information that enables the simultaneous exploration of wall characteristics and hemodynamic attributes during the cardiac cycle. We thus offer medical researchers an effective visual exploration tool for aneurysm treatment risk assessment. The 2.5D view serves as an overview that comprises a projection of the vessel surface to a 2D map, providing an occlusion-free surface visualization combined with a glyph-based depiction of the local wall thickness. The 3D view represents the focus upon which the data exploration takes place. To support the time-dependent parameter exploration and expert collaboration, a camera path is calculated automatically, where the user can place landmarks for further exploration of the properties. We developed a GPU-based implementation of our visualizations with a flexible interactive data exploration mechanism. We designed our techniques in collaboration with domain experts, and provide details about the evaluation.",
            "url": "http://dx.doi.org/10.1109/TVCG.2016.2598795",
            "id": "r_73",
            "s_ids": [
                "s_97",
                "s_638",
                "s_224",
                "s_585",
                "s_658"
            ],
            "type": "rich",
            "x": 7.493898391723633,
            "y": 3.9540703296661377
        },
        {
            "title": "Effects of Stereo and Screen Size on the Legibility of Three-Dimensional Streamtube Visualization",
            "data": "We report the impact of display characteristics (stereo and size) on task performance in diffusion magnetic resonance imaging (DMRI) in a user study with 12 participants. The hypotheses were that (1) adding stereo and increasing display size would improve task accuracy and reduce completion time, and (2) the greater the complexity of a spatial task, the greater the benefits of an improved display. Thus we expected to see greater performance gains when detailed visual reasoning was required. Participants used dense streamtube visualizations to perform five representative tasks: (1) determine the higher average fractional anisotropy (FA) values between two regions, (2) find the endpoints of fiber tracts, (3) name a bundle, (4) mark a brain lesion, and (5) judge if tracts belong to the same bundle. Contrary to our hypotheses, we found the task completion time was not improved by the use of the larger display and that performance accuracy was hurt rather than helped by the introduction of stereo in our study with dense DMRI data. Bigger was not always better. Thus cautious should be taken when selecting displays for scientific visualization applications. We explored the results further using the body-scale unit and subjective size and stereo experiences.",
            "url": "http://dx.doi.org/10.1109/TVCG.2012.216",
            "id": "r_74",
            "s_ids": [
                "s_350",
                "s_384",
                "s_110",
                "s_363"
            ],
            "type": "rich",
            "x": 9.786408424377441,
            "y": 3.1464149951934814
        },
        {
            "title": "TSR-TVD: Temporal Super-Resolution for Time-Varying Data Analysis and Visualization",
            "data": "We present TSR-TVD, a novel deep learning framework that generates temporal super-resolution (TSR) of time-varying data (TVD) using adversarial learning. TSR-TVD is the first work that applies the recurrent generative network (RGN), a combination of the recurrent neural network (RNN) and generative adversarial network (GAN), to generate temporal high-resolution volume sequences from low-resolution ones. The design of TSR-TVD includes a generator and a discriminator. The generator takes a pair of volumes as input and outputs the synthesized intermediate volume sequence through forward and backward predictions. The discriminator takes the synthesized intermediate volumes as input and produces a score indicating the realness of the volumes. Our method handles multivariate data as well where the trained network from one variable is applied to generate TSR for another variable. To demonstrate the effectiveness of TSR-TVD, we show quantitative and qualitative results with several time-varying multivariate data sets and compare our method against standard linear interpolation and solutions solely based on RNN or CNN.",
            "url": "http://dx.doi.org/10.1109/TVCG.2019.2934255",
            "id": "r_75",
            "s_ids": [
                "s_158",
                "s_485"
            ],
            "type": "rich",
            "x": 9.520474433898926,
            "y": 5.915861129760742
        },
        {
            "title": "Attractive Flicker: Guiding Attention in Dynamic Narrative Visualizations",
            "data": "Focus-context techniques provide visual guidance in visualizations by giving strong visual prominence to elements of interest while the context is suppressed. However, finding a visual feature to enhance for the focus to pop out from its context in a large dynamic scene, while leading to minimal visual deformation and subjective disturbance, is challenging. This paper proposes Attractive Flicker, a novel technique for visual guidance in dynamic narrative visualizations. We first show that flicker is a strong visual attractor in the entire visual field, without distorting, suppressing, or adding any scene elements. The novel aspect of our Attractive Flicker technique is that it consists of two signal stages: The first \u201corientation stage\u201d is a short but intensive flicker stimulus to attract the attention to elements of interest. Subsequently, the intensive flicker is reduced to a minimally disturbing luminance oscillation (\u201cengagement stage\u201d) as visual support to keep track of the focus elements. To find a good trade-off between attraction effectiveness and subjective annoyance caused by flicker, we conducted two perceptual studies to find suitable signal parameters. We showcase Attractive Flicker with the parameters obtained from the perceptual statistics in a study of molecular interactions. With Attractive Flicker, users were able to easily follow the narrative of the visualization on a large display, while the flickering of focus elements was not disturbing when observing the context.",
            "url": "http://dx.doi.org/10.1109/TVCG.2014.2346352",
            "id": "r_76",
            "s_ids": [
                "s_581",
                "s_671",
                "s_432",
                "s_0",
                "s_395"
            ],
            "type": "rich",
            "x": 10.022345542907715,
            "y": 3.189236640930176
        },
        {
            "title": "Vivaldi: A Domain-Specific Language for Volume Processing and Visualization on Distributed Heterogeneous Systems",
            "data": "As the size of image data from microscopes and telescopes increases, the need for high-throughput processing and visualization of large volumetric data has become more pressing. At the same time, many-core processors and GPU accelerators are commonplace, making high-performance distributed heterogeneous computing systems affordable. However, effectively utilizing GPU clusters is difficult for novice programmers, and even experienced programmers often fail to fully leverage the computing power of new parallel architectures due to their steep learning curve and programming complexity. In this paper, we propose Vivaldi, a new domain-specific language for volume processing and visualization on distributed heterogeneous computing systems. Vivaldi's Python-like grammar and parallel processing abstractions provide flexible programming tools for non-experts to easily write high-performance parallel computing code. Vivaldi provides commonly used functions and numerical operators for customized visualization and high-throughput image processing applications. We demonstrate the performance and usability of Vivaldi on several examples ranging from volume rendering to image segmentation.",
            "url": "http://dx.doi.org/10.1109/TVCG.2014.2346322",
            "id": "r_77",
            "s_ids": [
                "s_367",
                "s_556",
                "s_523",
                "s_337",
                "s_561",
                "s_352"
            ],
            "type": "rich",
            "x": 11.268532752990723,
            "y": 4.6747145652771
        },
        {
            "title": "Turbulence Visualization at the Terascale on Desktop PCs",
            "data": "Despite the ongoing efforts in turbulence research, the universal properties of the turbulence small-scale structure and the relationships between small- and large-scale turbulent motions are not yet fully understood. The visually guided exploration of turbulence features, including the interactive selection and simultaneous visualization of multiple features, can further progress our understanding of turbulence. Accomplishing this task for flow fields in which the full turbulence spectrum is well resolved is challenging on desktop computers. This is due to the extreme resolution of such fields, requiring memory and bandwidth capacities going beyond what is currently available. To overcome these limitations, we present a GPU system for feature-based turbulence visualization that works on a compressed flow field representation. We use a wavelet-based compression scheme including run-length and entropy encoding, which can be decoded on the GPU and embedded into brick-based volume ray-casting. This enables a drastic reduction of the data to be streamed from disk to GPU memory. Our system derives turbulence properties directly from the velocity gradient tensor, and it either renders these properties in turn or generates and renders scalar feature volumes. The quality and efficiency of the system is demonstrated in the visualization of two unsteady turbulence simulations, each comprising a spatio-temporal resolution of 10244. On a desktop computer, the system can visualize each time step in 5 seconds, and it achieves about three times this rate for the visualization of a scalar feature volume.",
            "url": "http://dx.doi.org/10.1109/TVCG.2012.274",
            "id": "r_78",
            "s_ids": [
                "s_470",
                "s_616",
                "s_222",
                "s_63",
                "s_343",
                "s_102"
            ],
            "type": "rich",
            "x": 8.745753288269043,
            "y": 5.485160827636719
        },
        {
            "title": "Vector Field Topology of Time-Dependent Flows in a Steady Reference Frame",
            "data": "The topological analysis of unsteady vector fields remains to this day one of the largest challenges in flow visualization. We build up on recent work on vortex extraction to define a time-dependent vector field topology for 2D and 3D flows. In our work, we split the vector field into two components: a vector field in which the flow becomes steady, and the remaining ambient flow that describes the motion of topological elements (such as sinks, sources and saddles) and feature curves (vortex corelines and bifurcation lines). To this end, we expand on recent local optimization approaches by modeling spatially-varying deformations through displacement transformations from continuum mechanics. We compare and discuss the relationships with existing local and integration-based topology extraction methods, showing for instance that separatrices seeded from saddles in the optimal frame align with the integration-based streakline vector field topology. In contrast to the streakline-based approach, our method gives a complete picture of the topology for every time slice, including the steps near the temporal domain boundaries. With our work it now becomes possible to extract topological information even when only few time slices are available. We demonstrate the method in several analytical and numerically-simulated flows and discuss practical aspects, limitations and opportunities for future work.",
            "url": "http://dx.doi.org/10.1109/TVCG.2019.2934375",
            "id": "r_79",
            "s_ids": [
                "s_84",
                "s_443"
            ],
            "type": "rich",
            "x": 7.8441548347473145,
            "y": 5.763240814208984
        },
        {
            "title": "ElVis: A System for the Accurate and Interactive Visualization of High-Order finite Element Solutions",
            "data": "This paper presents the Element Visualizer (ElVis), a new, open-source scientific visualization system for use with high-order finite element solutions to PDEs in three dimensions. This system is designed to minimize visualization errors of these types of fields by querying the underlying finite element basis functions (e.g., high-order polynomials) directly, leading to pixel-exact representations of solutions and geometry. The system interacts with simulation data through runtime plugins, which only require users to implement a handful of operations fundamental to finite element solvers. The data in turn can be visualized through the use of cut surfaces, contours, isosurfaces, and volume rendering. These visualization algorithms are implemented using NVIDIA's OptiX GPU-based ray-tracing engine, which provides accelerated ray traversal of the high-order geometry, and CUDA, which allows for effective parallel evaluation of the visualization algorithms. The direct interface between ElVis and the underlying data differentiates it from existing visualization tools. Current tools assume the underlying data is composed of linear primitives; high-order data must be interpolated with linear functions as a result. In this work, examples drawn from aerodynamic simulations-high-order discontinuous Galerkin finite element solutions of aerodynamic flows in particular-will demonstrate the superiority of ElVis' pixel-exact approach when compared with traditional linear-interpolation methods. Such methods can introduce a number of inaccuracies in the resulting visualization, making it unclear if visual artifacts are genuine to the solution data or if these artifacts are the result of interpolation errors. Linear methods additionally cannot properly visualize curved geometries (elements or boundaries) which can greatly inhibit developers' debugging efforts. As we will show, pixel-exact visualization exhibits none of these issues, removing the visualization scheme as a source of uncertainty for engineers using ElVis.",
            "url": "http://dx.doi.org/10.1109/TVCG.2012.218",
            "id": "r_80",
            "s_ids": [
                "s_278",
                "s_650",
                "s_453",
                "s_649"
            ],
            "type": "rich",
            "x": 9.855810165405273,
            "y": 5.229278564453125
        },
        {
            "title": "Modeling in the Time of COVID-19: Statistical and Rule-based Mesoscale Models",
            "data": "We present a new technique for the rapid modeling and construction of scientifically accurate mesoscale biological models. The resulting 3D models are based on a few 2D microscopy scans and the latest knowledge available about the biological entity, represented as a set of geometric relationships. Our new visual-programming technique is based on statistical and rule-based modeling approaches that are rapid to author, fast to construct, and easy to revise. From a few 2D microscopy scans, we determine the statistical properties of various structural aspects, such as the outer membrane shape, the spatial properties, and the distribution characteristics of the macromolecular elements on the membrane. This information is utilized in the construction of the 3D model. Once all the imaging evidence is incorporated into the model, additional information can be incorporated by interactively defining the rules that spatially characterize the rest of the biological entity, such as mutual interactions among macromolecules, and their distances and orientations relative to other structures. These rules are defined through an intuitive 3D interactive visualization as a visual-programming feedback loop. We demonstrate the applicability of our approach on a use case of the modeling procedure of the SARS-CoV-2 virion ultrastructure. This atomistic model, which we present here, can steer biological research to new promising directions in our efforts to fight the spread of the virus.",
            "url": "http://dx.doi.org/10.1109/TVCG.2020.3030415",
            "id": "r_81",
            "s_ids": [
                "s_289",
                "s_560",
                "s_402",
                "s_588",
                "s_193",
                "s_491",
                "s_153",
                "s_626",
                "s_283",
                "s_454",
                "s_395"
            ],
            "type": "rich",
            "x": 11.946690559387207,
            "y": 3.6632518768310547
        },
        {
            "title": "V2V: A Deep Learning Approach to Variable-to-Variable Selection and Translation for Multivariate Time-Varying Data",
            "data": "We present V2V, a novel deep learning framework, as a general-purpose solution to the variable-to-variable (V2V) selection and translation problem for multivariate time-varying data (MTVD) analysis and visualization. V2V leverages a representation learning algorithm to identify transferable variables and utilizes Kullback-Leibler divergence to determine the source and target variables. It then uses a generative adversarial network (GAN) to learn the mapping from the source variable to the target variable via the adversarial, volumetric, and feature losses. V2V takes the pairs of time steps of the source and target variable as input for training, Once trained, it can infer unseen time steps of the target variable given the corresponding time steps of the source variable. Several multivariate time-varying data sets of different characteristics are used to demonstrate the effectiveness of V2V, both quantitatively and qualitatively. We compare V2V against histogram matching and two other deep learning solutions (Pix2Pix and CycleGAN).",
            "url": "http://dx.doi.org/10.1109/TVCG.2020.3030346",
            "id": "r_82",
            "s_ids": [
                "s_158",
                "s_397",
                "s_313",
                "s_475",
                "s_485"
            ],
            "type": "rich",
            "x": 9.51290512084961,
            "y": 5.84752082824707
        },
        {
            "title": "A Fluid Flow Data Set for Machine Learning and its Application to Neural Flow Map Interpolation",
            "data": "In recent years, deep learning has opened countless research opportunities across many different disciplines. At present, visualization is mainly applied to explore and explain neural networks. Its counterpart-the application of deep learning to visualization problems-requires us to share data more openly in order to enable more scientists to engage in data-driven research. In this paper, we construct a large fluid flow data set and apply it to a deep learning problem in scientific visualization. Parameterized by the Reynolds number, the data set contains a wide spectrum of laminar and turbulent fluid flow regimes. The full data set was simulated on a high-performance compute cluster and contains 8000 time-dependent 2D vector fields, accumulating to more than 16 TB in size. Using our public fluid data set, we trained deep convolutional neural networks in order to set a benchmark for an improved post-hoc Lagrangian fluid flow analysis. In in-situ settings, flow maps are exported and interpolated in order to assess the transport characteristics of time-dependent fluids. Using deep learning, we improve the accuracy of flow map interpolations, allowing a more precise flow analysis at a reduced memory IO footprint.",
            "url": "http://dx.doi.org/10.1109/TVCG.2020.3028947",
            "id": "r_83",
            "s_ids": [
                "s_302",
                "s_562",
                "s_443"
            ],
            "type": "rich",
            "x": 8.901309967041016,
            "y": 5.460984230041504
        },
        {
            "title": "Persistence Atlas for Critical Point Variability in Ensembles",
            "data": "This paper presents a new approach for the visualization and analysis of the spatial variability of features of interest represented by critical points in ensemble data. Our framework, called Persistence Atlas, enables the visualization of the dominant spatial patterns of critical points, along with statistics regarding their occurrence in the ensemble. The persistence atlas represents in the geometrical domain each dominant pattern in the form of a confidence map for the appearance of critical points. As a by-product, our method also provides 2-dimensional layouts of the entire ensemble, highlighting the main trends at a global level. Our approach is based on the new notion of Persistence Map, a measure of the geometrical density in critical points which leverages the robustness to noise of topological persistence to better emphasize salient features. We show how to leverage spectral embedding to represent the ensemble members as points in a low-dimensional Euclidean space, where distances between points measure the dissimilarities between critical point layouts and where statistical tasks, such as clustering, can be easily carried out. Further, we show how the notion of mandatory critical point can be leveraged to evaluate for each cluster confidence regions for the appearance of critical points. Most of the steps of this framework can be trivially parallelized and we show how to efficiently implement them. Extensive experiments demonstrate the relevance of our approach. The accuracy of the confidence regions provided by the persistence atlas is quantitatively evaluated and compared to a baseline strategy using an off-the-shelf clustering approach. We illustrate the importance of the persistence atlas in a variety of real-life datasets, where clear trends in feature layouts are identified and analyzed. We provide a lightweight VTK-based C++ implementation of our approach that can be used for reproduction purposes.",
            "url": "http://dx.doi.org/10.1109/TVCG.2018.2864432",
            "id": "r_84",
            "s_ids": [
                "s_191",
                "s_482",
                "s_356",
                "s_572"
            ],
            "type": "rich",
            "x": 10.331377029418945,
            "y": 6.91035270690918
        },
        {
            "title": "Dynamic Load Balancing Based on Constrained K-D Tree Decomposition for Parallel Particle Tracing",
            "data": "We propose a dynamically load-balanced algorithm for parallel particle tracing, which periodically attempts to evenly redistribute particles across processes based on k-d tree decomposition. Each process is assigned with (1) a statically partitioned, axis-aligned data block that partially overlaps with neighboring blocks in other processes and (2) a dynamically determined k-d tree leaf node that bounds the active particles for computation; the bounds of the k-d tree nodes are constrained by the geometries of data blocks. Given a certain degree of overlap between blocks, our method can balance the number of particles as much as possible. Compared with other load-balancing algorithms for parallel particle tracing, the proposed method does not require any preanalysis, does not use any heuristics based on flow features, does not make any assumptions about seed distribution, does not move any data blocks during the run, and does not need any master process for work redistribution. Based on a comprehensive performance study up to 8K processes on a Blue Gene/Q system, the proposed algorithm outperforms baseline approaches in both load balance and scalability on various flow visualization and analysis problems.",
            "url": "http://dx.doi.org/10.1109/TVCG.2017.2744059",
            "id": "r_85",
            "s_ids": [
                "s_108",
                "s_136",
                "s_635",
                "s_434",
                "s_9"
            ],
            "type": "rich",
            "x": 8.956114768981934,
            "y": 7.606325626373291
        },
        {
            "title": "Robust Detection and Visualization of Jet-Stream Core Lines in Atmospheric Flow",
            "data": "Jet-streams, their core lines and their role in atmospheric dynamics have been subject to considerable meteorological research since the first half of the twentieth century. Yet, until today no consistent automated feature detection approach has been proposed to identify jet-stream core lines from 3D wind fields. Such 3D core lines can facilitate meteorological analyses previously not possible. Although jet-stream cores can be manually analyzed by meteorologists in 2D as height ridges in the wind speed field, to the best of our knowledge no automated ridge detection approach has been applied to jet-stream core detection. In this work, we -a team of visualization scientists and meteorologists-propose a method that exploits directional information in the wind field to extract core lines in a robust and numerically less involved manner than traditional 3D ridge detection. For the first time, we apply the extracted 3D core lines to meteorological analysis, considering real-world case studies and demonstrating our method's benefits for weather forecasting and meteorological research.",
            "url": "http://dx.doi.org/10.1109/TVCG.2017.2743989",
            "id": "r_86",
            "s_ids": [
                "s_659",
                "s_36",
                "s_641",
                "s_102",
                "s_595"
            ],
            "type": "rich",
            "x": 7.75087833404541,
            "y": 5.101170539855957
        },
        {
            "title": "Combined Visualization of Wall Thickness and Wall Shear Stress for the Evaluation of Aneurysms",
            "data": "For an individual rupture risk assessment of aneurysms, the aneurysm's wall morphology and hemodynamics provide valuable information. Hemodynamic information is usually extracted via computational fluid dynamic (CFD) simulation on a previously extracted 3D aneurysm surface mesh or directly measured with 4D phase-contrast magnetic resonance imaging. In contrast, a noninvasive imaging technique that depicts the aneurysm wall in vivo is still not available. Our approach comprises an experiment, where intravascular ultrasound (IVUS) is employed to probe a dissected saccular aneurysm phantom, which we modeled from a porcine kidney artery. Then, we extracted a 3D surface mesh to gain the vessel wall thickness and hemodynamic information from a CFD simulation. Building on this, we developed a framework that depicts the inner and outer aneurysm wall with dedicated information about local thickness via distance ribbons. For both walls, a shading is adapted such that the inner wall as well as its distance to the outer wall is always perceivable. The exploration of the wall is further improved by combining it with hemodynamic information from the CFD simulation. Hence, the visual analysis comprises a brushing and linking concept for individual highlighting of pathologic areas. Also, a surface clustering is integrated to provide an automatic division of different aneurysm parts combined with a risk score depending on wall thickness and hemodynamic information. In general, our approach can be employed for vessel visualization purposes where an inner and outer wall has to be adequately represented.",
            "url": "http://dx.doi.org/10.1109/TVCG.2014.2346406",
            "id": "r_87",
            "s_ids": [
                "s_124",
                "s_658",
                "s_666",
                "s_239",
                "s_585"
            ],
            "type": "rich",
            "x": 7.339260101318359,
            "y": 4.169096946716309
        },
        {
            "title": "Interactive Progressive Visualization with Space-Time Error Control",
            "data": "We present a novel scheme for progressive rendering in interactive visualization. Static settings with respect to a certain image quality or frame rate are inherently incapable of delivering both high frame rates for rapid changes and high image quality for detailed investigation. Our novel technique flexibly adapts by steering the visualization process in three major degrees of freedom: when to terminate the refinement of a frame in the background and start a new one, when to display a frame currently computed, and how much resources to consume. We base these decisions on the correlation of the errors due to insufficient sampling and response delay, which we estimate separately using fast yet expressive heuristics. To automate the configuration of the steering behavior, we employ offline video quality analysis. We provide an efficient implementation of our scheme for the application of volume raycasting, featuring integrated GPU-accelerated image reconstruction and error estimation. Our implementation performs an integral handling of the changes due to camera transforms, transfer function adaptations, as well as the progression of the data to in time. Finally, the overall technique is evaluated with an expert study.",
            "url": "http://dx.doi.org/10.1109/TVCG.2014.2346319",
            "id": "r_88",
            "s_ids": [
                "s_240",
                "s_641",
                "s_647",
                "s_277"
            ],
            "type": "rich",
            "x": 10.107250213623047,
            "y": 3.699244499206543
        },
        {
            "title": "Visualization of Temporal Similarity in field Data",
            "data": "This paper presents a visualization approach for detecting and exploring similarity in the temporal variation of field data. We provide an interactive technique for extracting correlations from similarity matrices which capture temporal similarity of univariate functions. We make use of the concept to extract periodic and quasiperiodic behavior at single (spatial) points as well as similarity between different locations within a field and also between different data sets. The obtained correlations are utilized for visual exploration of both temporal and spatial relationships in terms of temporal similarity. Our entire pipeline offers visual interaction and inspection, allowing for the flexibility that in particular time-dependent data analysis techniques require. We demonstrate the utility and versatility of our approach by applying our implementation to data from both simulation and measurement.",
            "url": "http://dx.doi.org/10.1109/TVCG.2012.284",
            "id": "r_89",
            "s_ids": [
                "s_240",
                "s_641",
                "s_277"
            ],
            "type": "rich",
            "x": 10.367928504943848,
            "y": 6.416464805603027
        },
        {
            "title": "Automatic Detection and Visualization of Qualitative Hemodynamic Characteristics in Cerebral Aneurysms",
            "data": "Cerebral aneurysms are a pathological vessel dilatation that bear a high risk of rupture. For the understanding and evaluation of the risk of rupture, the analysis of hemodynamic information plays an important role. Besides quantitative hemodynamic information, also qualitative flow characteristics, e.g., the inflow jet and impingement zone are correlated with the risk of rupture. However, the assessment of these two characteristics is currently based on an interactive visual investigation of the flow field, obtained by computational fluid dynamics (CFD) or blood flow measurements. We present an automatic and robust detection as well as an expressive visualization of these characteristics. The detection can be used to support a comparison, e.g., of simulation results reflecting different treatment options. Our approach utilizes local streamline properties to formalize the inflow jet and impingement zone. We extract a characteristic seeding curve on the ostium, on which an inflow jet boundary contour is constructed. Based on this boundary contour we identify the impingement zone. Furthermore, we present several visualization techniques to depict both characteristics expressively. Thereby, we consider accuracy and robustness of the extracted characteristics, minimal visual clutter and occlusions. An evaluation with six domain experts confirms that our approach detects both hemodynamic characteristics reasonably.",
            "url": "http://dx.doi.org/10.1109/TVCG.2012.202",
            "id": "r_90",
            "s_ids": [
                "s_290",
                "s_112",
                "s_563",
                "s_559",
                "s_224",
                "s_372",
                "s_653",
                "s_585"
            ],
            "type": "rich",
            "x": 7.511942386627197,
            "y": 4.444129943847656
        },
        {
            "title": "PelVis: Atlas-based Surgical Planning for Oncological Pelvic Surgery",
            "data": "Due to the intricate relationship between the pelvic organs and vital structures, such as vessels and nerves, pelvic anatomy is often considered to be complex to comprehend. In oncological pelvic surgery, a trade-off has to be made between complete tumor resection and preserving function by preventing damage to the nerves. Damage to the autonomic nerves causes undesirable post-operative side-effects such as fecal and urinal incontinence, as well as sexual dysfunction in up to 80 percent of the cases. Since these autonomic nerves are not visible in pre-operative MRI scans or during surgery, avoiding nerve damage during such a surgical procedure becomes challenging. In this work, we present visualization methods to represent context, target, and risk structures for surgical planning. We employ distance-based and occlusion management techniques in an atlas-based surgical planning tool for oncological pelvic surgery. Patient-specific pre-operative MRI scans are registered to an atlas model that includes nerve information. Through several interactive linked views, the spatial relationships and distances between the organs, tumor and risk zones are visualized to improve understanding, while avoiding occlusion. In this way, the surgeon can examine surgically relevant structures and plan the procedure before going into the operating theater, thus raising awareness of the autonomic nerve zone regions and potentially reducing post-operative complications. Furthermore, we present the results of a domain expert evaluation with surgical oncologists that demonstrates the advantages of our approach.",
            "url": "http://dx.doi.org/10.1109/TVCG.2016.2598826",
            "id": "r_91",
            "s_ids": [
                "s_633",
                "s_658",
                "s_307",
                "s_12",
                "s_349",
                "s_162",
                "s_134",
                "s_372"
            ],
            "type": "rich",
            "x": 7.703056812286377,
            "y": 3.7510366439819336
        },
        {
            "title": "Fast and Memory-Efficienty Topological Denoising of 2D and 3D Scalar Fields",
            "data": "Data acquisition, numerical inaccuracies, and sampling often introduce noise in measurements and simulations. Removing this noise is often necessary for efficient analysis and visualization of this data, yet many denoising techniques change the minima and maxima of a scalar field. For example, the extrema can appear or disappear, spatially move, and change their value. This can lead to wrong interpretations of the data, e.g., when the maximum temperature over an area is falsely reported being a few degrees cooler because the denoising method is unaware of these features. Recently, a topological denoising technique based on a global energy optimization was proposed, which allows the topology-controlled denoising of 2D scalar fields. While this method preserves the minima and maxima, it is constrained by the size of the data. We extend this work to large 2D data and medium-sized 3D data by introducing a novel domain decomposition approach. It allows processing small patches of the domain independently while still avoiding the introduction of new critical points. Furthermore, we propose an iterative refinement of the solution, which decreases the optimization energy compared to the previous approach and therefore gives smoother results that are closer to the input. We illustrate our technique on synthetic and real-world 2D and 3D data sets that highlight potential applications.",
            "url": "http://dx.doi.org/10.1109/TVCG.2014.2346432",
            "id": "r_92",
            "s_ids": [
                "s_254",
                "s_631",
                "s_32",
                "s_406",
                "s_354",
                "s_19"
            ],
            "type": "rich",
            "x": 9.439054489135742,
            "y": 6.879550457000732
        },
        {
            "title": "Sparse PDF Volumes for Consistent Multi-Resolution Volume Rendering",
            "data": "This paper presents a new multi-resolution volume representation called sparse pdf volumes, which enables consistent multi-resolution volume rendering based on probability density functions (pdfs) of voxel neighborhoods. These pdfs are defined in the 4D domain jointly comprising the 3D volume and its 1D intensity range. Crucially, the computation of sparse pdf volumes exploits data coherence in 4D, resulting in a sparse representation with surprisingly low storage requirements. At run time, we dynamically apply transfer functions to the pdfs using simple and fast convolutions. Whereas standard low-pass filtering and down-sampling incur visible differences between resolution levels, the use of pdfs facilitates consistent results independent of the resolution level used. We describe the efficient out-of-core computation of large-scale sparse pdf volumes, using a novel iterative simplification procedure of a mixture of 4D Gaussians. Finally, our data structure is optimized to facilitate interactive multi-resolution volume rendering on GPUs.",
            "url": "http://dx.doi.org/10.1109/TVCG.2014.2346324",
            "id": "r_93",
            "s_ids": [
                "s_256",
                "s_427",
                "s_636",
                "s_300"
            ],
            "type": "rich",
            "x": 9.664959907531738,
            "y": 4.724928855895996
        },
        {
            "title": "ViSlang: A System for Interpreted Domain-Specific Languages for Scientific Visualization",
            "data": "Researchers from many domains use scientific visualization in their daily practice. Existing implementations of algorithms usually come with a graphical user interface (high-level interface), or as software library or source code (low-level interface). In this paper we present a system that integrates domain-specific languages (DSLs) and facilitates the creation of new DSLs. DSLs provide an effective interface for domain scientists avoiding the difficulties involved with low-level interfaces and at the same time offering more flexibility than high-level interfaces. We describe the design and implementation of ViSlang, an interpreted language specifically tailored for scientific visualization. A major contribution of our design is the extensibility of the ViSlang language. Novel DSLs that are tailored to the problems of the domain can be created and integrated into ViSlang. We show that our approach can be added to existing user interfaces to increase the flexibility for expert users on demand, but at the same time does not interfere with the user experience of novice users. To demonstrate the flexibility of our approach we present new DSLs for volume processing, querying and visualization. We report the implementation effort for new DSLs and compare our approach with Matlab and Python implementations in terms of run-time performance.",
            "url": "http://dx.doi.org/10.1109/TVCG.2014.2346318",
            "id": "r_94",
            "s_ids": [
                "s_145",
                "s_162",
                "s_474",
                "s_300"
            ],
            "type": "rich",
            "x": 11.3491849899292,
            "y": 4.6426191329956055
        },
        {
            "title": "Visual Verification of Space Weather Ensemble Simulations",
            "data": "We propose a system to analyze and contextualize simulations of coronal mass ejections. As current simulation techniques require manual input, uncertainty is introduced into the simulation pipeline leading to inaccurate predictions that can be mitigated through ensemble simulations. We provide the space weather analyst with a multi-view system providing visualizations to: 1. compare ensemble members against ground truth measurements, 2. inspect time-dependent information derived from optical flow analysis of satellite images, and 3. combine satellite images with a volumetric rendering of the simulations. This three-tier workflow provides experts with tools to discover correlations between errors in predictions and simulation parameters, thus increasing knowledge about the evolution and propagation of coronal mass ejections that pose a danger to Earth and interplanetary travel.",
            "url": "http://dx.doi.org/10.1109/SciVis.2015.7429487",
            "id": "r_95",
            "s_ids": [
                "s_457",
                "s_399",
                "s_169",
                "s_403",
                "s_183",
                "s_244"
            ],
            "type": "rich",
            "x": 11.090789794921875,
            "y": 6.104916572570801
        },
        {
            "title": "Details-First, Show Context, Overview Last: Supporting Exploration of Viscous Fingers in Large-Scale Ensemble Simulations",
            "data": "Visualization research often seeks designs that first establish an overview of the data, in accordance to the information seeking mantra: \u201cOverview first, zoom and filter, then details on demand\u201d. However, in computational fluid dynamics (CFD), as well as in other domains, there are many situations where such a spatial overview is not relevant or practical for users, for example when the experts already have a good mental overview of the data, or when an analysis of a large overall structure may not be related to the specific, information-driven tasks of users. Using scientific workflow theory and, as a vehicle, the problem of viscous finger evolution, we advocate an alternative model that allows domain experts to explore features of interest first, then explore the context around those features, and finally move to a potentially unfamiliar summarization overview. In a model instantiation, we show how a computational back-end can identify and track over time low-level, small features, then be used to filter the context of those features while controlling the complexity of the visualization, and finally to summarize and compare simulations. We demonstrate the effectiveness of this approach with an online web-based exploration of a total volume of data approaching half a billion seven-dimensional data points, and report supportive feedback provided by domain experts with respect to both the instantiation and the theoretical model.",
            "url": "http://dx.doi.org/10.1109/TVCG.2018.2864849",
            "id": "r_96",
            "s_ids": [
                "s_312",
                "s_276",
                "s_615",
                "s_133",
                "s_410"
            ],
            "type": "rich",
            "x": 11.634987831115723,
            "y": 4.945385932922363
        },
        {
            "title": "Low-Pass Filtered Volumetric Shadows",
            "data": "We present a novel and efficient method to compute volumetric soft shadows for interactive direct volume visualization to improve the perception of spatial depth. By direct control of the softness of volumetric shadows, disturbing visual patterns due to hard shadows can be avoided and users can adapt the illumination to their personal and application-specific requirements. We compute the shadowing of a point in the data set by employing spatial filtering of the optical depth over a finite area patch pointing toward each light source. Conceptually, the area patch spans a volumetric region that is sampled with shadow rays; afterward, the resulting optical depth values are convolved with a low-pass filter on the patch. In the numerical computation, however, to avoid expensive shadow ray marching, we show how to align and set up summed area tables for both directional and point light sources. Once computed, the summed area tables enable efficient evaluation of soft shadows for each point in constant time without shadow ray marching and the softness of the shadows can be controlled interactively. We integrated our method in a GPU-based volume renderer with ray casting from the camera, which offers interactive control of the transfer function, light source positions, and viewpoint, for both static and time-dependent data sets. Our results demonstrate the benefit of soft shadows for visualization to achieve user-controlled illumination with many-point lighting setups for improved perception combined with high rendering speed.",
            "url": "http://dx.doi.org/10.1109/TVCG.2014.2346333",
            "id": "r_97",
            "s_ids": [
                "s_147",
                "s_641",
                "s_411",
                "s_130"
            ],
            "type": "rich",
            "x": 9.4810152053833,
            "y": 4.279471397399902
        },
        {
            "title": "Detecting Symmetry in Scalar fields Using Augmented Extremum Graphs",
            "data": "Visualizing symmetric patterns in the data often helps the domain scientists make important observations and gain insights about the underlying experiment. Detecting symmetry in scalar fields is a nascent area of research and existing methods that detect symmetry are either not robust in the presence of noise or computationally costly. We propose a data structure called the augmented extremum graph and use it to design a novel symmetry detection method based on robust estimation of distances. The augmented extremum graph captures both topological and geometric information of the scalar field and enables robust and computationally efficient detection of symmetry. We apply the proposed method to detect symmetries in cryo-electron microscopy datasets and the experiments demonstrate that the algorithm is capable of detecting symmetry even in the presence of significant noise. We describe novel applications that use the detected symmetry to enhance visualization of scalar field data and facilitate their exploration.",
            "url": "http://dx.doi.org/10.1109/TVCG.2013.148",
            "id": "r_98",
            "s_ids": [
                "s_385",
                "s_629"
            ],
            "type": "rich",
            "x": 9.046568870544434,
            "y": 6.608144283294678
        },
        {
            "title": "CPU Ray Tracing Large Particle Data with Balanced P-k-d Trees",
            "data": "We present a novel approach to rendering large particle data sets from molecular dynamics, astrophysics and other sources. We employ a new data structure adapted from the original balanced k-d tree, which allows for representation of data with trivial or no overhead. In the OSPRay visualization framework, we have developed an efficient CPU algorithm for traversing, classifying and ray tracing these data. Our approach is able to render up to billions of particles on a typical workstation, purely on the CPU, without any approximations or level-of-detail techniques, and optionally with attribute-based color mapping, dynamic range query, and advanced lighting models such as ambient occlusion and path tracing.",
            "url": "http://dx.doi.org/10.1109/SciVis.2015.7429492",
            "id": "r_99",
            "s_ids": [
                "s_632",
                "s_665",
                "s_243",
                "s_576",
                "s_273",
                "s_617"
            ],
            "type": "rich",
            "x": 10.12158203125,
            "y": 5.155786514282227
        },
        {
            "title": "Tensor Field Visualization using Fiber Surfaces of Invariant Space",
            "data": "Scientific visualization developed successful methods for scalar and vector fields. For tensor fields, however, effective, interactive visualizations are still missing despite progress over the last decades. We present a general approach for the generation of separating surfaces in symmetric, second-order, three-dimensional tensor fields. These surfaces are defined as fiber surfaces of the invariant space, i.e. as pre-images of surfaces in the range of a complete set of invariants. This approach leads to a generalization of the fiber surface algorithm by Klacansky et al. [16] to three dimensions in the range. This is due to the fact that the invariant space is three-dimensional for symmetric second-order tensors over a spatial domain. We present an algorithm for surface construction for simplicial grids in the domain and simplicial surfaces in the invariant space. We demonstrate our approach by applying it to stress fields from component design in mechanical engineering.",
            "url": "http://dx.doi.org/10.1109/TVCG.2018.2864846",
            "id": "r_100",
            "s_ids": [
                "s_522",
                "s_131",
                "s_590",
                "s_96",
                "s_353",
                "s_213",
                "s_293",
                "s_116"
            ],
            "type": "rich",
            "x": 8.4170560836792,
            "y": 6.109373569488525
        },
        {
            "title": "Multiscale Visualization and Scale-Adaptive Modification of DNA Nanostructures",
            "data": "We present an approach to represent DNA nanostructures in varying forms of semantic abstraction, describe ways to smoothly transition between them, and thus create a continuous multiscale visualization and interaction space for applications in DNA nanotechnology. This new way of observing, interacting with, and creating DNA nanostructures enables domain experts to approach their work in any of the semantic abstraction levels, supporting both low-level manipulations and high-level visualization and modifications. Our approach allows them to deal with the increasingly complex DNA objects that they are designing, to improve their features, and to add novel functions in a way that no existing single-scale approach offers today. For this purpose we collaborated with DNA nanotechnology experts to design a set of ten semantic scales. These scales take the DNA's chemical and structural behavior into account and depict it from atoms to the targeted architecture with increasing levels of abstraction. To create coherence between the discrete scales, we seamlessly transition between them in a well-defined manner. We use special encodings to allow experts to estimate the nanoscale object's stability. We also add scale-adaptive interactions that facilitate the intuitive modification of complex structures at multiple scales. We demonstrate the applicability of our approach on an experimental use case. Moreover, feedback from our collaborating domain experts confirmed an increased time efficiency and certainty for analysis and modification tasks on complex DNA structures. Our method thus offers exciting new opportunities with promising applications in medicine and biotechnology.",
            "url": "http://dx.doi.org/10.1109/TVCG.2017.2743981",
            "id": "r_101",
            "s_ids": [
                "s_280",
                "s_218",
                "s_477",
                "s_531",
                "s_160",
                "s_429",
                "s_474",
                "s_360",
                "s_395"
            ],
            "type": "rich",
            "x": 11.893961906433105,
            "y": 3.4554388523101807
        },
        {
            "title": "Interstitial and Interlayer Ion Diffusion Geometry Extraction in Graphitic Nanosphere Battery Materials",
            "data": "Large-scale molecular dynamics (MD) simulations are commonly used for simulating the synthesis and ion diffusion of battery materials. A good battery anode material is determined by its capacity to store ion or other diffusers. However, modeling of ion diffusion dynamics and transport properties at large length and long time scales would be impossible with current MD codes. To analyze the fundamental properties of these materials, therefore, we turn to geometric and topological analysis of their structure. In this paper, we apply a novel technique inspired by discrete Morse theory to the Delaunay triangulation of the simulated geometry of a thermally annealed carbon nanosphere. We utilize our computed structures to drive further geometric analysis to extract the interstitial diffusion structure as a single mesh. Our results provide a new approach to analyze the geometry of the simulated carbon nanosphere, and new insights into the role of carbon defect size and distribution in determining the charge capacity and charge dynamics of these carbon based battery materials.",
            "url": "http://dx.doi.org/10.1109/TVCG.2015.2467432",
            "id": "r_102",
            "s_ids": [
                "s_660",
                "s_665",
                "s_551",
                "s_3",
                "s_392",
                "s_617",
                "s_582",
                "s_273"
            ],
            "type": "rich",
            "x": 9.303056716918945,
            "y": 5.133116722106934
        },
        {
            "title": "Advection-Based Sparse Data Management for Visualizing Unsteady Flow",
            "data": "When computing integral curves and integral surfaces for large-scale unsteady flow fields, a major bottleneck is the widening gap between data access demands and the available bandwidth (both I/O and in-memory). In this work, we explore a novel advection-based scheme to manage flow field data for both efficiency and scalability. The key is to first partition flow field into blocklets (e.g. cells or very fine-grained blocks of cells), and then (pre)fetch and manage blocklets on-demand using a parallel key-value store. The benefits are (1) greatly increasing the scale of local-range analysis (e.g. source-destination queries, streak surface generation) that can fit within any given limit of hardware resources; (2) improving memory and I/O bandwidth-efficiencies as well as the scalability of naive task-parallel particle advection. We demonstrate our method using a prototype system that works on workstation and also in supercomputing environments. Results show significantly reduced I/O overhead compared to accessing raw flow data, and also high scalability on a supercomputer for a variety of applications.",
            "url": "http://dx.doi.org/10.1109/TVCG.2014.2346418",
            "id": "r_103",
            "s_ids": [
                "s_136",
                "s_108",
                "s_78",
                "s_644",
                "s_434",
                "s_364",
                "s_279",
                "s_137"
            ],
            "type": "rich",
            "x": 9.022489547729492,
            "y": 7.699234962463379
        },
        {
            "title": "MObjects--A Novel Method for the Visualization and Interactive Exploration of Defects in Industrial XCT Data",
            "data": "This paper describes an advanced visualization method for the analysis of defects in industrial 3D X-Ray Computed Tomography (XCT) data. We present a novel way to explore a high number of individual objects in a dataset, e.g., pores, inclusions, particles, fibers, and cracks demonstrated on the special application area of pore extraction in carbon fiber reinforced polymers (CFRP). After calculating the individual object properties volume, dimensions and shape factors, all objects are clustered into a mean object (MObject). The resulting MObject parameter space can be explored interactively. To do so, we introduce the visualization of mean object sets (MObject Sets) in a radial and a parallel arrangement. Each MObject may be split up into sub-classes by selecting a specific property, e.g., volume or shape factor, and the desired number of classes. Applying this interactive selection iteratively leads to the intended classifications and visualizations of MObjects along the selected analysis path. Hereby the given different scaling factors of the MObjects down the analysis path are visualized through a visual linking approach. Furthermore the representative MObjects are exported as volumetric datasets to serve as input for successive calculations and simulations. In the field of porosity determination in CFRP non-destructive testing practitioners use representative MObjects to improve ultrasonic calibration curves. Representative pores also serve as input for heat conduction simulations in active thermography. For a fast overview of the pore properties in a dataset we propose a local MObjects visualization in combination with a color-coded homogeneity visualization of cells. The advantages of our novel approach are demonstrated using real world CFRP specimens. The results were evaluated through a questionnaire in order to determine the practicality of the MObjects visualization as a supportive tool for domain specialists.",
            "url": "http://dx.doi.org/10.1109/TVCG.2013.177",
            "id": "r_104",
            "s_ids": [
                "s_455",
                "s_166",
                "s_115",
                "s_474",
                "s_18"
            ],
            "type": "rich",
            "x": 9.392159461975098,
            "y": 5.024239540100098
        },
        {
            "title": "GRACE: A Visual Comparison Framework for Integrated Spatial and Non-Spatial Geriatric Data",
            "data": "We present the design of a novel framework for the visual integration, comparison, and exploration of correlations in spatial and non-spatial geriatric research data. These data are in general high-dimensional and span both the spatial, volumetric domain - through magnetic resonance imaging volumes - and the non-spatial domain, through variables such as age, gender, or walking speed. The visual analysis framework blends medical imaging, mathematical analysis and interactive visualization techniques, and includes the adaptation of Sparse Partial Least Squares and iterated Tikhonov Regularization algorithms to quantify potential neurologymobility connections. A linked-view design geared specifically at interactive visual comparison integrates spatial and abstract visual representations to enable the users to effectively generate and refine hypotheses in a large, multidimensional, and fragmented space. In addition to the domain analysis and design description, we demonstrate the usefulness of this approach on two case studies. Last, we report the lessons learned through the iterative design and evaluation of our approach, in particular those relevant to the design of comparative visualization of spatial and non-spatial data.",
            "url": "http://dx.doi.org/10.1109/TVCG.2013.161",
            "id": "r_105",
            "s_ids": [
                "s_262",
                "s_203",
                "s_440",
                "s_547",
                "s_541",
                "s_465",
                "s_348",
                "s_410"
            ],
            "type": "rich",
            "x": 11.083663940429688,
            "y": 5.193977355957031
        },
        {
            "title": "Interactive 3D Visual Analysis of Atmospheric Fronts",
            "data": "Atmospheric fronts play a central role in meteorology, as the boundaries between different air masses and as fundamental features of extra-tropical cyclones. They appear in numerous conceptual model depictions of extra-tropical weather systems. Conceptually, fronts are three-dimensional surfaces in space possessing an innate structural complexity, yet in meteorology, both manual and objective identification and depiction have historically focused on the structure in two dimensions. In this work, we -a team of visualization scientists and meteorologists-propose a novel visualization approach to analyze the three-dimensional structure of atmospheric fronts and related physical and dynamical processes. We build upon existing approaches to objectively identify fronts as lines in two dimensions and extend these to obtain frontal surfaces in three dimensions, using the magnitude of temperature change along the gradient of a moist potential temperature field as the primary identifying factor. We introduce the use of normal curves in the temperature gradient field to visualize a frontal zone (i.e., the transitional zone between the air masses) and the distribution of atmospheric variables in such zones. To enable for the first time a statistical analysis of frontal zones, we present a new approach to obtain the volume enclosed by a zone, by classifying grid boxes that intersect with normal curves emanating from a selected front. We introduce our method by means of an idealized numerical simulation and demonstrate its use with two real-world cases using numerical weather prediction data.",
            "url": "http://dx.doi.org/10.1109/TVCG.2018.2864806",
            "id": "r_106",
            "s_ids": [
                "s_659",
                "s_36",
                "s_45",
                "s_102",
                "s_595"
            ],
            "type": "rich",
            "x": 10.636197090148926,
            "y": 5.775693893432617
        },
        {
            "title": "Dynamic Volume Lines: Visual Comparison of 3D Volumes through Space-filling Curves",
            "data": "The comparison of many members of an ensemble is difficult, tedious, and error-prone, which is aggravated by often just subtle differences. In this paper, we introduce Dynamic Volume Lines for the interactive visual analysis and comparison of sets of 3D volumes. Each volume is linearized along a Hilbert space-filling curve into a 1D Hilbert line plot, which depicts the intensities over the Hilbert indices. We present a nonlinear scaling of these 1D Hilbert line plots based on the intensity variations in the ensemble of 3D volumes, which enables a more effective use of the available screen space. The nonlinear scaling builds the basis for our interactive visualization techniques. An interactive histogram heatmap of the intensity frequencies serves as overview visualization. When zooming in, the frequencies are replaced by detailed 1D Hilbert line plots and optional functional boxplots. To focus on important regions of the volume ensemble, nonlinear scaling is incorporated into the plots. An interactive scaling widget depicts the local ensemble variations. Our brushing and linking interface reveals, for example, regions with a high ensemble variation by showing the affected voxels in a 3D spatial view. We show the applicability of our concepts using two case studies on ensembles of 3D volumes resulting from tomographic reconstruction. In the first case study, we evaluate an artificial specimen from simulated industrial 3D X-ray computed tomography (XCT). In the second case study, a real-world XCT foam specimen is investigated. Our results show that Dynamic Volume Lines can identify regions with high local intensity variations, allowing the user to draw conclusions, for example, about the choice of reconstruction parameters. Furthermore, it is possible to detect ring artifacts in reconstructions volumes.",
            "url": "http://dx.doi.org/10.1109/TVCG.2018.2864510",
            "id": "r_107",
            "s_ids": [
                "s_552",
                "s_407",
                "s_474",
                "s_115",
                "s_18"
            ],
            "type": "rich",
            "x": 9.871879577636719,
            "y": 4.899824142456055
        },
        {
            "title": "AnimoAminoMiner: Exploration of Protein Tunnels and their Properties in Molecular Dynamics",
            "data": "In this paper we propose a novel method for the interactive exploration of protein tunnels. The basic principle of our approach is that we entirely abstract from the 3D/4D space the simulated phenomenon is embedded in. A complex 3D structure and its curvature information is represented only by a straightened tunnel centerline and its width profile. This representation focuses on a key aspect of the studied geometry and frees up graphical estate to key chemical and physical properties represented by surrounding amino acids. The method shows the detailed tunnel profile and its temporal aggregation. The profile is interactively linked with a visual overview of all amino acids which are lining the tunnel over time. In this overview, each amino acid is represented by a set of colored lines depicting the spatial and temporal impact of the amino acid on the corresponding tunnel. This representation clearly shows the importance of amino acids with respect to selected criteria. It helps the biochemists to select the candidate amino acids for mutation which changes the protein function in a desired way. The AnimoAminoMiner was designed in close cooperation with domain experts. Its usefulness is documented by their feedback and a case study, which are included.",
            "url": "http://dx.doi.org/10.1109/TVCG.2015.2467434",
            "id": "r_108",
            "s_ids": [
                "s_141",
                "s_671",
                "s_474",
                "s_395",
                "s_448"
            ],
            "type": "rich",
            "x": 12.044694900512695,
            "y": 3.302705764770508
        },
        {
            "title": "Visualization-by-Sketching: An Artist's Interface for Creating Multivariate Time-Varying Data Visualizations",
            "data": "We present Visualization-by-Sketching, a direct-manipulation user interface for designing new data visualizations. The goals are twofold: First, make the process of creating real, animated, data-driven visualizations of complex information more accessible to artists, graphic designers, and other visual experts with traditional, non-technical training. Second, support and enhance the role of human creativity in visualization design, enabling visual experimentation and workflows similar to what is possible with traditional artistic media. The approach is to conceive of visualization design as a combination of processes that are already closely linked with visual creativity: sketching, digital painting, image editing, and reacting to exemplars. Rather than studying and tweaking low-level algorithms and their parameters, designers create new visualizations by painting directly on top of a digital data canvas, sketching data glyphs, and arranging and blending together multiple layers of animated 2D graphics. This requires new algorithms and techniques to interpret painterly user input relative to data \u201cunder\u201d the canvas, balance artistic freedom with the need to produce accurate data visualizations, and interactively explore large (e.g., terabyte-sized) multivariate datasets. Results demonstrate a variety of multivariate data visualization techniques can be rapidly recreated using the interface. More importantly, results and feedback from artists support the potential for interfaces in this style to attract new, creative users to the challenging task of designing more effective data visualizations and to help these users stay \u201cin the creative zone\u201d as they work.",
            "url": "http://dx.doi.org/10.1109/TVCG.2015.2467153",
            "id": "r_109",
            "s_ids": [
                "s_655",
                "s_421"
            ],
            "type": "rich",
            "x": 11.176615715026855,
            "y": 4.365100383758545
        },
        {
            "title": "Trajectory-Based Flow Feature Tracking in Joint Particle/Volume Datasets",
            "data": "Studying the dynamic evolution of time-varying volumetric data is essential in countless scientific endeavors. The ability to isolate and track features of interest allows domain scientists to better manage large complex datasets both in terms of visual understanding and computational efficiency. This work presents a new trajectory-based feature tracking technique for use in joint particle/volume datasets. While traditional feature tracking approaches generally require a high temporal resolution, this method utilizes the indexed trajectories of corresponding Lagrangian particle data to efficiently track features over large jumps in time. Such a technique is especially useful for situations where the volume dataset is either temporally sparse or too large to efficiently track a feature through all intermediate timesteps. In addition, this paper presents a few other applications of this approach, such as the ability to efficiently track the internal properties of volumetric features using variables from the particle data. We demonstrate the effectiveness of this technique using real world combustion and atmospheric datasets and compare it to existing tracking methods to justify its advantages and accuracy.",
            "url": "http://dx.doi.org/10.1109/TVCG.2014.2346423",
            "id": "r_110",
            "s_ids": [
                "s_423",
                "s_151",
                "s_647"
            ],
            "type": "rich",
            "x": 9.947415351867676,
            "y": 6.188593864440918
        },
        {
            "title": "Characterizing and Visualizing Predictive Uncertainty in Numerical Ensembles Through Bayesian Model Averaging",
            "data": "Numerical ensemble forecasting is a powerful tool that drives many risk analysis efforts and decision making tasks. These ensembles are composed of individual simulations that each uniquely model a possible outcome for a common event of interest: e.g., the direction and force of a hurricane, or the path of travel and mortality rate of a pandemic. This paper presents a new visual strategy to help quantify and characterize a numerical ensemble's predictive uncertainty: i.e., the ability for ensemble constituents to accurately and consistently predict an event of interest based on ground truth observations. Our strategy employs a Bayesian framework to first construct a statistical aggregate from the ensemble. We extend the information obtained from the aggregate with a visualization strategy that characterizes predictive uncertainty at two levels: at a global level, which assesses the ensemble as a whole, as well as a local level, which examines each of the ensemble's constituents. Through this approach, modelers are able to better assess the predictive strengths and weaknesses of the ensemble as a whole, as well as individual models. We apply our method to two datasets to demonstrate its broad applicability.",
            "url": "http://dx.doi.org/10.1109/TVCG.2013.138",
            "id": "r_111",
            "s_ids": [
                "s_199",
                "s_587",
                "s_623",
                "s_646",
                "s_291",
                "s_405",
                "s_332"
            ],
            "type": "rich",
            "x": 11.165047645568848,
            "y": 6.473668575286865
        },
        {
            "title": "Interactive Visualization of 3D Histopathology in Native Resolution",
            "data": "We present a visualization application that enables effective interactive visual analysis of large-scale 3D histopathology, that is, high-resolution 3D microscopy data of human tissue. Clinical work flows and research based on pathology have, until now, largely been dominated by 2D imaging. As we will show in the paper, studying volumetric histology data will open up novel and useful opportunities for both research and clinical practice. Our starting point is the current lack of appropriate visualization tools in histopathology, which has been a limiting factor in the uptake of digital pathology. Visualization of 3D histology data does pose difficult challenges in several aspects. The full-color datasets are dense and large in scale, on the order of 100,000 \u00d7 100,000 \u00d7 100 voxels. This entails serious demands on both rendering performance and user experience design. Despite this, our developed application supports interactive study of 3D histology datasets at native resolution. Our application is based on tailoring and tuning of existing methods, system integration work, as well as a careful study of domain specific demands emanating from a close participatory design process with domain experts as team members. Results from a user evaluation employing the tool demonstrate a strong agreement among the 14 participating pathologists that 3D histopathology will be a valuable and enabling tool for their work.",
            "url": "http://dx.doi.org/10.1109/TVCG.2018.2864816",
            "id": "r_112",
            "s_ids": [
                "s_546",
                "s_244",
                "s_674",
                "s_206"
            ],
            "type": "rich",
            "x": 8.00589370727539,
            "y": 3.8334102630615234
        },
        {
            "title": "FLDA: Latent Dirichlet Allocation Based Unsteady Flow Analysis",
            "data": "In this paper, we present a novel feature extraction approach called FLDA for unsteady flow fields based on Latent Dirichlet allocation (LDA) model. Analogous to topic modeling in text analysis, in our approach, pathlines and features in a given flow field are defined as documents and words respectively. Flow topics are then extracted based on Latent Dirichlet allocation. Different from other feature extraction methods, our approach clusters pathlines with probabilistic assignment, and aggregates features to meaningful topics at the same time. We build a prototype system to support exploration of unsteady flow field with our proposed LDA-based method. Interactive techniques are also developed to explore the extracted topics and to gain insight from the data. We conduct case studies to demonstrate the effectiveness of our proposed approach.",
            "url": "http://dx.doi.org/10.1109/TVCG.2014.2346416",
            "id": "r_113",
            "s_ids": [
                "s_635",
                "s_386",
                "s_136",
                "s_517",
                "s_434",
                "s_144"
            ],
            "type": "rich",
            "x": 7.633826732635498,
            "y": 4.75159215927124
        },
        {
            "title": "Efficient and Flexible Hierarchical Data Layouts for a Unified Encoding of Scalar Field Precision and Resolution",
            "data": "To address the problem of ever-growing scientific data sizes making data movement a major hindrance to analysis, we introduce a novel encoding for scalar fields: a unified tree of resolution and precision, specifically constructed so that valid cuts correspond to sensible approximations of the original field in the precision-resolution space. Furthermore, we introduce a highly flexible encoding of such trees that forms a parameterized family of data hierarchies. We discuss how different parameter choices lead to different trade-offs in practice, and show how specific choices result in known data representation schemes such as zfp [52], idx [58], and jpeg2000 [76]. Finally, we provide system-level details and empirical evidence on how such hierarchies facilitate common approximate queries with minimal data movement and time, using real-world data sets ranging from a few gigabytes to nearly a terabyte in size. Experiments suggest that our new strategy of combining reductions in resolution and precision is competitive with state-of-the-art compression techniques with respect to data quality, while being significantly more flexible and orders of magnitude faster, and requiring significantly reduced resources.",
            "url": "http://dx.doi.org/10.1109/TVCG.2020.3030381",
            "id": "r_114",
            "s_ids": [
                "s_534",
                "s_356",
                "s_186",
                "s_255",
                "s_72",
                "s_576",
                "s_392",
                "s_273"
            ],
            "type": "rich",
            "x": 9.305315017700195,
            "y": 8.029793739318848
        },
        {
            "title": "Dynamic Nested Tracking Graphs",
            "data": "This work describes an approach for the interactive visual analysis of large-scale simulations, where numerous superlevel set components and their evolution are of primary interest. The approach first derives, at simulation runtime, a specialized Cinema database that consists of images of component groups, and topological abstractions. This database is processed by a novel graph operation-based nested tracking graph algorithm (GO-NTG) that dynamically computes NTGs for component groups based on size, overlap, persistence, and level thresholds. The resulting NTGs are in turn used in a feature-centered visual analytics framework to query specific database elements and update feature parameters, facilitating flexible post hoc analysis.",
            "url": "http://dx.doi.org/10.1109/TVCG.2019.2934368",
            "id": "r_115",
            "s_ids": [
                "s_30",
                "s_220",
                "s_190",
                "s_94",
                "s_662",
                "s_35"
            ],
            "type": "rich",
            "x": 9.961684226989746,
            "y": 7.1714935302734375
        },
        {
            "title": "Progressive Wasserstein Barycenters of Persistence Diagrams",
            "data": "This paper presents an efficient algorithm for the progressive approximation of Wasserstein barycenters of persistence diagrams, with applications to the visual analysis of ensemble data. Given a set of scalar fields, our approach enables the computation of a persistence diagram which is representative of the set, and which visually conveys the number, data ranges and saliences of the main features of interest found in the set. Such representative diagrams are obtained by computing explicitly the discrete Wasserstein barycenter of the set of persistence diagrams, a notoriously computationally intensive task. In particular, we revisit efficient algorithms for Wasserstein distance approximation [12], [51] to extend previous work on barycenter estimation [94]. We present a new fast algorithm, which progressively approximates the barycenter by iteratively increasing the computation accuracy as well as the number of persistent features in the output diagram. Such a progressivity drastically improves convergence in practice and allows to design an interruptible algorithm, capable of respecting computation time constraints. This enables the approximation of Wasserstein barycenters within interactive times. We present an application to ensemble clustering where we revisit the $k$-means algorithm to exploit our barycenters and compute, within execution time constraints, meaningful clusters of ensemble data along with their barycenter diagram. Extensive experiments on synthetic and real-life data sets report that our algorithm converges to barycenters that are qualitatively meaningful with regard to the applications, and quantitatively comparable to previous techniques, while offering an order of magnitude speedup when run until convergence (without time constraint). Our algorithm can be trivially parallelized to provide additional speedups in practice on standard workstations. We provide a lightweight C++ implementation of our approach that can be used to reproduce our results.",
            "url": "http://dx.doi.org/10.1109/TVCG.2019.2934256",
            "id": "r_116",
            "s_ids": [
                "s_497",
                "s_181",
                "s_572"
            ],
            "type": "rich",
            "x": 9.152933120727539,
            "y": 7.513338088989258
        },
        {
            "title": "Labels on Levels: Labeling of Multi-Scale Multi-Instance and Crowded 3D Biological Environments",
            "data": "Labeling is intrinsically important for exploring and understanding complex environments and models in a variety of domains. We present a method for interactive labeling of crowded 3D scenes containing very many instances of objects spanning multiple scales in size. In contrast to previous labeling methods, we target cases where many instances of dozens of types are present and where the hierarchical structure of the objects in the scene presents an opportunity to choose the most suitable level for each placed label. Our solution builds on and goes beyond labeling techniques in medical 3D visualization, cartography, and biological illustrations from books and prints. In contrast to these techniques, the main characteristics of our new technique are: 1) a novel way of labeling objects as part of a bigger structure when appropriate, 2) visual clutter reduction by labeling only representative instances for each type of an object, and a strategy of selecting those. The appropriate level of label is chosen by analyzing the scene's depth buffer and the scene objects' hierarchy tree. We address the topic of communicating the parent-children relationship between labels by employing visual hierarchy concepts adapted from graphic design. Selecting representative instances considers several criteria tailored to the character of the data and is combined with a greedy optimization approach. We demonstrate the usage of our method with models from mesoscale biology where these two characteristics-multi-scale and multi-instance-are abundant, along with the fact that these scenes are extraordinarily dense.",
            "url": "http://dx.doi.org/10.1109/TVCG.2018.2864491",
            "id": "r_117",
            "s_ids": [
                "s_230",
                "s_77",
                "s_448",
                "s_450",
                "s_574",
                "s_454",
                "s_119",
                "s_474",
                "s_395"
            ],
            "type": "rich",
            "x": 9.90875244140625,
            "y": 6.525917053222656
        },
        {
            "title": "GlyphLens: View-Dependent Occlusion Management in the Interactive Glyph Visualization",
            "data": "Glyph as a powerful multivariate visualization technique is used to visualize data through its visual channels. To visualize 3D volumetric dataset, glyphs are usually placed on 2D surface, such as the slicing plane or the feature surface, to avoid occluding each other. However, the 3D spatial structure of some features may be missing. On the other hand, placing large number of glyphs over the entire 3D space results in occlusion and visual clutter that make the visualization ineffective. To avoid the occlusion, we propose a view-dependent interactive 3D lens that removes the occluding glyphs by pulling the glyphs aside through the animation. We provide two space deformation models and two lens shape models to displace the glyphs based on their spatial distributions. After the displacement, the glyphs around the user-interested region are still visible as the context information, and their spatial structures are preserved. Besides, we attenuate the brightness of the glyphs inside the lens based on their depths to provide more depth cue. Furthermore, we developed an interactive glyph visualization system to explore different glyph-based visualization applications. In the system, we provide a few lens utilities that allows users to pick a glyph or a feature and look at it from different view directions. We compare different display/interaction techniques to visualize/manipulate our lens and glyphs.",
            "url": "http://dx.doi.org/10.1109/TVCG.2016.2599049",
            "id": "r_118",
            "s_ids": [
                "s_447",
                "s_304",
                "s_318"
            ],
            "type": "rich",
            "x": 9.446934700012207,
            "y": 3.0258796215057373
        },
        {
            "title": "Visualization and Extraction of Carvings for Heritage Conservation",
            "data": "We present novel techniques for visualizing, illustrating, analyzing, and generating carvings in surfaces. In particular, we consider the carvings in the plaster of the cloister of the Magdeburg cathedral, which dates to the 13th century. Due to aging and weathering, the carvings have flattened. Historians and restorers are highly interested in using digitalization techniques to analyze carvings in historic artifacts and monuments and to get impressions and illustrations of their original shape and appearance. Moreover, museums and churches are interested in such illustrations for presenting them to visitors. The techniques that we propose allow for detecting, selecting, and visualizing carving structures. In addition, we introduce an example-based method for generating carvings. The resulting tool, which integrates all techniques, was evaluated by three experienced restorers to assess the usefulness and applicability. Furthermore, we compared our approach with exaggerated shading and other state-of-the-art methods.",
            "url": "http://dx.doi.org/10.1109/TVCG.2016.2598603",
            "id": "r_119",
            "s_ids": [
                "s_658",
                "s_148",
                "s_585",
                "s_589"
            ],
            "type": "rich",
            "x": 8.79211139678955,
            "y": 3.6080563068389893
        },
        {
            "title": "Accurate Interactive Visualization of Large Deformations and Variability in Biomedical Image Ensembles",
            "data": "Large image deformations pose a challenging problem for the visualization and statistical analysis of 3D image ensembles which have a multitude of applications in biology and medicine. Simple linear interpolation in the tangent space of the ensemble introduces artifactual anatomical structures that hamper the application of targeted visual shape analysis techniques. In this work we make use of the theory of stationary velocity fields to facilitate interactive non-linear image interpolation and plausible extrapolation for high quality rendering of large deformations and devise an efficient image warping method on the GPU. This does not only improve quality of existing visualization techniques, but opens up a field of novel interactive methods for shape ensemble analysis. Taking advantage of the efficient non-linear 3D image warping, we showcase four visualizations: 1) browsing on-the-fly computed group mean shapes to learn about shape differences between specific classes, 2) interactive reformation to investigate complex morphologies in a single view, 3) likelihood volumes to gain a concise overview of variability and 4) streamline visualization to show variation in detail, specifically uncovering its component tangential to a reference surface. Evaluation on a real world dataset shows that the presented method outperforms the state-of-the-art in terms of visual quality while retaining interactive frame rates. A case study with a domain expert was performed in which the novel analysis and visualization methods are applied on standard model structures, namely skull and mandible of different rodents, to investigate and compare influence of phylogeny, diet and geography on shape. The visualizations enable for instance to distinguish (population-)normal and pathological morphology, assist in uncovering correlation to extrinsic factors and potentially support assessment of model quality.",
            "url": "http://dx.doi.org/10.1109/TVCG.2015.2467198",
            "id": "r_120",
            "s_ids": [
                "s_586",
                "s_245",
                "s_558",
                "s_530"
            ],
            "type": "rich",
            "x": 8.51894760131836,
            "y": 4.0471110343933105
        },
        {
            "title": "Visualizing Tensor Normal Distributions at Multiple Levels of Detail",
            "data": "Despite the widely recognized importance of symmetric second order tensor fields in medicine and engineering, the visualization of data uncertainty in tensor fields is still in its infancy. A recently proposed tensorial normal distribution, involving a fourth order covariance tensor, provides a mathematical description of how different aspects of the tensor field, such as trace, anisotropy, or orientation, vary and covary at each point. However, this wealth of information is far too rich for a human analyst to take in at a single glance, and no suitable visualization tools are available. We propose a novel approach that facilitates visual analysis of tensor covariance at multiple levels of detail. We start with a visual abstraction that uses slice views and direct volume rendering to indicate large-scale changes in the covariance structure, and locations with high overall variance. We then provide tools for interactive exploration, making it possible to drill down into different types of variability, such as in shape or orientation. Finally, we allow the analyst to focus on specific locations of the field, and provide tensor glyph animations and overlays that intuitively depict confidence intervals at those points. Our system is demonstrated by investigating the effects of measurement noise on diffusion tensor MRI, and by analyzing two ensembles of stress tensor fields from solid mechanics.",
            "url": "http://dx.doi.org/10.1109/TVCG.2015.2467031",
            "id": "r_121",
            "s_ids": [
                "s_469",
                "s_417",
                "s_586",
                "s_558"
            ],
            "type": "rich",
            "x": 8.527817726135254,
            "y": 6.2679829597473145
        },
        {
            "title": "Fuzzy Volume Rendering",
            "data": "In order to assess the reliability of volume rendering, it is necessary to consider the uncertainty associated with the volume data and how it is propagated through the volume rendering algorithm, as well as the contribution to uncertainty from the rendering algorithm itself. In this work, we show how to apply concepts from the field of reliable computing in order to build a framework for management of uncertainty in volume rendering, with the result being a self-validating computational model to compute a posteriori uncertainty bounds. We begin by adopting a coherent, unifying possibility-based representation of uncertainty that is able to capture the various forms of uncertainty that appear in visualization, including variability, imprecision, and fuzziness. Next, we extend the concept of the fuzzy transform in order to derive rules for accumulation and propagation of uncertainty. This representation and propagation of uncertainty together constitute an automated framework for management of uncertainty in visualization, which we then apply to volume rendering. The result, which we call fuzzy volume rendering, is an uncertainty-aware rendering algorithm able to produce more complete depictions of the volume data, thereby allowing more reliable conclusions and informed decisions. Finally, we compare approaches for self-validated computation in volume rendering, demonstrating that our chosen method has the ability to handle complex uncertainty while maintaining efficiency.",
            "url": "http://dx.doi.org/10.1109/TVCG.2012.227",
            "id": "r_122",
            "s_ids": [
                "s_28",
                "s_647"
            ],
            "type": "rich",
            "x": 11.035833358764648,
            "y": 7.721480369567871
        },
        {
            "title": "Data-Driven Space-Filling Curves",
            "data": "Abstract-We propose a data-driven space-filling curve method for 2D and 3D visualization. Our flexible curve traverses the data elements in the spatial domain in a way that the resulting linearization better preserves features in space compared to existing methods. We achieve such data coherency by calculating a Hamiltonian path that approximately minimizes an objective function that describes the similarity of data values and location coherency in a neighborhood. Our extended variant even supports multiscale data via quadtrees and octrees. Our method is useful in many areas of visualization including multivariate or comparative visualization ensemble visualization of 2D and 3D data on regular grids or multiscale visual analysis of particle simulations. The effectiveness of our method is evaluated with numerical comparisons to existing techniques and through examples of ensemble and multivariate datasets.",
            "url": "http://dx.doi.org/10.1109/TVCG.2020.3030473",
            "id": "r_123",
            "s_ids": [
                "s_188",
                "s_309",
                "s_130"
            ],
            "type": "rich",
            "x": 10.013768196105957,
            "y": 6.791398525238037
        },
        {
            "title": "Localized Topological Simplification of Scalar Data",
            "data": "This paper describes a localized algorithm for the topological simplification of scalar data, an essential pre-processing step of topological data analysis (TDA). Given a scalar field $f$ and a selection of extrema to preserve, the proposed localized topological simplification (LTS) derives a function g that is close to $f$ and only exhibits the selected set of extrema. Specifically, sub- and superlevel set components associated with undesired extrema are first locally flattened and then correctly embedded into the global scalar field, such that these regions are guaranteed-from a combinatorial perspective-to no longer contain any undesired extrema. In contrast to previous global approaches, LTS only and independently processes regions of the domain that actually need to be simplified, which already results in a noticeable speedup. Moreover, due to the localized nature of the algorithm, LTS can utilize shared-memory parallelism to simplify regions simultaneously with a high parallel efficiency (70%). Hence, LTS significantly improves interactivity for the exploration of simplification parameters and their effect on subsequent topological analysis. For such exploration tasks, LTS brings the overall execution time of a plethora of TDA pipelines from minutes down to seconds, with an average observed speedup over state-of-the-art techniques of up to $\\times 36$. Furthermore, in the special case where preserved extrema are selected based on topological persistence, an adapted version of LTS partially computes the persistence diagram and simultaneously simplifies features below a predefined persistence threshold. The effectiveness of LTS, its parallel efficiency, and its resulting benefits for TDA are demonstrated on several simulated and acquired datasets from different application domains, including physics, chemistry, and biomedical imaging.",
            "url": "http://dx.doi.org/10.1109/TVCG.2020.3030353",
            "id": "r_124",
            "s_ids": [
                "s_30",
                "s_220",
                "s_662",
                "s_572"
            ],
            "type": "rich",
            "x": 9.259095191955566,
            "y": 7.042455196380615
        },
        {
            "title": "Physics-Based Visual Characterization of Molecular Interaction Forces",
            "data": "Molecular simulations are used in many areas of biotechnology, such as drug design and enzyme engineering. Despite the development of automatic computational protocols, analysis of molecular interactions is still a major aspect where human comprehension and intuition are key to accelerate, analyze, and propose modifications to the molecule of interest. Most visualization algorithms help the users by providing an accurate depiction of the spatial arrangement: the atoms involved in inter-molecular contacts. There are few tools that provide visual information on the forces governing molecular docking. However, these tools, commonly restricted to close interaction between atoms, do not consider whole simulation paths, long-range distances and, importantly, do not provide visual cues for a quick and intuitive comprehension of the energy functions (modeling intermolecular interactions) involved. In this paper, we propose visualizations designed to enable the characterization of interaction forces by taking into account several relevant variables such as molecule-ligand distance and the energy function, which is essential to understand binding affinities. We put emphasis on mapping molecular docking paths obtained from Molecular Dynamics or Monte Carlo simulations, and provide time-dependent visualizations for different energy components and particle resolutions: atoms, groups or residues. The presented visualizations have the potential to support domain experts in a more efficient drug or enzyme design process.",
            "url": "http://dx.doi.org/10.1109/TVCG.2016.2598825",
            "id": "r_125",
            "s_ids": [
                "s_548",
                "s_282",
                "s_296",
                "s_183",
                "s_1",
                "s_567"
            ],
            "type": "rich",
            "x": 12.262203216552734,
            "y": 3.419975996017456
        },
        {
            "title": "Correlated Photon Mapping for Interactive Global Illumination of Time-Varying Volumetric Data",
            "data": "We present a method for interactive global illumination of both static and time-varying volumetric data based on reduction of the overhead associated with re-computation of photon maps. Our method uses the identification of photon traces invariant to changes of visual parameters such as the transfer function (TF), or data changes between time-steps in a 4D volume. This lets us operate on a variant subset of the entire photon distribution. The amount of computation required in the two stages of the photon mapping process, namely tracing and gathering, can thus be reduced to the subset that are affected by a data or visual parameter change. We rely on two different types of information from the original data to identify the regions that have changed. A low resolution uniform grid containing the minimum and maximum data values of the original data is derived for each time step. Similarly, for two consecutive time-steps, a low resolution grid containing the difference between the overlapping data is used. We show that this compact metadata can be combined with the transfer function to identify the regions that have changed. Each photon traverses the low-resolution grid to identify if it can be directly transferred to the next photon distribution state or if it needs to be recomputed. An efficient representation of the photon distribution is presented leading to an order of magnitude improved performance of the raycasting step. The utility of the method is demonstrated in several examples that show visual fidelity, as well as performance. The examples show that visual quality can be retained when the fraction of retraced photons is as low as 40%-50%.",
            "url": "http://dx.doi.org/10.1109/TVCG.2016.2598430",
            "id": "r_126",
            "s_ids": [
                "s_673",
                "s_244"
            ],
            "type": "rich",
            "x": 9.447864532470703,
            "y": 4.229739665985107
        },
        {
            "title": "Intuitive Exploration of Volumetric Data Using Dynamic Galleries",
            "data": "In this work we present a volume exploration method designed to be used by novice users and visitors to science centers and museums. The volumetric digitalization of artifacts in museums is of rapidly increasing interest as enhanced user experience through interactive data visualization can be achieved. This is, however, a challenging task since the vast majority of visitors are not familiar with the concepts commonly used in data exploration, such as mapping of visual properties from values in the data domain using transfer functions. Interacting in the data domain is an effective way to filter away undesired information but it is difficult to predict where the values lie in the spatial domain. In this work we make extensive use of dynamic previews instantly generated as the user explores the data domain. The previews allow the user to predict what effect changes in the data domain will have on the rendered image without being aware that visual parameters are set in the data domain. Each preview represents a subrange of the data domain where overview and details are given on demand through zooming and panning. The method has been designed with touch interfaces as the target platform for interaction. We provide a qualitative evaluation performed with visitors to a science center to show the utility of the approach.",
            "url": "http://dx.doi.org/10.1109/TVCG.2015.2467294",
            "id": "r_127",
            "s_ids": [
                "s_673",
                "s_546",
                "s_244"
            ],
            "type": "rich",
            "x": 11.2788724899292,
            "y": 4.4965105056762695
        },
        {
            "title": "A Study of the Trade-off Between Reducing Precision and Reducing Resolution for Data Analysis and Visualization",
            "data": "There currently exist two dominant strategies to reduce data sizes in analysis and visualization: reducing the precision of the data, e.g., through quantization, or reducing its resolution, e.g., by subsampling. Both have advantages and disadvantages and both face fundamental limits at which the reduced information ceases to be useful. The paper explores the additional gains that could be achieved by combining both strategies. In particular, we present a common framework that allows us to study the trade-off in reducing precision and/or resolution in a principled manner. We represent data reduction schemes as progressive streams of bits and study how various bit orderings such as by resolution, by precision, etc., impact the resulting approximation error across a variety of data sets as well as analysis tasks. Furthermore, we compute streams that are optimized for different tasks to serve as lower bounds on the achievable error. Scientific data management systems can use the results presented in this paper as guidance on how to store and stream data to make efficient use of the limited storage and bandwidth in practice.",
            "url": "http://dx.doi.org/10.1109/TVCG.2018.2864853",
            "id": "r_128",
            "s_ids": [
                "s_534",
                "s_72",
                "s_186",
                "s_392",
                "s_255",
                "s_273"
            ],
            "type": "rich",
            "x": 9.278986930847168,
            "y": 8.052854537963867
        },
        {
            "title": "Visualization Multi-Pipeline for Communicating Biology",
            "data": "We propose a system to facilitate biology communication by developing a pipeline to support the instructional visualization of heterogeneous biological data on heterogeneous user-devices. Discoveries and concepts in biology are typically summarized with illustrations assembled manually from the interpretation and application of heterogenous data. The creation of such illustrations is time consuming, which makes it incompatible with frequent updates to the measured data as new discoveries are made. Illustrations are typically non-interactive, and when an illustration is updated, it still has to reach the user. Our system is designed to overcome these three obstacles. It supports the integration of heterogeneous datasets, reflecting the knowledge that is gained from different data sources in biology. After pre-processing the datasets, the system transforms them into visual representations as inspired by scientific illustrations. As opposed to traditional scientific illustration these representations are generated in real-time - they are interactive. The code generating the visualizations can be embedded in various software environments. To demonstrate this, we implemented both a desktop application and a remote-rendering server in which the pipeline is embedded. The remote-rendering server supports multi-threaded rendering and it is able to handle multiple users simultaneously. This scalability to different hardware environments, including multi-GPU setups, makes our system useful for efficient public dissemination of biological discoveries.",
            "url": "http://dx.doi.org/10.1109/TVCG.2017.2744518",
            "id": "r_129",
            "s_ids": [
                "s_626",
                "s_230",
                "s_477",
                "s_275",
                "s_594",
                "s_574",
                "s_474",
                "s_395"
            ],
            "type": "rich",
            "x": 11.403936386108398,
            "y": 4.0144171714782715
        },
        {
            "title": "Glyphs for General Second-Order 2D and 3D Tensors",
            "data": "Glyphs are a powerful tool for visualizing second-order tensors in a variety of scientic data as they allow to encode physical behavior in geometric properties. Most existing techniques focus on symmetric tensors and exclude non-symmetric tensors where the eigenvectors can be non-orthogonal or complex. We present a new construction of 2d and 3d tensor glyphs based on piecewise rational curves and surfaces with the following properties: invariance to (a) isometries and (b) scaling, (c) direct encoding of all real eigenvalues and eigenvectors, (d) one-to-one relation between the tensors and glyphs, (e) glyph continuity under changing the tensor. We apply the glyphs to visualize the Jacobian matrix fields of a number of 2d and 3d vector fields.",
            "url": "http://dx.doi.org/10.1109/TVCG.2016.2598998",
            "id": "r_130",
            "s_ids": [
                "s_163",
                "s_101",
                "s_653"
            ],
            "type": "rich",
            "x": 8.506619453430176,
            "y": 6.261783123016357
        },
        {
            "title": "Molecular Surface Maps",
            "data": "We present Molecular Surface Maps, a novel, view-independent, and concise representation for molecular surfaces. It transfers the well-known world map metaphor to molecular visualization. Our application maps the complex molecular surface to a simple 2D representation through a spherical intermediate, the Molecular Surface Globe. The Molecular Surface Map concisely shows arbitrary attributes of the original molecular surface, such as biochemical properties or geometrical features. This results in an intuitive overview, which allows researchers to assess all molecular surface attributes at a glance. Our representation can be used as a visual summarization of a molecule's interface with its environment. In particular, Molecular Surface Maps simplify the analysis and comparison of different data sets or points in time. Furthermore, the map representation can be used in a Space-time Cube to analyze time-dependent data from molecular simulations without the need for animation. We show the feasibility of Molecular Surface Maps for different typical analysis tasks of biomolecular data.",
            "url": "http://dx.doi.org/10.1109/TVCG.2016.2598824",
            "id": "r_131",
            "s_ids": [
                "s_187",
                "s_71",
                "s_321",
                "s_15",
                "s_177",
                "s_598",
                "s_495",
                "s_277"
            ],
            "type": "rich",
            "x": 12.338919639587402,
            "y": 3.4439263343811035
        },
        {
            "title": "Colon Flattening Using Heat Diffusion Riemannian Metric",
            "data": "We propose a new colon flattening algorithm that is efficient, shape-preserving, and robust to topological noise. Unlike previous approaches, which require a mandatory topological denoising to remove fake handles, our algorithm directly flattens the colon surface without any denoising. In our method, we replace the original Euclidean metric of the colon surface with a heat diffusion metric that is insensitive to topological noise. Using this heat diffusion metric, we then solve a Laplacian equation followed by an integration step to compute the final flattening. We demonstrate that our method is shape-preserving and the shape of the polyps are well preserved. The flattened colon also provides an efficient way to enhance the navigation and inspection in virtual colonoscopy. We further show how the existing colon registration pipeline is made more robust by using our colon flattening. We have tested our method on several colon wall surfaces and the experimental results demonstrate the robustness and the efficiency of our method.",
            "url": "http://dx.doi.org/10.1109/TVCG.2013.139",
            "id": "r_132",
            "s_ids": [
                "s_464",
                "s_54",
                "s_412",
                "s_251",
                "s_13"
            ],
            "type": "rich",
            "x": 8.207507133483887,
            "y": 4.407832145690918
        },
        {
            "title": "Direct Volume Rendering with Nonparametric Models of Uncertainty",
            "data": "We present a nonparametric statistical framework for the quantification, analysis, and propagation of data uncertainty in direct volume rendering (DVR). The state-of-the-art statistical DVR framework allows for preserving the transfer function (TF) of the ground truth function when visualizing uncertain data; however, the existing framework is restricted to parametric models of uncertainty. In this paper, we address the limitations of the existing DVR framework by extending the DVR framework for nonparametric distributions. We exploit the quantile interpolation technique to derive probability distributions representing uncertainty in viewing-ray sample intensities in closed form, which allows for accurate and efficient computation. We evaluate our proposed nonparametric statistical models through qualitative and quantitative comparisons with the mean-field and parametric statistical models, such as uniform and Gaussian, as well as Gaussian mixtures. In addition, we present an extension of the state-of-the-art rendering parametric framework to 2D TFs for improved DVR classifications. We show the applicability of our uncertainty quantification framework to ensemble, downsampled, and bivariate versions of scalar field datasets.",
            "url": "http://dx.doi.org/10.1109/TVCG.2020.3030394",
            "id": "r_133",
            "s_ids": [
                "s_669",
                "s_168",
                "s_89",
                "s_309",
                "s_152"
            ],
            "type": "rich",
            "x": 10.994952201843262,
            "y": 7.376486778259277
        },
        {
            "title": "Deep Volumetric Ambient Occlusion",
            "data": "We present a novel deep learning based technique for volumetric ambient occlusion in the context of direct volume rendering. Our proposed Deep Volumetric Ambient Occlusion (DVAO) approach can predict per-voxel ambient occlusion in volumetric data sets, while considering global information provided through the transfer function. The proposed neural network only needs to be executed upon change of this global information, and thus supports real-time volume interaction. Accordingly, we demonstrate DVAO's ability to predict volumetric ambient occlusion, such that it can be applied interactively within direct volume rendering. To achieve the best possible results, we propose and analyze a variety of transfer function representations and injection strategies for deep neural networks. Based on the obtained results we also give recommendations applicable in similar volume learning scenarios. Lastly, we show that DVAO generalizes to a variety of modalities, despite being trained on computed tomography data only.",
            "url": "http://dx.doi.org/10.1109/TVCG.2020.3030344",
            "id": "r_134",
            "s_ids": [
                "s_346",
                "s_183"
            ],
            "type": "rich",
            "x": 9.60118579864502,
            "y": 5.73504638671875
        },
        {
            "title": "Visualization of Neuronal Structures in Wide-Field Microscopy Brain Images",
            "data": "Wide-field microscopes are commonly used in neurobiology for experimental studies of brain samples. Available visualization tools are limited to electron, two-photon, and confocal microscopy datasets, and current volume rendering techniques do not yield effective results when used with wide-field data. We present a workflow for the visualization of neuronal structures in wide-field microscopy images of brain samples. We introduce a novel gradient-based distance transform that overcomes the out-of-focus blur caused by the inherent design of wide-field microscopes. This is followed by the extraction of the 3D structure of neurites using a multi-scale curvilinear filter and cell-bodies using a Hessian-based enhancement filter. The response from these filters is then applied as an opacity map to the raw data. Based on the visualization challenges faced by domain experts, our workflow provides multiple rendering modes to enable qualitative analysis of neuronal structures, which includes separation of cell-bodies from neurites and an intensity-based classification of the structures. Additionally, we evaluate our visualization results against both a standard image processing deconvolution technique and a confocal microscopy image of the same specimen. We show that our method is significantly faster and requires less computational resources, while producing high quality visualizations. We deploy our workflow in an immersive gigapixel facility as a paradigm for the processing and visualization of large, high-resolution, wide-field microscopy brain datasets.",
            "url": "http://dx.doi.org/10.1109/TVCG.2018.2864852",
            "id": "r_135",
            "s_ids": [
                "s_91",
                "s_179",
                "s_164",
                "s_535",
                "s_377",
                "s_13"
            ],
            "type": "rich",
            "x": 11.093092918395996,
            "y": 3.3198275566101074
        },
        {
            "title": "Visualization of Large Molecular Trajectories",
            "data": "The analysis of protein-ligand interactions is a time-intensive task. Researchers have to analyze multiple physico-chemical properties of the protein at once and combine them to derive conclusions about the protein-ligand interplay. Typically, several charts are inspected, and 3D animations can be played side-by-side to obtain a deeper understanding of the data. With the advances in simulation techniques, larger and larger datasets are available, with up to hundreds of thousands of steps. Unfortunately, such large trajectories are very difficult to investigate with traditional approaches. Therefore, the need for special tools that facilitate inspection of these large trajectories becomes substantial. In this paper, we present a novel system for visual exploration of very large trajectories in an interactive and user-friendly way. Several visualization motifs are automatically derived from the data to give the user the information about interactions between protein and ligand. Our system offers specialized widgets to ease and accelerate data inspection and navigation to interesting parts of the simulation. The system is suitable also for simulations where multiple ligands are involved. We have tested the usefulness of our tool on a set of datasets obtained from protein engineers, and we describe the expert feedback.",
            "url": "http://dx.doi.org/10.1109/TVCG.2018.2864851",
            "id": "r_136",
            "s_ids": [
                "s_627",
                "s_548",
                "s_183",
                "s_448",
                "s_1",
                "s_567"
            ],
            "type": "rich",
            "x": 12.191610336303711,
            "y": 3.304269552230835
        },
        {
            "title": "Exploring Time-Varying Multivariate Volume Data Using Matrix of Isosurface Similarity Maps",
            "data": "We present a novel visual representation and interface named the matrix of isosurface similarity maps (MISM) for effective exploration of large time-varying multivariate volumetric data sets. MISM synthesizes three types of similarity maps (i.e., self, temporal, and variable similarity maps) to capture the essential relationships among isosurfaces of different variables and time steps. Additionally, it serves as the main visual mapping and navigation tool for examining the vast number of isosurfaces and exploring the underlying time-varying multivariate data set. We present temporal clustering, variable grouping, and interactive filtering to reduce the huge exploration space of MISM. In conjunction with the isovalue and isosurface views, MISM allows users to identify important isosurfaces or isosurface pairs and compare them over space, time, and value range. More importantly, we introduce path recommendation that suggests, animates, and compares traversal paths for effectively exploring MISM under varied criteria and at different levels-of-detail. A silhouette-based method is applied to render multiple surfaces of interest in a visually succinct manner. We demonstrate the effectiveness of our approach with case studies of several time-varying multivariate data sets and an ensemble data set, and evaluate our work with two domain experts.",
            "url": "http://dx.doi.org/10.1109/TVCG.2018.2864808",
            "id": "r_137",
            "s_ids": [
                "s_645",
                "s_314",
                "s_485",
                "s_507",
                "s_136",
                "s_579",
                "s_490"
            ],
            "type": "rich",
            "x": 10.165812492370605,
            "y": 6.638605117797852
        },
        {
            "title": "Interactive Dynamic Volume Illumination with Refraction and Caustics",
            "data": "In recent years, significant progress has been made in developing high-quality interactive methods for realistic volume illumination. However, refraction - despite being an important aspect of light propagation in participating media - has so far only received little attention. In this paper, we present a novel approach for refractive volume illumination including caustics capable of interactive frame rates. By interleaving light and viewing ray propagation, our technique avoids memory-intensive storage of illumination information and does not require any precomputation. It is fully dynamic and all parameters such as light position and transfer function can be modified interactively without a performance penalty.",
            "url": "http://dx.doi.org/10.1109/TVCG.2017.2744438",
            "id": "r_138",
            "s_ids": [
                "s_49",
                "s_162"
            ],
            "type": "rich",
            "x": 9.485642433166504,
            "y": 4.147570610046387
        },
        {
            "title": "Corresponding Supine and Prone Colon Visualization Using Eigenfunction Analysis and Fold Modeling",
            "data": "We present a method for registration and visualization of corresponding supine and prone virtual colonoscopy scans based on eigenfunction analysis and fold modeling. In virtual colonoscopy, CT scans are acquired with the patient in two positions, and their registration is desirable so that physicians can corroborate findings between scans. Our algorithm performs this registration efficiently through the use of Fiedler vector representation (the second eigenfunction of the Laplace-Beltrami operator). This representation is employed to first perform global registration of the two colon positions. The registration is then locally refined using the haustral folds, which are automatically segmented using the 3D level sets of the Fiedler vector. The use of Fiedler vectors and the segmented folds presents a precise way of visualizing corresponding regions across datasets and visual modalities. We present multiple methods of visualizing the results, including 2D flattened rendering and the corresponding 3D endoluminal views. The precise fold modeling is used to automatically find a suitable cut for the 2D flattening, which provides a less distorted visualization. Our approach is robust, and we demonstrate its efficiency and efficacy by showing matched views on both the 2D flattened colons and in the 3D endoluminal view. We analytically evaluate the results by measuring the distance between features on the registered colons, and we also assess our fold segmentation against 20 manually labeled datasets. We have compared our results analytically to previous methods, and have found our method to achieve superior results. We also prove the hot spots conjecture for modeling cylindrical topology using Fiedler vector representation, which allows our approach to be used for general cylindrical geometry modeling and feature extraction.",
            "url": "http://dx.doi.org/10.1109/TVCG.2016.2598791",
            "id": "r_139",
            "s_ids": [
                "s_41",
                "s_17",
                "s_251",
                "s_13"
            ],
            "type": "rich",
            "x": 8.3428316116333,
            "y": 4.206761837005615
        },
        {
            "title": "Planar Visualization of Treelike Structures",
            "data": "We present a novel method to create planar visualizations of treelike structures (e.g., blood vessels and airway trees) where the shape of the object is well preserved, allowing for easy recognition by users familiar with the structures. Based on the extracted skeleton within the treelike object, a radial planar embedding is first obtained such that there are no self-intersections of the skeleton which would have resulted in occlusions in the final view. An optimization procedure which adjusts the angular positions of the skeleton nodes is then used to reconstruct the shape as closely as possible to the original, according to a specified view plane, which thus preserves the global geometric context of the object. Using this shape recovered embedded skeleton, the object surface is then flattened to the plane without occlusions using harmonic mapping. The boundary of the mesh is adjusted during the flattening step to account for regions where the mesh is stretched over concavities. This parameterized surface can then be used either as a map for guidance during endoluminal navigation or directly for interrogation and decision making. Depth cues are provided with a grayscale border to aid in shape understanding. Examples are presented using bronchial trees, cranial and lower limb blood vessels, and upper aorta datasets, and the results are evaluated quantitatively and with a user study.",
            "url": "http://dx.doi.org/10.1109/TVCG.2015.2467413",
            "id": "r_140",
            "s_ids": [
                "s_17",
                "s_13"
            ],
            "type": "rich",
            "x": 8.400649070739746,
            "y": 3.904039144515991
        },
        {
            "title": "Vortex Cores of Inertial Particles",
            "data": "The cores of massless, swirling particle motion are an indicator for vortex-like behavior in vector fields and to this end, a number of coreline extractors have been proposed in the literature. Though, many practical applications go beyond the study of the vector field. Instead, engineers seek to understand the behavior of inertial particles moving therein, for instance in sediment transport, helicopter brownout and pulverized coal combustion. In this paper, we present two strategies for the extraction of the corelines that inertial particles swirl around, which depend on particle density, particle diameter, fluid viscosity and gravity. The first is to deduce the local swirling behavior from the autonomous inertial motion ODE, which eventually reduces to a parallel vectors operation. For the second strategy, we use a particle density estimation to locate inertial attractors. With this, we are able to extract the cores of swirling inertial particle motion for both steady and unsteady 3D vector fields. We demonstrate our techniques in a number of benchmark data sets, and elaborate on the relation to traditional massless corelines.",
            "url": "http://dx.doi.org/10.1109/TVCG.2014.2346415",
            "id": "r_141",
            "s_ids": [
                "s_443",
                "s_653"
            ],
            "type": "rich",
            "x": 7.68286657333374,
            "y": 5.370606899261475
        },
        {
            "title": "Evaluation of Fast-Forward Video Visualization",
            "data": "We evaluate and compare video visualization techniques based on fast-forward. A controlled laboratory user study (n = 24) was conducted to determine the trade-off between support of object identification and motion perception, two properties that have to be considered when choosing a particular fast-forward visualization. We compare four different visualizations: two representing the state-of-the-art and two new variants of visualization introduced in this paper. The two state-of-the-art methods we consider are frame-skipping and temporal blending of successive frames. Our object trail visualization leverages a combination of frame-skipping and temporal blending, whereas predictive trajectory visualization supports motion perception by augmenting the video frames with an arrow that indicates the future object trajectory. Our hypothesis was that each of the state-of-the-art methods satisfies just one of the goals: support of object identification or motion perception. Thus, they represent both ends of the visualization design. The key findings of the evaluation are that object trail visualization supports object identification, whereas predictive trajectory visualization is most useful for motion perception. However, frame-skipping surprisingly exhibits reasonable performance for both tasks. Furthermore, we evaluate the subjective performance of three different playback speed visualizations for adaptive fast-forward, a subdomain of video fast-forward.",
            "url": "http://dx.doi.org/10.1109/TVCG.2012.222",
            "id": "r_142",
            "s_ids": [
                "s_156",
                "s_657",
                "s_173",
                "s_122",
                "s_130"
            ],
            "type": "rich",
            "x": 10.164490699768066,
            "y": 3.3520824909210205
        },
        {
            "title": "Scale Trotter: Illustrative Visual Travels Across Negative Scales",
            "data": "We present ScaleTrotter, a conceptual framework for an interactive, multi-scale visualization of biological mesoscale data and, specifically, genome data. ScaleTrotter allows viewers to smoothly transition from the nucleus of a cell to the atomistic composition of the DNA, while bridging several orders of magnitude in scale. The challenges in creating an interactive visualization of genome data are fundamentally different in several ways from those in other domains like astronomy that require a multi-scale representation as well. First, genome data has intertwined scale levels\u2014the DNA is an extremely long, connected molecule that manifests itself at all scale levels. Second, elements of the DNA do not disappear as one zooms out\u2014instead the scale levels at which they are observed group these elements differently. Third, we have detailed information and thus geometry for the entire dataset and for all scale levels, posing a challenge for interactive visual exploration. Finally, the conceptual scale levels for genome data are close in scale space, requiring us to find ways to visually embed a smaller scale into a coarser one. We address these challenges by creating a new multi-scale visualization concept. We use a scale-dependent camera model that controls the visual embedding of the scales into their respective parents, the rendering of a subset of the scale hierarchy, and the location, size, and scope of the view. In traversing the scales, ScaleTrotter is roaming between 2D and 3D visual representations that are depicted in integrated visuals. We discuss, specifically, how this form of multi-scale visualization follows from the specific characteristics of the genome data and describe its implementation. Finally, we discuss the implications of our work to the general illustrative depiction of multi-scale data.",
            "url": "http://dx.doi.org/10.1109/TVCG.2019.2934334",
            "id": "r_143",
            "s_ids": [
                "s_231",
                "s_280",
                "s_230",
                "s_474",
                "s_395",
                "s_429"
            ],
            "type": "rich",
            "x": 11.7498779296875,
            "y": 3.6756224632263184
        },
        {
            "title": "CPU Isosurface Ray Tracing of Adaptive Mesh Refinement Data",
            "data": "Adaptive mesh refinement (AMR) is a key technology for large-scale simulations that allows for adaptively changing the simulation mesh resolution, resulting in significant computational and storage savings. However, visualizing such AMR data poses a significant challenge due to the difficulties introduced by the hierarchical representation when reconstructing continuous field values. In this paper, we detail a comprehensive solution for interactive isosurface rendering of block-structured AMR data. We contribute a novel reconstruction strategy-the octant method-which is continuous, adaptive and simple to implement. Furthermore, we present a generally applicable hybrid implicit isosurface ray-tracing method, which provides better rendering quality and performance than the built-in sampling-based approach in OSPRay. Finally, we integrate our octant method and hybrid isosurface geometry into OSPRay as a module, providing the ability to create high-quality interactive visualizations combining volume and isosurface representations of BS-AMR data. We evaluate the rendering performance, memory consumption and quality of our method on two gigascale block-structured AMR datasets.",
            "url": "http://dx.doi.org/10.1109/TVCG.2018.2864850",
            "id": "r_144",
            "s_ids": [
                "s_155",
                "s_632",
                "s_38",
                "s_576",
                "s_309"
            ],
            "type": "rich",
            "x": 9.856490135192871,
            "y": 4.772428512573242
        },
        {
            "title": "Vol\u00b2velle: Printable Interactive Volume Visualization",
            "data": "Interaction is an indispensable aspect of data visualization. The presentation of volumetric data, in particular, often significantly benefits from interactive manipulation of parameters such as transfer functions, rendering styles, or clipping planes. However, when we want to create hardcopies of such visualizations, this essential aspect is lost. In this paper, we present a novel approach for creating hardcopies of volume visualizations which preserves a certain degree of interactivity. We present a method for automatically generating Volvelles, printable tangible wheel charts that can be manipulated to explore different parameter settings. Our interactive system allows the flexible mapping of arbitrary visualization parameters and supports advanced features such as linked views. The resulting designs can be easily reproduced using a standard printer and assembled within a few minutes.",
            "url": "http://dx.doi.org/10.1109/TVCG.2016.2599211",
            "id": "r_145",
            "s_ids": [
                "s_502",
                "s_162"
            ],
            "type": "rich",
            "x": 11.072942733764648,
            "y": 4.460916042327881
        },
        {
            "title": "Mining Graphs for Understanding Time-Varying Volumetric Data",
            "data": "A notable recent trend in time-varying volumetric data analysis and visualization is to extract data relationships and represent them in a low-dimensional abstract graph view for visual understanding and making connections to the underlying data. Nevertheless, the ever-growing size and complexity of data demands novel techniques that go beyond standard brushing and linking to allow significant reduction of cognition overhead and interaction cost. In this paper, we present a mining approach that automatically extracts meaningful features from a graph-based representation for exploring time-varying volumetric data. This is achieved through the utilization of a series of graph analysis techniques including graph simplification, community detection, and visual recommendation. We investigate the most important transition relationships for time-varying data and evaluate our solution with several time-varying data sets of different sizes and characteristics. For gaining insights from the data, we show that our solution is more efficient and effective than simply asking users to extract relationships via standard interaction techniques, especially when the data set is large and the relationships are complex. We also collect expert feedback to confirm the usefulness of our approach.",
            "url": "http://dx.doi.org/10.1109/TVCG.2015.2468031",
            "id": "r_146",
            "s_ids": [
                "s_65",
                "s_485",
                "s_9",
                "s_456",
                "s_490"
            ],
            "type": "rich",
            "x": 11.722888946533203,
            "y": 6.014060020446777
        },
        {
            "title": "JiTTree: A Just-in-Time Compiled Sparse GPU Volume Data Structure",
            "data": "Sparse volume data structures enable the efficient representation of large but sparse volumes in GPU memory for computation and visualization. However, the choice of a specific data structure for a given data set depends on several factors, such as the memory budget, the sparsity of the data, and data access patterns. In general, there is no single optimal sparse data structure, but a set of several candidates with individual strengths and drawbacks. One solution to this problem are hybrid data structures which locally adapt themselves to the sparsity. However, they typically suffer from increased traversal overhead which limits their utility in many applications. This paper presents JiTTree, a novel sparse hybrid volume data structure that uses just-in-time compilation to overcome these problems. By combining multiple sparse data structures and reducing traversal overhead we leverage their individual advantages. We demonstrate that hybrid data structures adapt well to a large range of data sets. They are especially superior to other sparse data structures for data sets that locally vary in sparsity. Possible optimization criteria are memory, performance and a combination thereof. Through just-in-time (JIT) compilation, JiTTree reduces the traversal overhead of the resulting optimal data structure. As a result, our hybrid volume data structure enables efficient computations on the GPU, while being superior in terms of memory usage when compared to non-hybrid data structures.",
            "url": "http://dx.doi.org/10.1109/TVCG.2015.2467331",
            "id": "r_147",
            "s_ids": [
                "s_61",
                "s_162",
                "s_474",
                "s_300",
                "s_145"
            ],
            "type": "rich",
            "x": 9.338033676147461,
            "y": 8.028119087219238
        },
        {
            "title": "A Multi-Criteria Approach to Camera Motion Design for Volume Data Animation",
            "data": "We present an integrated camera motion design and path generation system for building volume data animations. Creating animations is an essential task in presenting complex scientific visualizations. Existing visualization systems use an established animation function based on keyframes selected by the user. This approach is limited in providing the optimal in-between views of the data. Alternatively, computer graphics and virtual reality camera motion planning is frequently focused on collision free movement in a virtual walkthrough. For semi-transparent, fuzzy, or blobby volume data the collision free objective becomes insufficient. Here, we provide a set of essential criteria focused on computing camera paths to establish effective animations of volume data. Our dynamic multi-criteria solver coupled with a force-directed routing algorithm enables rapid generation of camera paths. Once users review the resulting animation and evaluate the camera motion, they are able to determine how each criterion impacts path generation. In this paper, we demonstrate how incorporating this animation approach with an interactive volume visualization system reduces the effort in creating context-aware and coherent animations. This frees the user to focus on visualization tasks with the objective of gaining additional insight from the volume data.",
            "url": "http://dx.doi.org/10.1109/TVCG.2013.123",
            "id": "r_148",
            "s_ids": [
                "s_446",
                "s_286",
                "s_647"
            ],
            "type": "rich",
            "x": 10.373123168945312,
            "y": 4.033430576324463
        },
        {
            "title": "Visualization of Electrostatic Dipoles in Molecular Dynamics of Metal Oxides",
            "data": "Metal oxides are important for many technical applications. For example alumina (aluminum oxide) is the most commonly-used ceramic in microelectronic devices thanks to its excellent properties. Experimental studies of these materials are increasingly supplemented with computer simulations. Molecular dynamics (MD) simulations can reproduce the material behavior very well and are now reaching time scales relevant for interesting processes like crack propagation. In this work we focus on the visualization of induced electric dipole moments on oxygen atoms in crack propagation simulations. The straightforward visualization using glyphs for the individual atoms, simple shapes like spheres or arrows, is insufficient for providing information about the data set as a whole. As our contribution we show for the first time that fractional anisotropy values computed from the local neighborhood of individual atoms of MD simulation data depict important information about relevant properties of the field of induced electric dipole moments. Iso surfaces in the field of fractional anisotropy as well as adjustments of the glyph representation allow the user to identify regions of correlated orientation. We present novel and relevant findings for the application domain resulting from these visualizations, like the influence of mechanical forces on the electrostatic properties.",
            "url": "http://dx.doi.org/10.1109/TVCG.2012.282",
            "id": "r_149",
            "s_ids": [
                "s_527",
                "s_637",
                "s_92",
                "s_15",
                "s_435",
                "s_471",
                "s_277"
            ],
            "type": "rich",
            "x": 9.232419967651367,
            "y": 5.177774429321289
        },
        {
            "title": "Automatic Tuning of Spatially Varying Transfer Functions for Blood Vessel Visualization",
            "data": "Computed Tomography Angiography (CTA) is commonly used in clinical routine for diagnosing vascular diseases. The procedure involves the injection of a contrast agent into the blood stream to increase the contrast between the blood vessels and the surrounding tissue in the image data. CTA is often visualized with Direct Volume Rendering (DVR) where the enhanced image contrast is important for the construction of Transfer Functions (TFs). For increased efficiency, clinical routine heavily relies on preset TFs to simplify the creation of such visualizations for a physician. In practice, however, TF presets often do not yield optimal images due to variations in mixture concentration of contrast agent in the blood stream. In this paper we propose an automatic, optimization-based method that shifts TF presets to account for general deviations and local variations of the intensity of contrast enhanced blood vessels. Some of the advantages of this method are the following. It computationally automates large parts of a process that is currently performed manually. It performs the TF shift locally and can thus optimize larger portions of the image than is possible with manual interaction. The method is based on a well known vesselness descriptor in the definition of the optimization criterion. The performance of the method is illustrated by clinically relevant CT angiography datasets displaying both improved structural overviews of vessel trees and improved adaption to local variations of contrast concentration.",
            "url": "http://dx.doi.org/10.1109/TVCG.2012.203",
            "id": "r_150",
            "s_ids": [
                "s_25",
                "s_389",
                "s_519",
                "s_458",
                "s_532"
            ],
            "type": "rich",
            "x": 7.587300777435303,
            "y": 4.17347526550293
        },
        {
            "title": "Objective Observer-Relative Flow Visualization in Curved Spaces for Unsteady 2D Geophysical Flows",
            "data": "Computing and visualizing features in fluid flow often depends on the observer, or reference frame, relative to which the input velocity field is given. A desired property of feature detectors is therefore that they are objective, meaning independent of the input reference frame. However, the standard definition of objectivity is only given for Euclidean domains and cannot be applied in curved spaces. We build on methods from mathematical physics and Riemannian geometry to generalize objectivity to curved spaces, using the powerful notion of symmetry groups as the basis for definition. From this, we develop a general mathematical framework for the objective computation of observer fields for curved spaces, relative to which other computed measures become objective. An important property of our framework is that it works intrinsically in 2D, instead of in the 3D ambient space. This enables a direct generalization of the 2D computation via optimization of observer fields in flat space to curved domains, without having to perform optimization in 3D. We specifically develop the case of unsteady 2D geophysical flows given on spheres, such as the Earth. Our observer fields in curved spaces then enable objective feature computation as well as the visualization of the time evolution of scalar and vector fields, such that the automatically computed reference frames follow moving structures like vortices in a way that makes them appear to be steady.",
            "url": "http://dx.doi.org/10.1109/TVCG.2020.3030454",
            "id": "r_151",
            "s_ids": [
                "s_145",
                "s_366",
                "s_557",
                "s_123",
                "s_561",
                "s_570",
                "s_300"
            ],
            "type": "rich",
            "x": 8.21733283996582,
            "y": 5.677694797515869
        },
        {
            "title": "TopoMap: A 0-dimensional Homology Preserving Projection of High-Dimensional Data",
            "data": "Multidimensional Projection is a fundamental tool for high-dimensional data analytics and visualization. With very few exceptions, projection techniques are designed to map data from a high-dimensional space to a visual space so as to preserve some dissimilarity (similarity) measure, such as the Euclidean distance for example. In fact, although adopting distinct mathematical formulations designed to favor different aspects of the data, most multidimensional projection methods strive to preserve dissimilarity measures that encapsulate geometric properties such as distances or the proximity relation between data objects. However, geometric relations are not the only interesting property to be preserved in a projection. For instance, the analysis of particular structures such as clusters and outliers could be more reliably performed if the mapping process gives some guarantee as to topological invariants such as connected components and loops. This paper introduces TopoMap, a novel projection technique which provides topological guarantees during the mapping process. In particular, the proposed method performs the mapping from a high-dimensional space to a visual space, while preserving the 0-dimensional persistence diagram of the Rips filtration of the high-dimensional data, ensuring that the filtrations generate the same connected components when applied to the original as well as projected data. The presented case studies show that the topological guarantee provided by TopoMap not only brings confidence to the visual analytic process but also can be used to assist in the assessment of other projection methods.",
            "url": "http://dx.doi.org/10.1109/TVCG.2020.3030441",
            "id": "r_152",
            "s_ids": [
                "s_27",
                "s_572",
                "s_198",
                "s_315",
                "s_344"
            ],
            "type": "rich",
            "x": 10.020956993103027,
            "y": 7.037785053253174
        },
        {
            "title": "Cohort-based T-SSIM Visual Computing for Radiation Therapy Prediction and Exploration",
            "data": "We describe a visual computing approach to radiation therapy (RT) planning, based on spatial similarity within a patient cohort. In radiotherapy for head and neck cancer treatment, dosage to organs at risk surrounding a tumor is a large cause of treatment toxicity. Along with the availability of patient repositories, this situation has lead to clinician interest in understanding and predicting RT outcomes based on previously treated similar patients. To enable this type of analysis, we introduce a novel topology-based spatial similarity measure, T-SSIM, and a predictive algorithm based on this similarity measure. We couple the algorithm with a visual steering interface that intertwines visual encodings for the spatial data and statistical results, including a novel parallel-marker encoding that is spatially aware. We report quantitative results on a cohort of 165 patients, as well as a qualitative evaluation with domain experts in radiation oncology, data management, biostatistics, and medical imaging, who are collaborating remotely.",
            "url": "http://dx.doi.org/10.1109/TVCG.2019.2934546",
            "id": "r_153",
            "s_ids": [
                "s_241",
                "s_329",
                "s_312",
                "s_316",
                "s_508",
                "s_113",
                "s_514",
                "s_383",
                "s_410"
            ],
            "type": "rich",
            "x": 7.7534637451171875,
            "y": 3.6913716793060303
        },
        {
            "title": "Artifact-Based Rendering: Harnessing Natural and Traditional Visual Media for More Expressive and Engaging 3D Visualizations",
            "data": "We introduce Artifact-Based Rendering (ABR), a framework of tools, algorithms, and processes that makes it possible to produce real, data-driven 3D scientific visualizations with a visual language derived entirely from colors, lines, textures, and forms created using traditional physical media or found in nature. A theory and process for ABR is presented to address three current needs: (i) designing better visualizations by making it possible for non-programmers to rapidly design and critique many alternative data-to-visual mappings; (ii) expanding the visual vocabulary used in scientific visualizations to depict increasingly complex multivariate data; (iii) bringing a more engaging, natural, and human-relatable handcrafted aesthetic to data visualization. New tools and algorithms to support ABR include front-end applets for constructing artifact-based colormaps, optimizing 3D scanned meshes for use in data visualization, and synthesizing textures from artifacts. These are complemented by an interactive rendering engine with custom algorithms and interfaces that demonstrate multiple new visual styles for depicting point, line, surface, and volume data. A within-the-research-team design study provides early evidence of the shift in visualization design processes that ABR is believed to enable when compared to traditional scientific visualization systems. Qualitative user feedback on applications to climate science and brain imaging support the utility of ABR for scientific discovery and public communication.",
            "url": "http://dx.doi.org/10.1109/TVCG.2019.2934260",
            "id": "r_154",
            "s_ids": [
                "s_217",
                "s_170",
                "s_664",
                "s_175",
                "s_425",
                "s_234",
                "s_409",
                "s_284",
                "s_421"
            ],
            "type": "rich",
            "x": 11.250597953796387,
            "y": 4.320864677429199
        },
        {
            "title": "Recirculation Surfaces for Flow Visualization",
            "data": "We present a formal approach to the visual analysis of recirculation in flows by introducing recirculation surfaces for 3D unsteady flow fields. Recirculation surfaces are the loci where massless particle integration returns to its starting point after some variable, finite integration. We give a rigorous definition of recirculation surfaces as 2-manifolds embedded in 5D space and study their properties. Based on this we construct an algorithm for their extraction, which searches for intersections of a recirculation surface with lines defined in 3D. This reduces the problem to a repeated search for critical points in 3D vector fields. We provide a uniform sampling of the search space paired with a surface reconstruction and visualize results. This way, we present the first algorithm for a comprehensive feature extraction in the 5D flow map of a 3D flow. The problem of finding isolated closed orbits in steady vector fields occurs as a special case of recirculation surfaces. This includes isolated closed orbits with saddle behavior. We show recirculation surfaces for a number of artificial and real flow data sets.",
            "url": "http://dx.doi.org/10.1109/TVCG.2018.2864813",
            "id": "r_155",
            "s_ids": [
                "s_270",
                "s_101",
                "s_653"
            ],
            "type": "rich",
            "x": 8.011056900024414,
            "y": 5.894285678863525
        },
        {
            "title": "CoDDA: A Flexible Copula-based Distribution Driven Analysis Framework for Large-Scale Multivariate Data",
            "data": "CoDDA (Copula-based Distribution Driven Analysis) is a flexible framework for large-scale multivariate datasets. A common strategy to deal with large-scale scientific simulation data is to partition the simulation domain and create statistical data summaries. Instead of storing the high-resolution raw data from the simulation, storing the compact statistical data summaries results in reduced storage overhead and alleviated I/O bottleneck. Such summaries, often represented in the form of statistical probability distributions, can serve various post-hoc analysis and visualization tasks. However, for multivariate simulation data using standard multivariate distributions for creating data summaries is not feasible. They are either storage inefficient or are computationally expensive to be estimated in simulation time (in situ) for large number of variables. In this work, using copula functions, we propose a flexible multivariate distribution-based data modeling and analysis framework that offers significant data reduction and can be used in an in situ environment. The framework also facilitates in storing the associated spatial information along with the multivariate distributions in an efficient representation. Using the proposed multivariate data summaries, we perform various multivariate post-hoc analyses like query-driven visualization and sampling-based visualization. We evaluate our proposed method on multiple real-world multivariate scientific datasets. To demonstrate the efficacy of our framework in an in situ environment, we apply it on a large-scale flow simulation.",
            "url": "http://dx.doi.org/10.1109/TVCG.2018.2864801",
            "id": "r_156",
            "s_ids": [
                "s_125",
                "s_521",
                "s_318",
                "s_345"
            ],
            "type": "rich",
            "x": 10.771910667419434,
            "y": 6.983599662780762
        },
        {
            "title": "Gaia Sky: Navigating the Gaia Catalog",
            "data": "In this paper, we present Gaia Sky, a free and open-source multiplatform 3D Universe system, developed since 2014 in the Data Processing and Analysis Consortium framework of ESA's Gaia mission. Gaia's data release 2 represents the largest catalog of the stars of our Galaxy, comprising 1.3 billion star positions, with parallaxes, proper motions, magnitudes, and colors. In this mission, Gaia Sky is the central tool for off-the-shelf visualization of these data, and for aiding production of outreach material. With its capabilities to effectively handle these data, to enable seamless navigation along the high dynamic range of distances, and at the same time to provide advanced visualization techniques including relativistic aberration and gravitational wave effects, currently no actively maintained cross-platform, modern, and open alternative exists.",
            "url": "http://dx.doi.org/10.1109/TVCG.2018.2864508",
            "id": "r_157",
            "s_ids": [
                "s_539",
                "s_340",
                "s_211",
                "s_641"
            ],
            "type": "rich",
            "x": 10.652742385864258,
            "y": 4.570015907287598
        },
        {
            "title": "Decomposition and Simplification of Multivariate Data using Pareto Sets",
            "data": "Topological and structural analysis of multivariate data is aimed at improving the understanding and usage of such data through identification of intrinsic features and structural relationships among multiple variables. We present two novel methods for simplifying so-called Pareto sets that describe such structural relationships. Such simplification is a precondition for meaningful visualization of structurally rich or noisy data. As a framework for simplification operations, we introduce a decomposition of the data domain into regions of equivalent structural behavior and the reachability graph that describes global connectivity of Pareto extrema. Simplification is then performed as a sequence of edge collapses in this graph; to determine a suitable sequence of such operations, we describe and utilize a comparison measure that reflects the changes to the data that each operation represents. We demonstrate and evaluate our methods on synthetic and real-world examples.",
            "url": "http://dx.doi.org/10.1109/TVCG.2014.2346447",
            "id": "r_158",
            "s_ids": [
                "s_607",
                "s_500",
                "s_220"
            ],
            "type": "rich",
            "x": 10.135826110839844,
            "y": 7.112730503082275
        },
        {
            "title": "Vessel Visualization using Curved Surface Reformation",
            "data": "Visualizations of vascular structures are frequently used in radiological investigations to detect and analyze vascular diseases. Obstructions of the blood flow through a vessel are one of the main interests of physicians, and several methods have been proposed to aid the visual assessment of calcifications on vessel walls. Curved Planar Reformation (CPR) is a wide-spread method that is designed for peripheral arteries which exhibit one dominant direction. To analyze the lumen of arbitrarily oriented vessels, Centerline Reformation (CR) has been proposed. Both methods project the vascular structures into 2D image space in order to reconstruct the vessel lumen. In this paper, we propose Curved Surface Reformation (CSR), a technique that computes the vessel lumen fully in 3D. This offers high-quality interactive visualizations of vessel lumina and does not suffer from problems of earlier methods such as ambiguous visibility cues or premature discretization of centerline data. Our method maintains exact visibility information until the final query of the 3D lumina data. We also present feedback from several domain experts.",
            "url": "http://dx.doi.org/10.1109/TVCG.2013.215",
            "id": "r_159",
            "s_ids": [
                "s_640",
                "s_591",
                "s_117",
                "s_81",
                "s_154",
                "s_207",
                "s_474",
                "s_162"
            ],
            "type": "rich",
            "x": 7.526188373565674,
            "y": 4.2119927406311035
        },
        {
            "title": "Sketching Uncertainty into Simulations",
            "data": "In a variety of application areas, the use of simulation steering in decision making is limited at best. Research focusing on this problem suggests that most user interfaces are too complex for the end user. Our goal is to let users create and investigate multiple, alternative scenarios without the need for special simulation expertise. To simplify the specification of parameters, we move from a traditional manipulation of numbers to a sketch-based input approach. Users steer both numeric parameters and parameters with a spatial correspondence by sketching a change onto the rendering. Special visualizations provide immediate visual feedback on how the sketches are transformed into boundary conditions of the simulation models. Since uncertainty with respect to many intertwined parameters plays an important role in planning, we also allow the user to intuitively setup complete value ranges, which are then automatically transformed into ensemble simulations. The interface and the underlying system were developed in collaboration with experts in the field of flood management. The real-world data they have provided has allowed us to construct scenarios used to evaluate the system. These were presented to a variety of flood response personnel, and their feedback is discussed in detail in the paper. The interface was found to be intuitive and relevant, although a certain amount of training might be necessary.",
            "url": "http://dx.doi.org/10.1109/TVCG.2012.261",
            "id": "r_160",
            "s_ids": [
                "s_261",
                "s_538",
                "s_106",
                "s_73",
                "s_474"
            ],
            "type": "rich",
            "x": 11.384389877319336,
            "y": 5.067293643951416
        },
        {
            "title": "An Interactive Framework for Visualization of Weather Forecast Ensembles",
            "data": "Numerical Weather Prediction (NWP) ensembles are commonly used to assess the uncertainty and confidence in weather forecasts. Spaghetti plots are conventional tools for meteorologists to directly examine the uncertainty exhibited by ensembles, where they simultaneously visualize isocontours of all ensemble members. To avoid visual clutter in practical usages, one needs to select a small number of informative isovalues for visual analysis. Moreover, due to the complex topology and variation of ensemble isocontours, it is often a challenging task to interpret the spaghetti plot for even a single isovalue in large ensembles. In this paper, we propose an interactive framework for uncertainty visualization of weather forecast ensembles that significantly improves and expands the utility of spaghetti plots in ensemble analysis. Complementary to state-of-the-art methods, our approach provides a complete framework for visual exploration of ensemble isocontours, including isovalue selection, interactive isocontour variability exploration, and interactive sub-region selection and re-analysis. Our framework is built upon the high-density clustering paradigm, where the mode structure of the density function is represented as a hierarchy of nested subsets of the data. We generalize the high-density clustering for isocontours and propose a bandwidth selection method for estimating the density function of ensemble isocontours. We present novel visualizations based on high-density clustering results, called the mode plot and the simplified spaghetti plot. The proposed mode plot visually encodes the structure provided by the high-density clustering result and summarizes the distribution of ensemble isocontours. It also enables the selection of subsets of interesting isocontours, which are interactively highlighted in a linked spaghetti plot for providing spatial context. To provide an interpretable overview of the positional variability of isocontours, our system allows for selection of informative isovalues from the simplified spaghetti plot. Due to the spatial variability of ensemble isocontours, the system allows for interactive selection and focus on sub-regions for local uncertainty and clustering re-analysis. We examine a number of ensemble datasets to establish the utility of our approach and discuss its advantages over state-of-the-art visual analysis tools for ensemble data.",
            "url": "http://dx.doi.org/10.1109/TVCG.2018.2864815",
            "id": "r_161",
            "s_ids": [
                "s_168",
                "s_152"
            ],
            "type": "rich",
            "x": 10.631891250610352,
            "y": 6.433703899383545
        },
        {
            "title": "Visual Analysis of Aneurysm Data using Statistical Graphics",
            "data": "This paper presents a framework to explore multi-field data of aneurysms occurring at intracranial and cardiac arteries by using statistical graphics. The rupture of an aneurysm is often a fatal scenario, whereas during treatment serious complications for the patient can occur. Whether an aneurysm ruptures or whether a treatment is successful depends on the interaction of different morphological such as wall deformation and thickness, and hemodynamic attributes like wall shear stress and pressure. Therefore, medical researchers are very interested in better understanding these relationships. However, the required analysis is a time-consuming process, where suspicious wall regions are difficult to detect due to the time-dependent behavior of the data. Our proposed visualization framework enables medical researchers to efficiently assess aneurysm risk and treatment options. This comprises a powerful set of views including 2D and 3D depictions of the aneurysm morphology as well as statistical plots of different scalar fields. Brushing and linking aids the user to identify interesting wall regions and to understand the influence of different attributes on the aneurysm's state. Moreover, a visual comparison of pre- and post-treatment as well as different treatment options is provided. Our analysis techniques are designed in collaboration with domain experts, e.g., physicians, and we provide details about the evaluation.",
            "url": "http://dx.doi.org/10.1109/TVCG.2018.2864509",
            "id": "r_162",
            "s_ids": [
                "s_97",
                "s_443",
                "s_20",
                "s_555",
                "s_585",
                "s_658"
            ],
            "type": "rich",
            "x": 7.429879188537598,
            "y": 4.097731113433838
        },
        {
            "title": "Probabilistic Asymptotic Decider for Topological Ambiguity Resolution in Level-Set Extraction for Uncertain 2D Data",
            "data": "We present a framework for the analysis of uncertainty in isocontour extraction. The marching squares (MS) algorithm for isocontour reconstruction generates a linear topology that is consistent with hyperbolic curves of a piecewise bilinear interpolation. The saddle points of the bilinear interpolant cause topological ambiguity in isocontour extraction. The midpoint decider and the asymptotic decider are well-known mathematical techniques for resolving topological ambiguities. The latter technique investigates the data values at the cell saddle points for ambiguity resolution. The uncertainty in data, however, leads to uncertainty in underlying bilinear interpolation functions for the MS algorithm, and hence, their saddle points. In our work, we study the behavior of the asymptotic decider when data at grid vertices is uncertain. First, we derive closed-form distributions characterizing variations in the saddle point values for uncertain bilinear interpolants. The derivation assumes uniform and nonparametric noise models, and it exploits the concept of ratio distribution for analytic formulations. Next, the probabilistic asymptotic decider is devised for ambiguity resolution in uncertain data using distributions of the saddle point values derived in the first step. Finally, the confidence in probabilistic topological decisions is visualized using a colormapping technique. We demonstrate the higher accuracy and stability of the probabilistic asymptotic decider in uncertain data with regard to existing decision frameworks, such as deciders in the mean field and the probabilistic midpoint decider, through the isocontour visualization of synthetic and real datasets.",
            "url": "http://dx.doi.org/10.1109/TVCG.2018.2864505",
            "id": "r_163",
            "s_ids": [
                "s_669",
                "s_309"
            ],
            "type": "rich",
            "x": 10.934867858886719,
            "y": 7.691064834594727
        },
        {
            "title": "An Intelligent System Approach for Probabilistic Volume Rendering Using Hierarchical 3D Convolutional Sparse Coding",
            "data": "In this paper, we propose a novel machine learning-based voxel classification method for highly-accurate volume rendering. Unlike conventional voxel classification methods that incorporate intensity-based features, the proposed method employs dictionary based features learned directly from the input data using hierarchical multi-scale 3D convolutional sparse coding, a novel extension of the state-of-the-art learning-based sparse feature representation method. The proposed approach automatically generates high-dimensional feature vectors in up to 75 dimensions, which are then fed into an intelligent system built on a random forest classifier for accurately classifying voxels from only a handful of selection scribbles made directly on the input data by the user. We apply the probabilistic transfer function to further customize and refine the rendered result. The proposed method is more intuitive to use and more robust to noise in comparison with conventional intensity-based classification methods. We evaluate the proposed method using several synthetic and real-world volume datasets, and demonstrate the methods usability through a user study.",
            "url": "http://dx.doi.org/10.1109/TVCG.2017.2744078",
            "id": "r_164",
            "s_ids": [
                "s_523",
                "s_670",
                "s_503",
                "s_352"
            ],
            "type": "rich",
            "x": 9.643988609313965,
            "y": 5.752618312835693
        },
        {
            "title": "Progressive Direct Volume-to-Volume Transformation",
            "data": "We present a novel technique to generate transformations between arbitrary volumes, providing both expressive distances and smooth interpolates. In contrast to conventional morphing or warping approaches, our technique requires no user guidance, intermediate representations (like extracted features), or blending, and imposes no restrictions regarding shape or structure. Our technique operates directly on the volumetric data representation, and while linear programming approaches could solve the underlying problem optimally, their polynomial complexity makes them infeasible for high-resolution volumes. We therefore propose a progressive refinement approach designed for parallel execution that is able to quickly deliver approximate results that are iteratively improved toward the optimum. On this basis, we further present a new approach for the streaming selection of time steps in temporal data that allows for the reconstruction of the full sequence with a user-specified error bound. We finally demonstrate the utility of our technique for different applications, compare our approach against alternatives, and evaluate its characteristics with a variety of different data sets.",
            "url": "http://dx.doi.org/10.1109/TVCG.2016.2599042",
            "id": "r_165",
            "s_ids": [
                "s_240",
                "s_277"
            ],
            "type": "rich",
            "x": 9.422710418701172,
            "y": 7.225931644439697
        },
        {
            "title": "Direct Multifield Volume Ray Casting of Fiber Surfaces",
            "data": "Multifield data are common in visualization. However, reducing these data to comprehensible geometry is a challenging problem. Fiber surfaces, an analogy of isosurfaces to bivariate volume data, are a promising new mechanism for understanding multifield volumes. In this work, we explore direct ray casting of fiber surfaces from volume data without any explicit geometry extraction. We sample directly along rays in domain space, and perform geometric tests in range space where fibers are defined, using a signed distance field derived from the control polygons. Our method requires little preprocess, and enables real-time exploration of data, dynamic modification and pixel-exact rendering of fiber surfaces, and support for higher-order interpolation in domain space. We demonstrate this approach on several bivariate datasets, including analysis of multi-field combustion data.",
            "url": "http://dx.doi.org/10.1109/TVCG.2016.2599040",
            "id": "r_166",
            "s_ids": [
                "s_39",
                "s_665",
                "s_229",
                "s_445",
                "s_273"
            ],
            "type": "rich",
            "x": 8.78370189666748,
            "y": 5.757442951202393
        },
        {
            "title": "Topological Analysis of Inertial Dynamics",
            "data": "Traditional vector field visualization has a close focus on velocity, and is typically constrained to the dynamics of massless particles. In this paper, we present a novel approach to the analysis of the force-induced dynamics of inertial particles. These forces can arise from acceleration fields such as gravitation, but also be dependent on the particle dynamics itself, as in the case of magnetism. Compared to massless particles, the velocity of an inertial particle is not determined solely by its position and time in a vector field. In contrast, its initial velocity can be arbitrary and impacts the dynamics over its entire lifetime. This leads to a four-dimensional problem for 2D setups, and a six-dimensional problem for the 3D case. Our approach avoids this increase in dimensionality and tackles the visualization by an integrated topological analysis approach. We demonstrate the utility of our approach using a synthetic time-dependent acceleration field, a system of magnetic dipoles, and N-body systems both in 2D and 3D.",
            "url": "http://dx.doi.org/10.1109/TVCG.2016.2599018",
            "id": "r_167",
            "s_ids": [
                "s_539",
                "s_340",
                "s_146",
                "s_643",
                "s_315",
                "s_641"
            ],
            "type": "rich",
            "x": 7.815420627593994,
            "y": 5.328747272491455
        },
        {
            "title": "Real-Time Molecular Visualization Supporting Diffuse Interreflections and Ambient Occlusion",
            "data": "Today molecular simulations produce complex data sets capturing the interactions of molecules in detail. Due to the complexity of this time-varying data, advanced visualization techniques are required to support its visual analysis. Current molecular visualization techniques utilize ambient occlusion as a global illumination approximation to improve spatial comprehension. Besides these shadow-like effects, interreflections are also known to improve the spatial comprehension of complex geometric structures. Unfortunately, the inherent computational complexity of interreflections would forbid interactive exploration, which is mandatory in many scenarios dealing with static and time-varying data. In this paper, we introduce a novel analytic approach for capturing interreflections of molecular structures in real-time. By exploiting the knowledge of the underlying space filling representations, we are able to reduce the required parameters and can thus apply symbolic regression to obtain an analytic expression for interreflections. We show how to obtain the data required for the symbolic regression analysis, and how to exploit our analytic solution to enhance interactive molecular visualizations.",
            "url": "http://dx.doi.org/10.1109/TVCG.2015.2467293",
            "id": "r_168",
            "s_ids": [
                "s_444",
                "s_567",
                "s_296",
                "s_183"
            ],
            "type": "rich",
            "x": 12.29493236541748,
            "y": 3.505007028579712
        },
        {
            "title": "Extracting, Tracking, and Visualizing Magnetic Flux Vortices in 3D Complex-Valued Superconductor Simulation Data",
            "data": "We propose a method for the vortex extraction and tracking of superconducting magnetic flux vortices for both structured and unstructured mesh data. In the Ginzburg-Landau theory, magnetic flux vortices are well-defined features in a complex-valued order parameter field, and their dynamics determine electromagnetic properties in type-II superconductors. Our method represents each vortex line (a 1D curve embedded in 3D space) as a connected graph extracted from the discretized field in both space and time. For a time-varying discrete dataset, our vortex extraction and tracking method is as accurate as the data discretization. We then apply 3D visualization and 2D event diagrams to the extraction and tracking results to help scientists understand vortex dynamics and macroscale superconductor behavior in greater detail than previously possible.",
            "url": "http://dx.doi.org/10.1109/TVCG.2015.2466838",
            "id": "r_169",
            "s_ids": [
                "s_136",
                "s_331",
                "s_9",
                "s_459",
                "s_56"
            ],
            "type": "rich",
            "x": 7.550332546234131,
            "y": 5.180576801300049
        },
        {
            "title": "Trend-Centric Motion Visualization: Designing and Applying a New Strategy for Analyzing Scientific Motion Collections",
            "data": "In biomechanics studies, researchers collect, via experiments or simulations, datasets with hundreds or thousands of trials, each describing the same type of motion (e.g., a neck flexion-extension exercise) but under different conditions (e.g., different patients, different disease states, pre- and post-treatment). Analyzing similarities and differences across all of the trials in these collections is a major challenge. Visualizing a single trial at a time does not work, and the typical alternative of juxtaposing multiple trials in a single visual display leads to complex, difficult-to-interpret visualizations. We address this problem via a new strategy that organizes the analysis around motion trends rather than trials. This new strategy matches the cognitive approach that scientists would like to take when analyzing motion collections. We introduce several technical innovations making trend-centric motion visualization possible. First, an algorithm detects a motion collection's trends via time-dependent clustering. Second, a 2D graphical technique visualizes how trials leave and join trends. Third, a 3D graphical technique, using a median 3D motion plus a visual variance indicator, visualizes the biomechanics of the set of trials within each trend. These innovations are combined to create an interactive exploratory visualization tool, which we designed through an iterative process in collaboration with both domain scientists and a traditionally-trained graphic designer. We report on insights generated during this design process and demonstrate the tool's effectiveness via a validation study with synthetic data and feedback from expert musculoskeletal biomechanics researchers who used the tool to analyze the effects of disc degeneration on human spinal kinematics.",
            "url": "http://dx.doi.org/10.1109/TVCG.2014.2346451",
            "id": "r_170",
            "s_ids": [
                "s_655",
                "s_391",
                "s_118",
                "s_317",
                "s_310",
                "s_654",
                "s_611",
                "s_421"
            ],
            "type": "rich",
            "x": 10.363268852233887,
            "y": 3.31115984916687
        },
        {
            "title": "ADR - Anatomy-Driven Reformation",
            "data": "Dedicated visualization methods are among the most important tools of modern computer-aided medical applications. Reformation methods such as Multiplanar Reformation or Curved Planar Reformation have evolved as useful tools that facilitate diagnostic and therapeutic work. In this paper, we present a novel approach that can be seen as a generalization of Multiplanar Reformation to curved surfaces. The main concept is to generate reformatted medical volumes driven by the individual anatomical geometry of a specific patient. This process generates flat views of anatomical structures that facilitate many tasks such as diagnosis, navigation and annotation. Our reformation framework is based on a non-linear as-rigid-as-possible volumetric deformation scheme that uses generic triangular surface meshes as input. To manage inevitable distortions during reformation, we introduce importance maps which allow controlling the error distribution and improving the overall visual quality in areas of elevated interest. Our method seamlessly integrates with well-established concepts such as the slice-based inspection of medical datasets and we believe it can improve the overall efficiency of many medical workflows. To demonstrate this, we additionally present an integrated visualization system and discuss several use cases that substantiate its benefits.",
            "url": "http://dx.doi.org/10.1109/TVCG.2014.2346405",
            "id": "r_171",
            "s_ids": [
                "s_438",
                "s_566",
                "s_37",
                "s_442",
                "s_585",
                "s_515"
            ],
            "type": "rich",
            "x": 8.06396770477295,
            "y": 3.848623752593994
        },
        {
            "title": "SeiVis: An Interactive Visual Subsurface Modeling Application",
            "data": "The most important resources to fulfill today's energy demands are fossil fuels, such as oil and natural gas. When exploiting hydrocarbon reservoirs, a detailed and credible model of the subsurface structures is crucial in order to minimize economic and ecological risks. Creating such a model is an inverse problem: reconstructing structures from measured reflection seismics. The major challenge here is twofold: First, the structures in highly ambiguous seismic data are interpreted in the time domain. Second, a velocity model has to be built from this interpretation to match the model to depth measurements from wells. If it is not possible to obtain a match at all positions, the interpretation has to be updated, going back to the first step. This results in a lengthy back and forth between the different steps, or in an unphysical velocity model in many cases. This paper presents a novel, integrated approach to interactively creating subsurface models from reflection seismics. It integrates the interpretation of the seismic data using an interactive horizon extraction technique based on piecewise global optimization with velocity modeling. Computing and visualizing the effects of changes to the interpretation and velocity model on the depth-converted model on the fly enables an integrated feedback loop that enables a completely new connection of the seismic data in time domain and well data in depth domain. Using a novel joint time/depth visualization, depicting side-by-side views of the original and the resulting depth-converted data, domain experts can directly fit their interpretation in time domain to spatial ground truth data. We have conducted a domain expert evaluation, which illustrates that the presented workflow enables the creation of exact subsurface models much more rapidly than previous approaches.",
            "url": "http://dx.doi.org/10.1109/TVCG.2012.259",
            "id": "r_172",
            "s_ids": [
                "s_369",
                "s_540",
                "s_550",
                "s_634",
                "s_509",
                "s_300"
            ],
            "type": "rich",
            "x": 10.297612190246582,
            "y": 5.513439655303955
        },
        {
            "title": "Interactive Visualization of Atmospheric Effects for Celestial Bodies",
            "data": "We present an atmospheric model tailored for the interactive visualization of planetary surfaces. As the exploration of the solar system is progressing with increasingly accurate missions and instruments, the faithful visualization of planetary environments is gaining increasing interest in space research, mission planning, and science communication and education. Atmospheric effects are crucial in data analysis and to provide contextual information for planetary data. Our model correctly accounts for the non-linear path of the light inside the atmosphere (in Earth's case), the light absorption effects by molecules and dust particles, such as the ozone layer and the Martian dust, and a wavelength-dependent phase function for Mie scattering. The mode focuses on interactivity, versatility, and customization, and a comprehensive set of interactive controls make it possible to adapt its appearance dynamically. We demonstrate our results using Earth and Mars as examples. However, it can be readily adapted for the exploration of other atmospheres found on, for example, of exoplanets. For Earth's atmosphere, we visually compare our results with pictures taken from the International Space Station and against the CIE clear sky model. The Martian atmosphere is reproduced based on available scientific data, feedback from domain experts, and is compared to images taken by the Curiosity rover. The work presented here has been implemented in the OpenSpace system, which enables interactive parameter setting and real-time feedback visualization targeting presentations in a wide range of environments, from immersive dome theaters to virtual reality headsets.",
            "url": "http://dx.doi.org/10.1109/TVCG.2020.3030333",
            "id": "r_173",
            "s_ids": [
                "s_651",
                "s_457",
                "s_620",
                "s_599",
                "s_244",
                "s_344"
            ],
            "type": "rich",
            "x": 10.638250350952148,
            "y": 4.762228488922119
        },
        {
            "title": "Deadeye Visualization Revisited: Investigation of Preattentiveness and Applicability in Virtual Environments",
            "data": "Visualizations rely on highlighting to attract and guide our attention. To make an object of interest stand out independently from a number of distractors, the underlying visual cue, e.g., color, has to be preattentive. In our prior work, we introduced Deadeye as an instantly recognizable highlighting technique that works by rendering the target object for one eye only. In contrast to prior approaches, Deadeye excels by not modifying any visual properties of the target. However, in the case of 2D visualizations, the method requires an additional setup to allow dichoptic presentation, which is a considerable drawback. As a follow-up to requests from the community, this paper explores Deadeye as a highlighting technique for 3D visualizations, because such stereoscopic scenarios support dichoptic presentation out of the box. Deadeye suppresses binocular disparities for the target object, so we cannot assume the applicability of our technique as a given fact. With this motivation, the paper presents quantitative evaluations of Deadeye in VR, including configurations with multiple heterogeneous distractors as an important robustness challenge. After confirming the preserved preattentiveness (all average accuracies above 90%) under such real-world conditions, we explore VR volume rendering as an example application scenario for Deadeye. We depict a possible workflow for integrating our technique, conduct an exploratory survey to demonstrate benefits and limitations, and finally provide related design implications.",
            "url": "http://dx.doi.org/10.1109/TVCG.2019.2934370",
            "id": "r_174",
            "s_ids": [
                "s_53",
                "s_516",
                "s_26",
                "s_427"
            ],
            "type": "rich",
            "x": 9.98121452331543,
            "y": 3.217468738555908
        },
        {
            "title": "On the Treatment of Field Quantities and Elemental Continuity in FEM Solutions",
            "data": "As the finite element method (FEM) and the finite volume method (FVM), both traditional and high-order variants, continue their proliferation into various applied engineering disciplines, it is important that the visualization techniques and corresponding data analysis tools that act on the results produced by these methods faithfully represent the underlying data. To state this in another way: the interpretation of data generated by simulation needs to be consistent with the numerical schemes that underpin the specific solver technology. As the verifiable visualization literature has demonstrated: visual artifacts produced by the introduction of either explicit or implicit data transformations, such as data resampling, can sometimes distort or even obfuscate key scientific features in the data. In this paper, we focus on the handling of elemental continuity, which is often only<inline-formula><tex-math notation=\"LaTeX\">$C^{0}$</tex-math><alternatives><inline-graphic xlink:href=\"24tvcg01-jallepalli-2744058-ieq-1-source.tif\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"/></alternatives></inline-formula>continuous or piecewise discontinuous, when visualizing primary or derived fields from FEM or FVM simulations. We demonstrate that traditional data handling and visualization of these fields introduce visual errors. In addition, we show how the use of the recently proposed line-SIAC filter provides a way of handling elemental continuity issues in an accuracy-conserving manner with the added benefit of casting the data in a smooth context even if the representation is element discontinuous.",
            "url": "http://dx.doi.org/10.1109/TVCG.2017.2744058",
            "id": "r_175",
            "s_ids": [
                "s_489",
                "s_542",
                "s_68",
                "s_649",
                "s_453"
            ],
            "type": "rich",
            "x": 9.869104385375977,
            "y": 5.354486465454102
        },
        {
            "title": "Inviwo ??? An extensible, multi-purpose visualization framework",
            "data": "To enable visualization research impacting other scientific domains, the availability of easy-to-use visualization frameworks is essential. Nevertheless, an easy-to-use system also has to be adapted to the capabilities of modern hardware architectures, as only this allows for realizing interactive visualizations. With this trade-off in mind, we have designed and realized the cross-platform Inviwo (Interactive Visualization Workshop) visualization framework, that supports both interactive visualization research as well as efficient visualization application development and deployment. In this poster we give an overview of the architecture behind Inviwo, and show how its design enables us and other researchers to realize their visualization ideas efficiently. Inviwo consists of a modern and lightweight, graphics independent core, which is extended by optional modules that encapsulate visualization algorithms, well-known utility libraries and commonly used parallel-processing APIs (such as OpenGL and OpenCL). The core enables a simplistic structure for creating bridges between the different modules regarding data transfer across architecture and devices with an easy-to-use screen graph and minimalistic programming. Making the base structures in a modern way while providing intuitive methods of extending the functionality and creating modules based on other modules, we hope that Inviwo can help the visualization community to perform research through a rapid-prototyping design and GUI, while at the same time allowing users to take advantage of the results implemented in the system in any way they desire later on. Inviwo is publicly available at www.inviwo.org, and can be used freely by anyone under a permissive free software license (Simplified BSD).",
            "url": "http://dx.doi.org/10.1109/SciVis.2015.7429514",
            "id": "r_176",
            "s_ids": [
                "s_250",
                "s_197",
                "s_142",
                "s_673",
                "s_66",
                "s_546",
                "s_183"
            ],
            "type": "rich",
            "x": 11.291733741760254,
            "y": 4.349414825439453
        },
        {
            "title": "A Classification of User Tasks in Visual Analysis of Volume Data",
            "data": "Empirical findings from studies in one scientific domain have very limited applicability to other domains, unless we formally establish deeper insights on the generalizability of task types. We present a domain-independent classification of visual analysis tasks with volume visualizations. This taxonomy will help researchers design experiments, ensure coverage, and generate hypotheses in empirical studies with volume datasets. To develop our taxonomy, we first interviewed scientists working with spatial data in disparate domains. We then ran a survey to evaluate the design participants in which were scientists and professionals from around the world, working with volume data in various scientific domains. Respondents agreed substantially with our taxonomy design, but also suggested important refinements. We report the results in the form of a goal-based generic categorization of visual analysis tasks with volume visualizations. Our taxonomy covers tasks performed with a wide variety of volume datasets.",
            "url": "http://dx.doi.org/10.1109/SciVis.2015.7429485",
            "id": "r_177",
            "s_ids": [
                "s_167",
                "s_226",
                "s_363",
                "s_5"
            ],
            "type": "rich",
            "x": 11.837074279785156,
            "y": 4.974132537841797
        },
        {
            "title": "Improving the Usability of Virtual Reality Neuron Tracing with Topological Elements",
            "data": "Researchers in the field of connectomics are working to reconstruct a map of neural connections in the brain in order to understand at a fundamental level how the brain processes information. Constructing this wiring diagram is done by tracing neurons through high-resolution image stacks acquired with fluorescence microscopy imaging techniques. While a large number of automatic tracing algorithms have been proposed, these frequently rely on local features in the data and fail on noisy data or ambiguous cases, requiring time-consuming manual correction. As a result, manual and semi-automatic tracing methods remain the state-of-the-art for creating accurate neuron reconstructions. We propose a new semi-automatic method that uses topological features to guide users in tracing neurons and integrate this method within a virtual reality (VR) framework previously used for manual tracing. Our approach augments both visualization and interaction with topological elements, allowing rapid understanding and tracing of complex morphologies. In our pilot study, neuroscientists demonstrated a strong preference for using our tool over prior approaches, reported less fatigue during tracing, and commended the ability to better understand possible paths and alternatives. Quantitative evaluation of the traces reveals that users' tracing speed increased, while retaining similar accuracy compared to a fully manual approach.",
            "url": "http://dx.doi.org/10.1109/TVCG.2020.3030363",
            "id": "r_178",
            "s_ids": [
                "s_298",
                "s_576",
                "s_100",
                "s_660",
                "s_466",
                "s_272",
                "s_486",
                "s_273"
            ],
            "type": "rich",
            "x": 11.308235168457031,
            "y": 3.2098724842071533
        },
        {
            "title": "OpenSpace: A System for Astrographics",
            "data": "Human knowledge about the cosmos is rapidly increasing as instruments and simulations are generating new data supporting the formation of theory and understanding of the vastness and complexity of the universe. OpenSpace is a software system that takes on the mission of providing an integrated view of all these sources of data and supports interactive exploration of the known universe from the millimeter scale showing instruments on spacecrafts to billions of light years when visualizing the early universe. The ambition is to support research in astronomy and space exploration, science communication at museums and in planetariums as well as bringing exploratory astrographics to the class room. There is a multitude of challenges that need to be met in reaching this goal such as the data variety, multiple spatio-temporal scales, collaboration capabilities, etc. Furthermore, the system has to be flexible and modular to enable rapid prototyping and inclusion of new research results or space mission data and thereby shorten the time from discovery to dissemination. To support the different use cases the system has to be hardware agnostic and support a range of platforms and interaction paradigms. In this paper we describe how OpenSpace meets these challenges in an open source effort that is paving the path for the next generation of interactive astrographics.",
            "url": "http://dx.doi.org/10.1109/TVCG.2019.2934259",
            "id": "r_179",
            "s_ids": [
                "s_457",
                "s_244",
                "s_433",
                "s_651",
                "s_501",
                "s_79",
                "s_476",
                "s_620",
                "s_344",
                "s_599"
            ],
            "type": "rich",
            "x": 10.920976638793945,
            "y": 4.580874919891357
        },
        {
            "title": "Anisotropic Ambient Volume Shading",
            "data": "We present a novel method to compute anisotropic shading for direct volume rendering to improve the perception of the orientation and shape of surface-like structures. We determine the scale-aware anisotropy of a shading point by analyzing its ambient region. We sample adjacent points with similar scalar values to perform a principal component analysis by computing the eigenvectors and eigenvalues of the covariance matrix. In particular, we estimate the tangent directions, which serve as the tangent frame for anisotropic bidirectional reflectance distribution functions. Moreover, we exploit the ratio of the eigenvalues to measure the magnitude of the anisotropy at each shading point. Altogether, this allows us to model a data-driven, smooth transition from isotropic to strongly anisotropic volume shading. In this way, the shape of volumetric features can be enhanced significantly by aligning specular highlights along the principal direction of anisotropy. Our algorithm is independent of the transfer function, which allows us to compute all shading parameters once and store them with the data set. We integrated our method in a GPU-based volume renderer, which offers interactive control of the transfer function, light source positions, and viewpoint. Our results demonstrate the benefit of anisotropic shading for visualization to achieve data-driven local illumination for improved perception compared to isotropic shading.",
            "url": "http://dx.doi.org/10.1109/TVCG.2015.2467963",
            "id": "r_180",
            "s_ids": [
                "s_147",
                "s_411"
            ],
            "type": "rich",
            "x": 9.543360710144043,
            "y": 4.31347131729126
        },
        {
            "title": "Visualization of Astronomical Nebulae via Distributed Multi-GPU Compressed Sensing Tomography",
            "data": "The 3D visualization of astronomical nebulae is a challenging problem since only a single 2D projection is observable from our fixed vantage point on Earth. We attempt to generate plausible and realistic looking volumetric visualizations via a tomographic approach that exploits the spherical or axial symmetry prevalent in some relevant types of nebulae. Different types of symmetry can be implemented by using different randomized distributions of virtual cameras. Our approach is based on an iterative compressed sensing reconstruction algorithm that we extend with support for position-dependent volumetric regularization and linear equality constraints. We present a distributed multi-GPU implementation that is capable of reconstructing high-resolution datasets from arbitrary projections. Its robustness and scalability are demonstrated for astronomical imagery from the Hubble Space Telescope. The resulting volumetric data is visualized using direct volume rendering. Compared to previous approaches, our method preserves a much higher amount of detail and visual variety in the 3D visualization, especially for objects with only approximate symmetry.",
            "url": "http://dx.doi.org/10.1109/TVCG.2012.281",
            "id": "r_181",
            "s_ids": [
                "s_524",
                "s_147",
                "s_431",
                "s_536",
                "s_139",
                "s_130",
                "s_238"
            ],
            "type": "rich",
            "x": 10.020633697509766,
            "y": 4.414642810821533
        },
        {
            "title": "Visual Steering and Verification of Mass Spectrometry Data Factorization in Air Quality Research",
            "data": "The study of aerosol composition for air quality research involves the analysis of high-dimensional single particle mass spectrometry data. We describe, apply, and evaluate a novel interactive visual framework for dimensionality reduction of such data. Our framework is based on non-negative matrix factorization with specifically defined regularization terms that aid in resolving mass spectrum ambiguity. Thereby, visualization assumes a key role in providing insight into and allowing to actively control a heretofore elusive data processing step, and thus enabling rapid analysis meaningful to domain scientists. In extending existing black box schemes, we explore design choices for visualizing, interacting with, and steering the factorization process to produce physically meaningful results. A domain-expert evaluation of our system performed by the air quality research experts involved in this effort has shown that our method and prototype admits the finding of unambiguous and physically correct lower-dimensional basis transformations of mass spectrometry data at significantly increased speed and a higher degree of ease.",
            "url": "http://dx.doi.org/10.1109/TVCG.2012.280",
            "id": "r_182",
            "s_ids": [
                "s_98",
                "s_413",
                "s_220",
                "s_361",
                "s_483",
                "s_295",
                "s_365"
            ],
            "type": "rich",
            "x": 10.316225051879883,
            "y": 6.546288967132568
        },
        {
            "title": "Lagrangian Coherent Structures for Design Analysis of Revolving Doors",
            "data": "Room air flow and air exchange are important aspects for the design of energy-efficient buildings. As a result, simulations are increasingly used prior to construction to achieve an energy-efficient design. We present a visual analysis of air flow generated at building entrances, which uses a combination of revolving doors and air curtains. The resulting flow pattern is challenging because of two interacting flow patterns: On the one hand, the revolving door acts as a pump, on the other hand, the air curtain creates a layer of uniformly moving warm air between the interior of the building and the revolving door. Lagrangian coherent structures (LCS), which by definition are flow barriers, are the method of choice for visualizing the separation and recirculation behavior of warm and cold air flow. The extraction of LCS is based on the finite-time Lyapunov exponent (FTLE) and makes use of a ridge definition which is consistent with the concept of weak LCS. Both FTLE computation and ridge extraction are done in a robust and efficient way by making use of the fast Fourier transform for computing scale-space derivatives.",
            "url": "http://dx.doi.org/10.1109/TVCG.2012.243",
            "id": "r_183",
            "s_ids": [
                "s_462",
                "s_336",
                "s_379",
                "s_538",
                "s_564",
                "s_430",
                "s_103",
                "s_215"
            ],
            "type": "rich",
            "x": 8.528419494628906,
            "y": 5.398994445800781
        },
        {
            "title": "ChemVA: Interactive Visual Analysis of Chemical Compound Similarity in Virtual Screening",
            "data": "In the modern drug discovery process, medicinal chemists deal with the complexity of analysis of large ensembles of candidate molecules. Computational tools, such as dimensionality reduction (DR) and classification, are commonly used to efficiently process the multidimensional space of features. These underlying calculations often hinder interpretability of results and prevent experts from assessing the impact of individual molecular features on the resulting representations. To provide a solution for scrutinizing such complex data, we introduce ChemVA, an interactive application for the visual exploration of large molecular ensembles and their features. Our tool consists of multiple coordinated views: Hexagonal view, Detail view, 3D view, Table view, and a newly proposed Difference view designed for the comparison of DR projections. These views display DR projections combined with biological activity, selected molecular features, and confidence scores for each of these projections. This conjunction of views allows the user to drill down through the dataset and to efficiently select candidate compounds. Our approach was evaluated on two case studies of finding structurally similar ligands with similar binding affinity to a target protein, as well as on an external qualitative evaluation. The results suggest that our system allows effective visual inspection and comparison of different high-dimensional molecular representations. Furthermore, ChemVA assists in the identification of candidate compounds while providing information on the certainty behind different molecular representations.",
            "url": "http://dx.doi.org/10.1109/TVCG.2020.3030438",
            "id": "r_184",
            "s_ids": [
                "s_48",
                "s_376",
                "s_263",
                "s_141",
                "s_306",
                "s_419",
                "s_583",
                "s_580",
                "s_448"
            ],
            "type": "rich",
            "x": 12.367596626281738,
            "y": 3.4548985958099365
        },
        {
            "title": "A Visualization Framework for Multi-scale Coherent Structures in Taylor-Couette Turbulence",
            "data": "Taylor-Couette flow (TCF) is the turbulent fluid motion created between two concentric and independently rotating cylinders. It has been heavily researched in fluid mechanics thanks to the various nonlinear dynamical phenomena that are exhibited in the flow. As many dense coherent structures overlap each other in TCF, it is challenging to isolate and visualize them, especially when the cylinder rotation ratio is changing. Previous approaches rely on 2D cross sections to study TCF due to its simplicity, which cannot provide the complete information of TCF. In the meantime, standard visualization techniques, such as volume rendering / iso-surfacing of certain attributes and the placement of integral curves/surfaces, usually produce cluttered visualization. To address this challenge and to support domain experts in the analysis of TCF, we developed a visualization framework to separate large-scale structures from the dense, small-scale structures and provide an effective visual representation of these structures. Instead of using a single physical attribute as the standard approach which cannot efficiently separate structures in different scales for TCF, we adapt the feature level-set method to combine multiple attributes and use them as a filter to separate large- and small-scale structures. To visualize these structures, we apply the iso-surface extraction on the kernel density estimate of the distance field generated from the feature level-set. The proposed methods successfully reveal 3D large-scale coherent structures of TCF with different control parameter settings, which are difficult to achieve with the conventional methods.",
            "url": "http://dx.doi.org/10.1109/TVCG.2020.3028892",
            "id": "r_185",
            "s_ids": [
                "s_51",
                "s_424",
                "s_157"
            ],
            "type": "rich",
            "x": 8.355687141418457,
            "y": 5.508585453033447
        },
        {
            "title": "Temporal Views of Flattened Mitral Valve Geometries",
            "data": "The mitral valve, one of the four valves in the human heart, controls the bloodflow between the left atrium and ventricle and may suffer from various pathologies. Malfunctioning valves can be treated by reconstructive surgeries, which have to be carefully planned and evaluated. While current research focuses on the modeling and segmentation of the valve, we base our work on existing segmentations of patient-specific mitral valves, that are also time-resolved ($3\\mathrm{D}+\\mathrm{t}$) over the cardiac cycle. The interpretation of the data can be ambiguous, due to the complex surface of the valve and multiple time steps. We therefore propose a software prototype to analyze such $3\\mathrm{D}+\\mathrm{t}$ data, by extracting pathophysiological parameters and presenting them via dimensionally reduced visualizations. For this, we rely on an existing algorithm to unroll the convoluted valve surface towards a flattened 2D representation. In this paper, we show that the $3\\mathrm{D}+\\mathrm{t}$ data can be transferred to 3D or 2D representations in a way that allows the domain expert to faithfully grasp important aspects of the cardiac cycle. In this course, we not only consider common pathophysiological parameters, but also introduce new observations that are derived from landmarks within the segmentation model. Our analysis techniques were developed in collaboration with domain experts and a survey showed that the insights have the potential to support mitral valve diagnosis and the comparison of the pre- and post-operative condition of a patient.",
            "url": "http://dx.doi.org/10.1109/TVCG.2019.2934337",
            "id": "r_186",
            "s_ids": [
                "s_452",
                "s_492",
                "s_642",
                "s_334",
                "s_658"
            ],
            "type": "rich",
            "x": 7.476317882537842,
            "y": 4.20993709564209
        },
        {
            "title": "Culling for Extreme-Scale Segmentation Volumes: A Hybrid Deterministic and Probabilistic Approach",
            "data": "With the rapid increase in raw volume data sizes, such as terabyte-sized microscopy volumes, the corresponding segmentation label volumes have become extremely large as well. We focus on integer label data, whose efficient representation in memory, as well as fast random data access, pose an even greater challenge than the raw image data. Often, it is crucial to be able to rapidly identify which segments are located where, whether for empty space skipping for fast rendering, or for spatial proximity queries. We refer to this process as<i>culling</i>. In order to enable efficient culling of millions of labeled segments, we present a novel hybrid approach that combines deterministic and probabilistic representations of label data in a data-adaptive hierarchical data structure that we call the label list tree. In each node, we adaptively encode label data using either a probabilistic constant-time access representation for fast conservative culling, or a deterministic logarithmic-time access representation for exact queries. We choose the best data structures for representing the labels of each spatial region while building the label list tree. At run time, we further employ a novel<i>query-adaptive</i>culling strategy. While filtering a query down the tree, we prune it successively, and in each node adaptively select the representation that is best suited for evaluating the pruned query, depending on its size. We show an analysis of the efficiency of our approach with several large data sets from connectomics, including a brain scan with more than 13 million labeled segments, and compare our method to conventional culling approaches. Our approach achieves significant reductions in storage size as well as faster query times.",
            "url": "http://dx.doi.org/10.1109/TVCG.2018.2864847",
            "id": "r_187",
            "s_ids": [
                "s_557",
                "s_88",
                "s_578",
                "s_544",
                "s_561",
                "s_300"
            ],
            "type": "rich",
            "x": 9.521774291992188,
            "y": 7.811023235321045
        },
        {
            "title": "Deadeye: A Novel Preattentive Visualization Technique Based on Dichoptic Presentation",
            "data": "Preattentive visual features such as hue or flickering can effectively draw attention to an object of interest - for instance, an important feature in a scientific visualization. These features appear to pop out and can be recognized by our visual system, independently from the number of distractors. Most cues do not take advantage of the fact that most humans have two eyes. In cases where binocular vision is applied, it is almost exclusively used to convey depth by exposing stereo pairs. We present Deadeye, a novel preattentive visualization technique based on presenting different stimuli to each eye. The target object is rendered for one eye only and is instantly detected by our visual system. In contrast to existing cues, Deadeye does not modify any visual properties of the target and, thus, is particularly suited for visualization applications. Our evaluation confirms that Deadeye is indeed perceived preattentively. We also explore a conjunction search based on our technique and show that, in contrast to 3D depth, the task cannot be processed in parallel.",
            "url": "http://dx.doi.org/10.1109/TVCG.2018.2864498",
            "id": "r_188",
            "s_ids": [
                "s_53",
                "s_427"
            ],
            "type": "rich",
            "x": 10.008359909057617,
            "y": 3.1614742279052734
        },
        {
            "title": "Synteny Explorer: An Interactive Visualization Application for Teaching Genome Evolution",
            "data": "Rapid advances in biology demand new tools for more active research dissemination and engaged teaching. This paper presents Synteny Explorer, an interactive visualization application designed to let college students explore genome evolution of mammalian species. The tool visualizes synteny blocks: segments of homologous DNA shared between various extant species that can be traced back or reconstructed in extinct, ancestral species. We take a karyogram-based approach to create an interactive synteny visualization, leading to a more appealing and engaging design for undergraduate-level genome evolution education. For validation, we conduct three user studies: two focused studies on color and animation design choices and a larger study that performs overall system usability testing while comparing our karyogram-based designs with two more common genome mapping representations in an educational context. While existing views communicate the same information, study participants found the interactive, karyogram-based views much easier and likable to use. We additionally discuss feedback from biology and genomics faculty, who judge Synteny Explorer's fitness for use in classrooms.",
            "url": "http://dx.doi.org/10.1109/TVCG.2016.2598789",
            "id": "r_189",
            "s_ids": [
                "s_308",
                "s_498",
                "s_647",
                "s_441",
                "s_371",
                "s_182",
                "s_569",
                "s_75"
            ],
            "type": "rich",
            "x": 11.57893180847168,
            "y": 3.877211570739746
        },
        {
            "title": "Multi-field Pattern Matching based on Sparse Feature Sampling",
            "data": "We present an approach to pattern matching in 3D multi-field scalar data. Existing pattern matching algorithms work on single scalar or vector fields only, yet many numerical simulations output multi-field data where only a joint analysis of multiple fields describes the underlying phenomenon fully. Our method takes this into account by bundling information from multiple fields into the description of a pattern. First, we extract a sparse set of features for each 3D scalar field using the 3D SIFT algorithm (Scale-Invariant Feature Transform). This allows for a memory-saving description of prominent features in the data with invariance to translation, rotation, and scaling. Second, the user defines a pattern as a set of SIFT features in multiple fields by e.g. brushing a region of interest. Third, we locate and rank matching patterns in the entire data set. Experiments show that our algorithm is efficient in terms of required memory and computational efforts.",
            "url": "http://dx.doi.org/10.1109/TVCG.2015.2467292",
            "id": "r_190",
            "s_ids": [
                "s_257",
                "s_406",
                "s_19"
            ],
            "type": "rich",
            "x": 9.589593887329102,
            "y": 6.677229404449463
        },
        {
            "title": "Boundary Aware Reconstruction of Scalar Fields",
            "data": "In visualization, the combined role of data reconstruction and its classification plays a crucial role. In this paper we propose a novel approach that improves classification of different materials and their boundaries by combining information from the classifiers at the reconstruction stage. Our approach estimates the targeted materials' local support before performing multiple material-specific reconstructions that prevent much of the misclassification traditionally associated with transitional regions and transfer function (TF) design. With respect to previously published methods our approach offers a number of improvements and advantages. For one, it does not rely on TFs acting on derivative expressions, therefore it is less sensitive to noisy data and the classification of a single material does not depend on specialized TF widgets or specifying regions in a multidimensional TF. Additionally, improved classification is attained without increasing TF dimensionality, which promotes scalability to multivariate data. These aspects are also key in maintaining low interaction complexity. The results are simple-to-achieve visualizations that better comply with the user's understanding of discrete features within the studied object.",
            "url": "http://dx.doi.org/10.1109/TVCG.2014.2346351",
            "id": "r_191",
            "s_ids": [
                "s_389",
                "s_673",
                "s_599",
                "s_244"
            ],
            "type": "rich",
            "x": 9.944677352905273,
            "y": 6.546102046966553
        },
        {
            "title": "Derived Metric Tensors for Flow Surface Visualization",
            "data": "Integral flow surfaces constitute a widely used flow visualization tool due to their capability to convey important flow information such as fluid transport, mixing, and domain segmentation. Current flow surface rendering techniques limit their expressiveness, however, by focusing virtually exclusively on displacement visualization, visually neglecting the more complex notion of deformation such as shearing and stretching that is central to the field of continuum mechanics. To incorporate this information into the flow surface visualization and analysis process, we derive a metric tensor field that encodes local surface deformations as induced by the velocity gradient of the underlying flow field. We demonstrate how properties of the resulting metric tensor field are capable of enhancing present surface visualization and generation methods and develop novel surface querying, sampling, and visualization techniques. The provided results show how this step towards unifying classic flow visualization and more advanced concepts from continuum mechanics enables more detailed and improved flow analysis.",
            "url": "http://dx.doi.org/10.1109/TVCG.2012.211",
            "id": "r_192",
            "s_ids": [
                "s_646",
                "s_332"
            ],
            "type": "rich",
            "x": 8.017913818359375,
            "y": 5.670865535736084
        },
        {
            "title": "Ray Tracing Structured AMR Data Using ExaBricks",
            "data": "Structured Adaptive Mesh Refinement (Structured AMR) enables simulations to adapt the domain resolution to save computation and storage, and has become one of the dominant data representations used by scientific simulations; however, efficiently rendering such data remains a challenge. We present an efficient approach for volume- and iso-surface ray tracing of Structured AMR data on GPU-equipped workstations, using a combination of two different data structures. Together, these data structures allow a ray tracing based renderer to quickly determine which segments along the ray need to be integrated and at what frequency, while also providing quick access to all data values required for a smooth sample reconstruction kernel. Our method makes use of the RTX ray tracing hardware for surface rendering, ray marching, space skipping, and adaptive sampling; and allows for interactive changes to the transfer function and implicit iso-surfacing thresholds. We demonstrate that our method achieves high performance with little memory overhead, enabling interactive high quality rendering of complex AMR data sets on individual GPU workstations.",
            "url": "http://dx.doi.org/10.1109/TVCG.2020.3030470",
            "id": "r_193",
            "s_ids": [
                "s_632",
                "s_105",
                "s_576",
                "s_100",
                "s_259",
                "s_273"
            ],
            "type": "rich",
            "x": 9.819816589355469,
            "y": 4.715269565582275
        },
        {
            "title": "Uncertainty-Oriented Ensemble Data Visualization and Exploration using Variable Spatial Spreading",
            "data": "As an important method of handling potential uncertainties in numerical simulations, ensemble simulation has been widely applied in many disciplines. Visualization is a promising and powerful ensemble simulation analysis method. However, conventional visualization methods mainly aim at data simplification and highlighting important information based on domain expertise instead of providing a flexible data exploration and intervention mechanism. Trial-and-error procedures have to be repeatedly conducted by such approaches. To resolve this issue, we propose a new perspective of ensemble data analysis using the attribute variable dimension as the primary analysis dimension. Particularly, we propose a variable uncertainty calculation method based on variable spatial spreading. Based on this method, we design an interactive ensemble analysis framework that provides a flexible interactive exploration of the ensemble data. Particularly, the proposed spreading curve view, the region stability heat map view, and the temporal analysis view, together with the commonly used 2D map view, jointly support uncertainty distribution perception, region selection, and temporal analysis, as well as other analysis requirements. We verify our approach by analyzing a real-world ensemble simulation dataset. Feedback collected from domain experts confirms the efficacy of our framework.",
            "url": "http://dx.doi.org/10.1109/TVCG.2020.3030377",
            "id": "r_194",
            "s_ids": [
                "s_34",
                "s_195",
                "s_428",
                "s_434",
                "s_460"
            ],
            "type": "rich",
            "x": 11.183948516845703,
            "y": 6.4268107414245605
        },
        {
            "title": "High-throughput feature extraction for measuring attributes of deforming open-cell foams",
            "data": "Metallic open-cell foams are promising structural materials with applications in multifunctional systems such as biomedical implants, energy absorbers in impact, noise mitigation, and batteries. There is a high demand for means to understand and correlate the design space of material performance metrics to the material structure in terms of attributes such as density, ligament and node properties, void sizes, and alignments. Currently, X-ray Computed Tomography (CT) scans of these materials are segmented either manually or with skeletonization approaches that may not accurately model the variety of shapes present in nodes and ligaments, especially irregularities that arise from manufacturing, image artifacts, or deterioration due to compression. In this paper, we present a new workflow for analysis of open-cell foams that combines a new density measurement to identify nodal structures, and topological approaches to identify ligament structures between them. Additionally, we provide automated measurement of foam properties. We demonstrate stable extraction of features and time-tracking in an image sequence of a foam being compressed. Our approach allows researchers to study larger and more complex foams than could previously be segmented only manually, and enables the high-throughput analysis needed to predict future foam performance.",
            "url": "http://dx.doi.org/10.1109/TVCG.2019.2934620",
            "id": "r_195",
            "s_ids": [
                "s_466",
                "s_660",
                "s_214",
                "s_171",
                "s_50",
                "s_159",
                "s_273"
            ],
            "type": "rich",
            "x": 9.158770561218262,
            "y": 5.200885772705078
        },
        {
            "title": "Extraction and Visual Analysis of Potential Vorticity Banners around the Alps",
            "data": "Potential vorticity is among the most important scalar quantities in atmospheric dynamics. For instance, potential vorticity plays a key role in particularly strong wind peaks in extratropical cyclones and it is able to explain the occurrence of frontal rain bands. Potential vorticity combines the key quantities of atmospheric dynamics, namely rotation and stratification. Under suitable wind conditions elongated banners of potential vorticity appear in the lee of mountains. Their role in atmospheric dynamics has recently raised considerable interest in the meteorological community for instance due to their influence in aviation wind hazards and maritime transport. In order to support meteorologists and climatologists in the analysis of these structures, we developed an extraction algorithm and a visual exploration framework consisting of multiple linked views. For the extraction we apply a predictor-corrector algorithm that follows streamlines and realigns them with extremal lines of potential vorticity. Using the agglomerative hierarchical clustering algorithm, we group banners from different sources based on their proximity. To visually analyze the time-dependent banner geometry, we provide interactive overviews and enable the query for detail on demand, including the analysis of different time steps, potentially correlated scalar quantities, and the wind vector field. In particular, we study the relationship between relative humidity and the banners for their potential in indicating the development of precipitation. Working with our method, the collaborating meteorologists gained a deeper understanding of the three-dimensional processes, which may spur follow-up research in the future.",
            "url": "http://dx.doi.org/10.1109/TVCG.2019.2934310",
            "id": "r_196",
            "s_ids": [
                "s_624",
                "s_630",
                "s_109",
                "s_520",
                "s_184",
                "s_443"
            ],
            "type": "rich",
            "x": 10.54450511932373,
            "y": 5.727587699890137
        },
        {
            "title": "A Declarative Grammar of Flexible Volume Visualization Pipelines",
            "data": "This paper presents a declarative grammar for conveniently and effectively specifying advanced volume visualizations. Existing methods for creating volume visualizations either lack the flexibility to specify sophisticated visualizations or are difficult to use for those unfamiliar with volume rendering implementation and parameterization. Our design provides the ability to quickly create expressive visualizations without knowledge of the volume rendering implementation. It attempts to capture aspects of those difficult but powerful methods while remaining flexible and easy to use. As a proof of concept, our current implementation of the grammar allows users to combine multiple data variables in various ways and define transfer functions for diverse input data. The grammar also has the ability to describe advanced shading effects and create animations. We demonstrate the power and flexibility of our approach using multiple practical volume visualizations.",
            "url": "http://dx.doi.org/10.1109/TVCG.2018.2864841",
            "id": "r_197",
            "s_ids": [
                "s_596",
                "s_326",
                "s_647"
            ],
            "type": "rich",
            "x": 10.944116592407227,
            "y": 4.288697719573975
        },
        {
            "title": "Hexahedral Mesh Structure Visualization and Evaluation",
            "data": "Understanding hexahedral (hex-) mesh structures is important for a number of hex-mesh generation and optimization tasks. However, due to various configurations of the singularities in a valid pure hex-mesh, the structure (or base complex) of the mesh can be arbitrarily complex. In this work, we present a first and effective method to help meshing practitioners understand the possible configurations in a valid 3D base complex for the characterization of their complexity. In particular, we propose a strategy to decompose the complex hex-mesh structure into multi-level sub-structures so that they can be studied separately, from which we identify a small set of the sub-structures that can most efficiently represent the whole mesh structure. Furthermore, from this set of sub-structures, we attempt to define the first metric for the quantification of the complexity of hex-mesh structure. To aid the exploration of the extracted multi-level structure information, we devise a visual exploration system coupled with a matrix view to help alleviate the common challenge of 3D data exploration (e.g., clutter and occlusion). We have applied our tool and metric to a large number of hex-meshes generated with different approaches to reveal different characteristics of these methods in terms of the mesh structures they can produce. We also use our metric to assess the existing structure simplification techniques in terms of their effectiveness.",
            "url": "http://dx.doi.org/10.1109/TVCG.2018.2864827",
            "id": "r_198",
            "s_ids": [
                "s_398",
                "s_157"
            ],
            "type": "rich",
            "x": 8.736074447631836,
            "y": 6.8847575187683105
        },
        {
            "title": "Robust and Fast Extraction of 3D Symmetric Tensor Field Topology",
            "data": "3D symmetric tensor fields appear in many science and engineering fields, and topology-driven analysis is important in many of these application domains, such as solid mechanics and fluid dynamics. Degenerate curves and neutral surfaces are important topological features in 3D symmetric tensor fields. Existing methods to extract degenerate curves and neutral surfaces often miss parts of the curves and surfaces, respectively. Moreover, these methods are computationally expensive due to the lack of knowledge of structures of degenerate curves and neutral surfaces.&lt;;/p&gt; &lt;;p&gt;In this paper, we provide theoretical analysis on the geometric and topological structures of degenerate curves and neutral surfaces of 3D linear tensor fields. These structures lead to parameterizations for degenerate curves and neutral surfaces that can not only provide more robust extraction of these features but also incur less computational cost.&lt;;/p&gt; &lt;;p&gt;We demonstrate the benefits of our approach by applying our degenerate curve and neutral surface detection techniques to solid mechanics simulation data sets.",
            "url": "http://dx.doi.org/10.1109/TVCG.2018.2864768",
            "id": "r_199",
            "s_ids": [
                "s_4",
                "s_60",
                "s_120",
                "s_311"
            ],
            "type": "rich",
            "x": 8.376215934753418,
            "y": 6.105894088745117
        },
        {
            "title": "A Fractional Cartesian Composition Model for Semi-Spatial Comparative Visualization Design",
            "data": "The study of spatial data ensembles leads to substantial visualization challenges in a variety of applications. In this paper, we present a model for comparative visualization that supports the design of according ensemble visualization solutions by partial automation. We focus on applications, where the user is interested in preserving selected spatial data characteristics of the data as much as possible-even when many ensemble members should be jointly studied using comparative visualization. In our model, we separate the design challenge into a minimal set of user-specified parameters and an optimization component for the automatic configuration of the remaining design variables. We provide an illustrated formal description of our model and exemplify our approach in the context of several application examples from different domains in order to demonstrate its generality within the class of comparative visualization problems for spatial data ensembles.",
            "url": "http://dx.doi.org/10.1109/TVCG.2016.2598870",
            "id": "r_200",
            "s_ids": [
                "s_358",
                "s_162",
                "s_395",
                "s_338"
            ],
            "type": "rich",
            "x": 11.012639999389648,
            "y": 6.638277530670166
        },
        {
            "title": "Visualization and Analysis of Rotating Stall for Transonic Jet Engine Simulation",
            "data": "Identification of early signs of rotating stall is essential for the study of turbine engine stability. With recent advancements of high performance computing, high-resolution unsteady flow fields allow in depth exploration of rotating stall and its possible causes. Performing stall analysis, however, involves significant effort to process large amounts of simulation data, especially when investigating abnormalities across many time steps. In order to assist scientists during the exploration process, we present a visual analytics framework to identify suspected spatiotemporal regions through a comparative visualization so that scientists are able to focus on relevant data in more detail. To achieve this, we propose efficient stall analysis algorithms derived from domain knowledge and convey the analysis results through juxtaposed interactive plots. Using our integrated visualization system, scientists can visually investigate the detected regions for potential stall initiation and further explore these regions to enhance the understanding of this phenomenon. Positive feedback from scientists demonstrate the efficacy of our system in analyzing rotating stall.",
            "url": "http://dx.doi.org/10.1109/TVCG.2015.2467952",
            "id": "r_201",
            "s_ids": [
                "s_529",
                "s_521",
                "s_422",
                "s_606",
                "s_318",
                "s_345"
            ],
            "type": "rich",
            "x": 8.72029972076416,
            "y": 5.113203525543213
        },
        {
            "title": "Acuity-Driven Gigapixel Visualization",
            "data": "We present a framework for acuity-driven visualization of super-high resolution image data on gigapixel displays. Tiled display walls offer a large workspace that can be navigated physically by the user. Based on head tracking information, the physical characteristics of the tiled display and the formulation of visual acuity, we guide an out-of-core gigapixel rendering scheme by delivering high levels of detail only in places where it is perceivable to the user. We apply this principle to gigapixel image rendering through adaptive level of detail selection. Additionally, we have developed an acuity-driven tessellation scheme for high-quality Focus-and-Context (F+C) lenses that significantly reduces visual artifacts while accurately capturing the underlying lens function. We demonstrate this framework on the Reality Deck, an immersive gigapixel display. We present the results of a user study designed to quantify the impact of our acuity-driven rendering optimizations in the visual exploration process. We discovered no evidence suggesting a difference in search task performance between our framework and naive rendering of gigapixel resolution data, while realizing significant benefits in terms of data transfer overhead. Additionally, we show that our acuity-driven tessellation scheme offers substantially increased frame rates when compared to naive pre-tessellation, while providing indistinguishable image quality.",
            "url": "http://dx.doi.org/10.1109/TVCG.2013.127",
            "id": "r_202",
            "s_ids": [
                "s_76",
                "s_13"
            ],
            "type": "rich",
            "x": 9.976655960083008,
            "y": 3.5579166412353516
        },
        {
            "title": "A Perceptual-Statistics Shading Model",
            "data": "The process of surface perception is complex and based on several influencing factors, e.g., shading, silhouettes, occluding contours, and top down cognition. The accuracy of surface perception can be measured and the influencing factors can be modified in order to decrease the error in perception. This paper presents a novel concept of how a perceptual evaluation of a visualization technique can contribute to its redesign with the aim of improving the match between the distal and the proximal stimulus. During analysis of data from previous perceptual studies, we observed that the slant of 3D surfaces visualized on 2D screens is systematically underestimated. The visible trends in the error allowed us to create a statistical model of the perceived surface slant. Based on this statistical model we obtained from user experiments, we derived a new shading model that uses adjusted surface normals and aims to reduce the error in slant perception. The result is a shape-enhancement of visualization which is driven by an experimentally-founded statistical model. To assess the efficiency of the statistical shading model, we repeated the evaluation experiment and confirmed that the error in perception was decreased. Results of both user experiments are publicly-available datasets.",
            "url": "http://dx.doi.org/10.1109/TVCG.2012.188",
            "id": "r_203",
            "s_ids": [
                "s_621",
                "s_74",
                "s_480",
                "s_395"
            ],
            "type": "rich",
            "x": 9.74095344543457,
            "y": 3.124317169189453
        },
        {
            "title": "Sea of Genes: A Reflection on Visualising Metagenomic Data for Museums",
            "data": "We examine the process of designing an exhibit to communicate scientific findings from a complex dataset and unfamiliar domain to the public in a science museum. Our exhibit sought to communicate new lessons based on scientific findings from the domain of metagenomics. This multi-user exhibit had three goals: (1) to inform the public about microbial communities and their daily cycles; (2) to link microbes' activity to the concept of gene expression; (3) and to highlight scientists' use of gene expression data to understand the role of microbes. To address these three goals, we derived visualization designs with three corresponding stories, each corresponding to a goal. We present three successive rounds of design and evaluation of our attempts to convey these goals. We could successfully present one story but had limited success with our second and third goals. This work presents a detailed account of an attempt to explain tightly coupled relationships through storytelling and animation in a multi-user, informal learning environment to a public with varying prior knowledge on the domain and identify lessons for future design.",
            "url": "http://dx.doi.org/10.1109/TVCG.2020.3030412",
            "id": "r_204",
            "s_ids": [
                "s_242",
                "s_647",
                "s_565",
                "s_400"
            ],
            "type": "rich",
            "x": 11.563887596130371,
            "y": 4.047283172607422
        },
        {
            "title": "Visual Analysis of Large Multivariate Scattered Data using Clustering and Probabilistic Summaries",
            "data": "Rapidly growing data sizes of scientific simulations pose significant challenges for interactive visualization and analysis techniques. In this work, we propose a compact probabilistic representation to interactively visualize large scattered datasets. In contrast to previous approaches that represent blocks of volumetric data using probability distributions, we model clusters of arbitrarily structured multivariate data. In detail, we discuss how to efficiently represent and store a high-dimensional distribution for each cluster. We observe that it suffices to consider low-dimensional marginal distributions for two or three data dimensions at a time to employ common visual analysis techniques. Based on this observation, we represent high-dimensional distributions by combinations of low-dimensional Gaussian mixture models. We discuss the application of common interactive visual analysis techniques to this representation. In particular, we investigate several frequency-based views, such as density plots in 1D and 2D, density-based parallel coordinates, and a time histogram. We visualize the uncertainty introduced by the representation, discuss a level-of-detail mechanism, and explicitly visualize outliers. Furthermore, we propose a spatial visualization by splatting anisotropic 3D Gaussians for which we derive a closed-form solution. Lastly, we describe the application of brushing and linking to this clustered representation. Our evaluation on several large, real-world datasets demonstrates the scaling of our approach.",
            "url": "http://dx.doi.org/10.1109/TVCG.2020.3030379",
            "id": "r_205",
            "s_ids": [
                "s_42",
                "s_149",
                "s_411"
            ],
            "type": "rich",
            "x": 10.653554916381836,
            "y": 6.878467082977295
        },
        {
            "title": "Toward Localized Topological Data Structures: Querying the Forest for the Tree",
            "data": "Topological approaches to data analysis can answer complex questions about the number, connectivity, and scale of intrinsic features in scalar data. However, the global nature of many topological structures makes their computation challenging at scale, and thus often limits the size of data that can be processed. One key quality to achieving scalability and performance on modern architectures is data locality, i.e., a process operates on data that resides in a nearby memory system, avoiding frequent jumps in data access patterns. From this perspective, topological computations are particularly challenging because the implied data structures represent features that can span the entire data set, often requiring a global traversal phase that limits their scalability. Traditionally, expensive preprocessing is considered an acceptable trade-off as it accelerates all subsequent queries. Most published use cases, however, explore only a fraction of all possible queries, most often those returning small, local features. In these cases, much of the global information is not utilized, yet computing it dominates the overall response time. We address this challenge for merge trees, one of the most commonly used topological structures. In particular, we propose an alternative representation, the merge forest, a collection of local trees corresponding to regions in a domain decomposition. Local trees are connected by a bridge set that allows us to recover any necessary global information at query time. The resulting system couples (i) a preprocessing that scales linearly in practice with (ii) fast runtime queries that provide the same functionality as traditional queries of a global merge tree. We test the scalability of our approach on a shared-memory parallel computer and demonstrate how data structure locality enables the analysis of large data with an order of magnitude performance improvement over the status quo. Furthermore, a merge forest reduces the memory overhead compared to a global merge tree and enables the processing of data sets that are an order of magnitude larger than possible with previous algorithms.",
            "url": "http://dx.doi.org/10.1109/TVCG.2019.2934257",
            "id": "r_206",
            "s_ids": [
                "s_72",
                "s_660",
                "s_392",
                "s_273"
            ],
            "type": "rich",
            "x": 9.358957290649414,
            "y": 7.987087249755859
        },
        {
            "title": "Objective Vortex Corelines of Finite-sized Objects in Fluid Flows",
            "data": "Vortices are one of the most-frequently studied phenomena in fluid flows. The center of the rotating motion is called the vortex coreline and its successful detection strongly depends on the choice of the reference frame. The optimal frame moves with the center of the vortex, which incidentally makes the observed fluid flow steady and thus standard vortex coreline extractors such as Sujudi-Haimes become applicable. Recently, an objective optimization framework was proposed that determines a near-steady reference frame for tracer particles. In this paper, we extend this technique to the detection of vortex corelines of inertial particles. An inertial particle is a finite-sized object that is carried by a fluid flow. In contrast to the usual tracer particles, they do not move tangentially with the flow, since they are subject to gravity and exhibit mass-dependent inertia. Their particle state is determined by their position and own velocity, which makes the search for the optimal frame a high-dimensional problem. We demonstrate in this paper that the objective detection of an inertial vortex coreline can be reduced in 2D to a critical point search in 2D. For 3D flows, however, the vortex coreline criterion remains a parallel vectors condition in 6D. To detect the vortex corelines we propose a recursive subdivision approach that is tailored to the underlying structure of the 6D vectors. The resulting algorithm is objective, and we demonstrate the vortex coreline extraction in a number of 2D and 3D vector fields.",
            "url": "http://dx.doi.org/10.1109/TVCG.2018.2864828",
            "id": "r_207",
            "s_ids": [
                "s_443",
                "s_653"
            ],
            "type": "rich",
            "x": 7.581774711608887,
            "y": 5.24179744720459
        },
        {
            "title": "Visual Analysis of Spatio-temporal Relations of Pairwise Attributes in Unsteady Flow",
            "data": "Despite significant advances in the analysis and visualization of unsteady flow, the interpretation of it's behavior still remains a challenge. In this work, we focus on the linear correlation and non-linear dependency of different physical attributes of unsteady flows to aid their study from a new perspective. Specifically, we extend the existing spatial correlation quantification, i.e. the Local Correlation Coefficient (LCC), to the spatio-temporal domain to study the correlation of attribute-pairs from both the Eulerian and Lagrangian views. To study the dependency among attributes, which need not be linear, we extend and compute the mutual information (MI) among attributes over time. To help visualize and interpret the derived correlation and dependency among attributes associated with a particle, we encode the correlation and dependency values on individual pathlines. Finally, to utilize the correlation and MI computation results to identify regions with interesting flow behavior, we propose a segmentation strategy of the flow domain based on the ranking of the strength of the attributes relations. We have applied our correlation and dependency metrics to a number of 2D and 3D unsteady flows with varying spatio-temporal kernel sizes to demonstrate and assess their effectiveness.",
            "url": "http://dx.doi.org/10.1109/TVCG.2018.2864817",
            "id": "r_208",
            "s_ids": [
                "s_174",
                "s_424",
                "s_505",
                "s_157"
            ],
            "type": "rich",
            "x": 8.20684814453125,
            "y": 5.359190464019775
        },
        {
            "title": "Backward Finite-Time Lyapunov Exponents in Inertial Flows",
            "data": "Inertial particles are finite-sized objects that are carried by fluid flows and in contrast to massless tracer particles they are subject to inertia effects. In unsteady flows, the dynamics of tracer particles have been extensively studied by the extraction of Lagrangian coherent structures (LCS), such as hyperbolic LCS as ridges of the Finite-Time Lyapunov Exponent (FTLE). The extension of the rich LCS framework to inertial particles is currently a hot topic in the CFD literature and is actively under research. Recently, backward FTLE on tracer particles has been shown to correlate with the preferential particle settling of small inertial particles. For larger particles, inertial trajectories may deviate strongly from (massless) tracer trajectories, and thus for a better agreement, backward FTLE should be computed on inertial trajectories directly. Inertial backward integration, however, has not been possible until the recent introduction of the influence curve concept, which - given an observation and an initial velocity - allows to recover all sources of inertial particles as tangent curves of a derived vector field. In this paper, we show that FTLE on the influence curve vector field is in agreement with preferential particle settling and more importantly it is not only valid for small (near-tracer) particles. We further generalize the influence curve concept to general equations of motion in unsteady spatio-velocity phase spaces, which enables backward integration with more general equations of motion. Applying the influence curve concept to tracer particles in the spatio-velocity domain emits streaklines in massless flows as tangent curves of the influence curve vector field. We demonstrate the correlation between inertial backward FTLE and the preferential particle settling in a number of unsteady vector fields",
            "url": "http://dx.doi.org/10.1109/TVCG.2016.2599016",
            "id": "r_209",
            "s_ids": [
                "s_443",
                "s_653"
            ],
            "type": "rich",
            "x": 7.842944622039795,
            "y": 5.413028717041016
        },
        {
            "title": "A Visual Voting Framework for Weather Forecast Calibration",
            "data": "Numerical weather predictions have been widely used for weather forecasting. Many large meteorological centers are producing highly accurate ensemble forecasts routinely to provide effective weather forecast services. However, biases frequently exist in forecast products because of various reasons, such as the imperfection of the weather forecast models. Failure to identify and neutralize the biases would result in unreliable forecast products that might mislead analysts; consequently, unreliable weather predictions are produced. The analog method has been commonly used to overcome the biases. Nevertheless, this method has some serious limitations including the difficulties in finding effective similar past forecasts, the large search space for proper parameters and the lack of support for interactive, real-time analysis. In this study, we develop a visual analytics system based on a novel voting framework to circumvent the problems. The framework adopts the idea of majority voting to combine judiciously the different variants of analog methods towards effective retrieval of the proper analogs for calibration. The system seamlessly integrates the analog methods into an interactive visualization pipeline with a set of coordinated views that characterizes the different methods. Instant visual hints are provided in the views to guide users in finding and refining analogs. We have worked closely with the domain experts in the meteorological research to develop the system. The effectiveness of the system is demonstrated using two case studies. An informal evaluation with the experts proves the usability and usefulness of the system.",
            "url": "http://dx.doi.org/10.1109/SciVis.2015.7429488",
            "id": "r_210",
            "s_ids": [
                "s_67",
                "s_499",
                "s_195",
                "s_85",
                "s_288",
                "s_401",
                "s_512",
                "s_478"
            ],
            "type": "rich",
            "x": 11.216442108154297,
            "y": 5.968529224395752
        },
        {
            "title": "The Mixture Graph-A Data Structure for Compressing, Rendering, and Querying Segmentation Histograms",
            "data": "In this paper, we present a novel data structure, called the Mixture Graph. This data structure allows us to compress, render, and query segmentation histograms. Such histograms arise when building a mipmap of a volume containing segmentation IDs. Each voxel in the histogram mipmap contains a convex combination (mixture) of segmentation IDs. Each mixture represents the distribution of IDs in the respective voxel's children. Our method factorizes these mixtures into a series of linear interpolations between exactly two segmentation IDs. The result is represented as a directed acyclic graph (DAG) whose nodes are topologically ordered. Pruning replicate nodes in the tree followed by compression allows us to store the resulting data structure efficiently. During rendering, transfer functions are propagated from sources (leafs) through the DAG to allow for efficient, pre-filtered rendering at interactive frame rates. Assembly of histogram contributions across the footprint of a given volume allows us to efficiently query partial histograms, achieving up to 178 x speed-up over naive parallelized range queries. Additionally, we apply the Mixture Graph to compute correctly pre-filtered volume lighting and to interactively explore segments based on shape, geometry, and orientation using multi-dimensional transfer functions.",
            "url": "http://dx.doi.org/10.1109/TVCG.2020.3030451",
            "id": "r_211",
            "s_ids": [
                "s_212",
                "s_578",
                "s_663"
            ],
            "type": "rich",
            "x": 9.605687141418457,
            "y": 7.465196132659912
        },
        {
            "title": "Visualization of Human Spine Biomechanics for Spinal Surgery",
            "data": "We propose a visualization application, designed for the exploration of human spine simulation data. Our goal is to support research in biomechanical spine simulation and advance efforts to implement simulation-backed analysis in surgical applications. Biomechanical simulation is a state-of-the-art technique for analyzing load distributions of spinal structures. Through the inclusion of patient-specific data, such simulations may facilitate personalized treatment and customized surgical interventions. Difficulties in spine modelling and simulation can be partly attributed to poor result representation, which may also be a hindrance when introducing such techniques into a clinical environment. Comparisons of measurements across multiple similar anatomical structures and the integration of temporal data make commonly available diagrams and charts insufficient for an intuitive and systematic display of results. Therefore, we facilitate methods such as multiple coordinated views, abstraction and focus and context to display simulation outcomes in a dedicated tool. $\\mathrm{By}$ linking the result data with patient-specific anatomy, we make relevant parameters tangible for clinicians. Furthermore, we introduce new concepts to show the directions of impact force vectors, which were not accessible before. We integrated our toolset into a spine segmentation and simulation pipeline and evaluated our methods with both surgeons and biomechanical researchers. When comparing our methods against standard representations that are currently in use, we found increases in accuracy and speed in data exploration tasks. $\\mathrm{in}$ a qualitative review, domain experts deemed the tool highly useful when dealing with simulation result data, which typically combines time-dependent patient movement and the resulting force distributions on spinal structures.",
            "url": "http://dx.doi.org/10.1109/TVCG.2020.3030388",
            "id": "r_212",
            "s_ids": [
                "s_452",
                "s_95",
                "s_439",
                "s_658"
            ],
            "type": "rich",
            "x": 8.000309944152832,
            "y": 3.6600561141967773
        },
        {
            "title": "Void-and-Cluster Sampling of Large Scattered Data and Trajectories",
            "data": "We propose a data reduction technique for scattered data based on statistical sampling. Our void-and-cluster sampling technique finds a representative subset that is optimally distributed in the spatial domain with respect to the blue noise property. In addition, it can adapt to a given density function, which we use to sample regions of high complexity in the multivariate value domain more densely. Moreover, our sampling technique implicitly defines an ordering on the samples that enables progressive data loading and a continuous level-of-detail representation. We extend our technique to sample time-dependent trajectories, for example pathlines in a time interval, using an efficient and iterative approach. Furthermore, we introduce a local and continuous error measure to quantify how well a set of samples represents the original dataset. We apply this error measure during sampling to guide the number of samples that are taken. Finally, we use this error measure and other quantities to evaluate the quality, performance, and scalability of our algorithm.",
            "url": "http://dx.doi.org/10.1109/TVCG.2019.2934335",
            "id": "r_213",
            "s_ids": [
                "s_42",
                "s_149",
                "s_411"
            ],
            "type": "rich",
            "x": 10.579438209533691,
            "y": 7.196012020111084
        },
        {
            "title": "Scale-Space Splatting: Reforming Spacetime for Cross-Scale Exploration of Integral Measures in Molecular Dynamics",
            "data": "Understanding large amounts of spatiotemporal data from particle-based simulations, such as molecular dynamics, often relies on the computation and analysis of aggregate measures. These, however, by virtue of aggregation, hide structural information about the space/time localization of the studied phenomena. This leads to degenerate cases where the measures fail to capture distinct behaviour. In order to drill into these aggregate values, we propose a multi-scale visual exploration technique. Our novel representation, based on partial domain aggregation, enables the construction of a continuous scale-space for discrete datasets and the simultaneous exploration of scales in both space and time. We link these two scale-spaces in a scale-space space-time cube and model linked views as orthogonal slices through this cube, thus enabling the rapid identification of spatio-temporal patterns at multiple scales. To demonstrate the effectiveness of our approach, we showcase an advanced exploration of a protein-ligand simulation.",
            "url": "http://dx.doi.org/10.1109/TVCG.2019.2934258",
            "id": "r_214",
            "s_ids": [
                "s_449",
                "s_141",
                "s_162",
                "s_338"
            ],
            "type": "rich",
            "x": 10.42264461517334,
            "y": 6.423535346984863
        },
        {
            "title": "A Versatile and Efficient GPU Data Structure for Spatial Indexing",
            "data": "In this paper we present a novel GPU-based data structure for spatial indexing. Based on Fenwick trees-a special type of binary indexed trees-our data structure allows construction in linear time. Updates and prefixes can be computed in logarithmic time, whereas point queries require only constant time on average. Unlike competing data structures such as summed-area tables and spatial hashing, our data structure requires a constant amount of bits for each data element, and it offers unconstrained point queries. This property makes our data structure ideally suited for applications requiring unconstrained indexing of large data, such as block-storage of large and block-sparse volumes. Finally, we provide asymptotic bounds on both run-time and memory requirements, and we show applications for which our new data structure is useful.",
            "url": "http://dx.doi.org/10.1109/TVCG.2016.2599043",
            "id": "r_215",
            "s_ids": [
                "s_663",
                "s_145"
            ],
            "type": "rich",
            "x": 9.321157455444336,
            "y": 8.027297973632812
        },
        {
            "title": "Interactive Visualization for Singular Fibers of Functions f : R3 \u2192 R2",
            "data": "Scalar topology in the form of Morse theory has provided computational tools that analyze and visualize data from scientific and engineering tasks. Contracting isocontours to single points encapsulates variations in isocontour connectivity in the Reeb graph. For multivariate data, isocontours generalize to fibers-inverse images of points in the range, and this area is therefore known as fiber topology. However, fiber topology is less fully developed than Morse theory, and current efforts rely on manual visualizations. This paper presents how to accelerate and semi-automate this task through an interface for visualizing fiber singularities of multivariate functions R<sup>3</sup>\u2192R<sup>2</sup>. This interface exploits existing conventions of fiber topology, but also introduces a 3D view based on the extension of Reeb graphs to Reeb spaces. Using the Joint Contour Net, a quantized approximation of the Reeb space, this accelerates topological visualization and permits online perturbation to reduce or remove degeneracies in functions under study. Validation of the interface is performed by assessing whether the interface supports the mathematical workflow both of experts and of less experienced mathematicians.",
            "url": "http://dx.doi.org/10.1109/TVCG.2015.2467433",
            "id": "r_216",
            "s_ids": [
                "s_347",
                "s_414",
                "s_445",
                "s_450",
                "s_29",
                "s_143",
                "s_233"
            ],
            "type": "rich",
            "x": 8.604155540466309,
            "y": 6.688293933868408
        },
        {
            "title": "Reconstruction and Visualization of Coordinated 3D Cell Migration Based on Optical Flow",
            "data": "Animal development is marked by the repeated reorganization of cells and cell populations, which ultimately determine form and shape of the growing organism. One of the central questions in developmental biology is to understand precisely how cells reorganize, as well as how and to what extent this reorganization is coordinated. While modern microscopes can record video data for every cell during animal development in 3D+t, analyzing these videos remains a major challenge: reconstruction of comprehensive cell tracks turned out to be very demanding especially with decreasing data quality and increasing cell densities. In this paper, we present an analysis pipeline for coordinated cellular motions in developing embryos based on the optical flow of a series of 3D images. We use numerical integration to reconstruct cellular long-term motions in the optical flow of the video, we take care of data validation, and we derive a LIC-based, dense flow visualization for the resulting pathlines. This approach allows us to handle low video quality such as noisy data or poorly separated cells, and it allows the biologists to get a comprehensive understanding of their data by capturing dynamic growth processes in stills. We validate our methods using three videos of growing fruit fly embryos.",
            "url": "http://dx.doi.org/10.1109/TVCG.2015.2467291",
            "id": "r_217",
            "s_ids": [
                "s_593",
                "s_6",
                "s_209",
                "s_488",
                "s_319",
                "s_35"
            ],
            "type": "rich",
            "x": 11.682938575744629,
            "y": 3.604092597961426
        },
        {
            "title": "Visual Data Analysis as an Integral Part of Environmental Management",
            "data": "The U.S. Department of Energy's (DOE) Office of Environmental Management (DOE/EM) currently supports an effort to understand and predict the fate of nuclear contaminants and their transport in natural and engineered systems. Geologists, hydrologists, physicists and computer scientists are working together to create models of existing nuclear waste sites, to simulate their behavior and to extrapolate it into the future. We use visualization as an integral part in each step of this process. In the first step, visualization is used to verify model setup and to estimate critical parameters. High-performance computing simulations of contaminant transport produces massive amounts of data, which is then analyzed using visualization software specifically designed for parallel processing of large amounts of structured and unstructured data. Finally, simulation results are validated by comparing simulation results to measured current and historical field data. We describe in this article how visual analysis is used as an integral part of the decision-making process in the planning of ongoing and future treatment options for the contaminated nuclear waste sites. Lessons learned from visually analyzing our large-scale simulation runs will also have an impact on deciding on treatment measures for other contaminated sites.",
            "url": "http://dx.doi.org/10.1109/TVCG.2012.278",
            "id": "r_218",
            "s_ids": [
                "s_121",
                "s_237",
                "s_667",
                "s_496",
                "s_357",
                "s_58",
                "s_11",
                "s_185",
                "s_463",
                "s_404",
                "s_526",
                "s_7",
                "s_393",
                "s_294"
            ],
            "type": "rich",
            "x": 11.046210289001465,
            "y": 5.584549427032471
        },
        {
            "title": "Feature-Based Tensor Field Visualization for Fiber Reinforced Polymers",
            "data": "Virtual testing is an integral part of modern product development in mechanical engineering. Numerical structure simulations allow the computation of local stresses which are given as tensor fields. For homogeneous materials, the tensor information is usually reduced to a scalar field like the von Mises stress. A material-dependent threshold defines the material failure answering the key question of engineers. This leads to a rather simple feature-based visualisation. For composite materials like short fiber reinforced polymers, the situation is much more complex. The material property is determined by the fiber distribution at every position, often described as fiber orientation tensor field. Essentially, the material's ability to cope with stress becomes anisotropic and inhomogeneous. We show how to combine the stress field and the fiber orientation field in such cases, leading to a feature-based visualization of tensor fields for composite materials. The resulting features inform the engineer about potential improvements in the product development.",
            "url": "http://dx.doi.org/10.1109/SciVis.2015.7429491",
            "id": "r_219",
            "s_ids": [
                "s_351",
                "s_293",
                "s_116"
            ],
            "type": "rich",
            "x": 9.011826515197754,
            "y": 5.526360034942627
        },
        {
            "title": "Homomorphic-Encrypted Volume Rendering",
            "data": "Computationally demanding tasks are typically calculated in dedicated data centers, and real-time visualizations also follow this trend. Some rendering tasks, however, require the highest level of confidentiality so that no other party, besides the owner, can read or see the sensitive data. Here we present a direct volume rendering approach that performs volume rendering directly on encrypted volume data by using the homomorphic Paillier encryption algorithm. This approach ensures that the volume data and rendered image are uninterpretable to the rendering server. Our volume rendering pipeline introduces novel approaches for encrypted-data compositing, interpolation, and opacity modulation, as well as simple transfer function design, where each of these routines maintains the highest level of privacy. We present performance and memory overhead analysis that is associated with our privacy-preserving scheme. Our approach is open and secure by design, as opposed to secure through obscurity. Owners of the data only have to keep their secure key confidential to guarantee the privacy of their volume data and the rendered images. Our work is, to our knowledge, the first privacy-preserving remote volume-rendering approach that does not require that any server involved be trustworthy; even in cases when the server is compromised, no sensitive data will be leaked to a foreign party.",
            "url": "http://dx.doi.org/10.1109/TVCG.2020.3030436",
            "id": "r_220",
            "s_ids": [
                "s_86",
                "s_205",
                "s_395"
            ],
            "type": "rich",
            "x": 10.493793487548828,
            "y": 4.1511454582214355
        },
        {
            "title": "Mode Surfaces of Symmetric Tensor Fields: Topological Analysis and Seamless Extraction",
            "data": "Mode surfaces are the generalization of degenerate curves and neutral surfaces, which constitute 3D symmetric tensor field topology. Efficient analysis and visualization of mode surfaces can provide additional insight into not only degenerate curves and neutral surfaces, but also how these features transition into each other. Moreover, the geometry and topology of mode surfaces can help domain scientists better understand the tensor fields in their applications. Existing mode surface extraction methods can miss features in the surfaces. Moreover, the mode surfaces extracted from neighboring cells have gaps, which make their subsequent analysis difficult. In this paper, we provide novel analysis on the topological structures of mode surfaces, including a common parameterization of all mode surfaces of a tensor field using 2D asymmetric tensors. This allows us to not only better understand the structures in mode surfaces and their interactions with degenerate curves and neutral surfaces, but also develop an efficient algorithm to seamlessly extract mode surfaces, including neutral surfaces. The seamless mode surfaces enable efficient analysis of their geometric structures, such as the principal curvature directions. We apply our analysis and visualization to a number of solid mechanics data sets.",
            "url": "http://dx.doi.org/10.1109/TVCG.2020.3030431",
            "id": "r_221",
            "s_ids": [
                "s_201",
                "s_4",
                "s_120",
                "s_311"
            ],
            "type": "rich",
            "x": 8.335123062133789,
            "y": 6.068785667419434
        },
        {
            "title": "A Testing Environment for Continuous Colormaps",
            "data": "Many computer science disciplines (e.g., combinatorial optimization, natural language processing, and information retrieval) use standard or established test suites for evaluating algorithms. In visualization, similar approaches have been adopted in some areas (e.g., volume visualization), while user testimonies and empirical studies have been the dominant means of evaluation in most other areas, such as designing colormaps. In this paper, we propose to establish a test suite for evaluating the design of colormaps. With such a suite, the users can observe the effects when different continuous colormaps are applied to planar scalar fields that may exhibit various characteristic features, such as jumps, local extrema, ridge or valley lines, different distributions of scalar values, different gradients, different signal frequencies, different levels of noise, and so on. The suite also includes an expansible collection of real-world data sets including the most popular data for colormap testing in the visualization literature. The test suite has been integrated into a web-based application for creating continuous colormaps (https://ccctool.com/), facilitating close inter-operation between design and evaluation processes. This new facility complements traditional evaluation methods such as user testimonies and empirical studies.",
            "url": "http://dx.doi.org/10.1109/TVCG.2020.3028955",
            "id": "r_222",
            "s_ids": [
                "s_305",
                "s_249",
                "s_24",
                "s_493",
                "s_116"
            ],
            "type": "rich",
            "x": 11.792166709899902,
            "y": 5.156982421875
        },
        {
            "title": "Multi-Scale Topological Analysis of Asymmetric Tensor Fields on Surfaces",
            "data": "Asymmetric tensor fields have found applications in many science and engineering domains, such as fluid dynamics. Recent advances in the visualization and analysis of 2D asymmetric tensor fields focus on pointwise analysis of the tensor field and effective visualization metaphors such as colors, glyphs, and hyperstreamlines. In this paper, we provide a novel multi-scale topological analysis framework for asymmetric tensor fields on surfaces. Our multi-scale framework is based on the notions of eigenvalue and eigenvector graphs. At the core of our framework are the identification of atomic operations that modify the graphs and the scale definition that guides the order in which the graphs are simplified to enable clarity and focus for the visualization of topological analysis on data of different sizes. We also provide efficient algorithms to realize these operations. Furthermore, we provide physical interpretation of these graphs. To demonstrate the utility of our system, we apply our multi-scale analysis to data in computational fluid dynamics.",
            "url": "http://dx.doi.org/10.1109/TVCG.2019.2934314",
            "id": "r_223",
            "s_ids": [
                "s_613",
                "s_4",
                "s_311",
                "s_201",
                "s_504",
                "s_204",
                "s_505",
                "s_120"
            ],
            "type": "rich",
            "x": 8.546778678894043,
            "y": 6.32175350189209
        },
        {
            "title": "Decision Graph Embedding for High-Resolution Manometry Diagnosis",
            "data": "High-resolution manometry is an imaging modality which enables the categorization of esophageal motility disorders. Spatio-temporal pressure data along the esophagus is acquired using a tubular device and multiple test swallows are performed by the patient. Current approaches visualize these swallows as individual instances, despite the fact that aggregated metrics are relevant in the diagnostic process. Based on the current Chicago Classification, which serves as the gold standard in this area, we introduce a visualization supporting an efficient and correct diagnosis. To reach this goal, we propose a novel decision graph representing the Chicago Classification with workflow optimization in mind. Based on this graph, we are further able to prioritize the different metrics used during diagnosis and can exploit this prioritization in the actual data visualization. Thus, different disorders and their related parameters are directly represented and intuitively influence the appearance of our visualization. Within this paper, we introduce our novel visualization, justify the design decisions, and provide the results of a user study we performed with medical students as well as a domain expert. On top of the presented visualization, we further discuss how to derive a visual signature for individual patients that allows us for the first time to perform an intuitive comparison between subjects, in the form of small multiples.",
            "url": "http://dx.doi.org/10.1109/TVCG.2017.2744299",
            "id": "r_224",
            "s_ids": [
                "s_46",
                "s_2",
                "s_468",
                "s_183"
            ],
            "type": "rich",
            "x": 7.923369407653809,
            "y": 3.8280584812164307
        },
        {
            "title": "Adaptive Multilinear Tensor Product Wavelets",
            "data": "Many foundational visualization techniques including isosurfacing, direct volume rendering and texture mapping rely on piecewise multilinear interpolation over the cells of a mesh. However, there has not been much focus within the visualization community on techniques that efficiently generate and encode globally continuous functions defined by the union of multilinear cells. Wavelets provide a rich context for analyzing and processing complicated datasets. In this paper, we exploit adaptive regular refinement as a means of representing and evaluating functions described by a subset of their nonzero wavelet coefficients. We analyze the dependencies involved in the wavelet transform and describe how to generate and represent the coarsest adaptive mesh with nodal function values such that the inverse wavelet transform is exactly reproduced via simple interpolation (subdivision) over the mesh elements. This allows for an adaptive, sparse representation of the function with on-demand evaluation at any point in the domain. We focus on the popular wavelets formed by tensor products of linear B-splines, resulting in an adaptive, nonconforming but crack-free quadtree (2D) or octree (3D) mesh that allows reproducing globally continuous functions via multilinear interpolation over its cells.",
            "url": "http://dx.doi.org/10.1109/TVCG.2015.2467412",
            "id": "r_225",
            "s_ids": [
                "s_368",
                "s_255"
            ],
            "type": "rich",
            "x": 9.295135498046875,
            "y": 7.081155776977539
        },
        {
            "title": "Coherency-Based Curve Compression for High-Order finite Element Model Visualization",
            "data": "Finite element (FE) models are frequently used in engineering and life sciences within time-consuming simulations. In contrast with the regular grid structure facilitated by volumetric data sets, as used in medicine or geosciences, FE models are defined over a non-uniform grid. Elements can have curved faces and their interior can be defined through high-order basis functions, which pose additional challenges when visualizing these models. During ray-casting, the uniformly distributed sample points along each viewing ray must be transformed into the material space defined within each element. The computational complexity of this transformation makes a straightforward approach inadequate for interactive data exploration. In this paper, we introduce a novel coherency-based method which supports the interactive exploration of FE models by decoupling the expensive world-to-material space transformation from the rendering stage, thereby allowing it to be performed within a precomputation stage. Therefore, our approach computes view-independent proxy rays in material space, which are clustered to facilitate data reduction. During rendering, these proxy rays are accessed, and it becomes possible to visually analyze high-order FE models at interactive frame rates, even when they are time-varying or consist of multiple modalities. Within this paper, we provide the necessary background about the FE data, describe our decoupling method, and introduce our interactive rendering algorithm. Furthermore, we provide visual results and analyze the error introduced by the presented approach.",
            "url": "http://dx.doi.org/10.1109/TVCG.2012.206",
            "id": "r_226",
            "s_ids": [
                "s_457",
                "s_250",
                "s_604",
                "s_668",
                "s_183"
            ],
            "type": "rich",
            "x": 9.631333351135254,
            "y": 5.196542263031006
        },
        {
            "title": "Interactive Black-Hole Visualization",
            "data": "We present an efficient algorithm for visualizing the effect of black holes on its distant surroundings as seen from an observer nearby in orbit. Our solution is GPU-based and builds upon a two-step approach, where we first derive an adaptive grid to map the 360-view around the observer to the distorted celestial sky, which can be directly reused for different camera orientations. Using a grid, we can rapidly trace rays back to the observer through the distorted spacetime, avoiding the heavy workload of standard tracing solutions at real-time rates. By using a novel interpolation technique we can also simulate an observer path by smoothly transitioning between multiple grids. Our approach accepts real star catalogues and environment maps of the celestial sky and generates the resulting black-hole deformations in real time.",
            "url": "http://dx.doi.org/10.1109/TVCG.2020.3030452",
            "id": "r_227",
            "s_ids": [
                "s_172",
                "s_134"
            ],
            "type": "rich",
            "x": 10.143728256225586,
            "y": 4.344464302062988
        },
        {
            "title": "Advanced Rendering of Line Data with Ambient Occlusion and Transparency",
            "data": "3D Lines are a widespread rendering primitive for the visualization of data from research fields like fluid dynamics or fiber tractography. Global illumination effects and transparent rendering improve the perception of three-dimensional features and decrease occlusion within the data set, thus enabling better understanding of complex line data. We present an efficient approach for high quality GPU-based rendering of line data with ambient occlusion and transparency effects. Our approach builds on GPU-based raycasting of rounded cones, which are geometric primitives similar to truncated cones, but with spherical endcaps. Object space ambient occlusion is provided by an efficient voxel cone tracing approach. Our core contribution is a new fragment visibility sorting strategy that allows for interactive visualization of line data sets with millions of line segments. We improve performance further by exploiting hierarchical opacity maps.",
            "url": "http://dx.doi.org/10.1109/TVCG.2020.3028954",
            "id": "r_228",
            "s_ids": [
                "s_549",
                "s_189"
            ],
            "type": "rich",
            "x": 9.709979057312012,
            "y": 4.232072353363037
        },
        {
            "title": "Visualization of Bubble Formation in Porous Media",
            "data": "We present a visualization approach for the analysis of CO<sub>2</sub>bubble-induced attenuation in porous rock formations. As a basis for this, we introduce customized techniques to extract CO<sub>2</sub>bubbles and their surrounding porous structure from X-ray computed tomography data (XCT) measurements. To understand how the structure of porous media influences the occurrence and the shape of formed bubbles, we automatically classify and relate them in terms of morphology and geometric features, and further directly support searching for promising porous structures. To allow for the meaningful direct visual comparison of bubbles and their structures, we propose a customized registration technique considering the bubble shape as well as its points of contact with the porous media surface. With our quantitative extraction of geometric bubble features, we further support the analysis as well as the creation of a physical model. We demonstrate that our approach was successfully used to answer several research questions in the domain, and discuss its high practical relevance to identify critical seismic characteristics of fluid-saturated rock that govern its capability to store CO<sub>2</sub>.",
            "url": "http://dx.doi.org/10.1109/TVCG.2018.2864506",
            "id": "r_229",
            "s_ids": [
                "s_479",
                "s_240",
                "s_436",
                "s_614",
                "s_277",
                "s_192"
            ],
            "type": "rich",
            "x": 9.252543449401855,
            "y": 5.240782260894775
        },
        {
            "title": "Interactive Design and Visualization of Branched Covering Spaces",
            "data": "Branched covering spaces are a mathematical concept which originates from complex analysis and topology and has applications in tensor field topology and geometry remeshing. Given a manifold surface and an<inline-formula><tex-math notation=\"LaTeX\">$N$</tex-math><alternatives><inline-graphic xlink:href=\"24tvcg01-zhang-2744038-ieq-1-source.tif\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"/></alternatives></inline-formula>-way rotational symmetry field, a branched covering space is a manifold surface that has an<inline-formula><tex-math notation=\"LaTeX\">$N$</tex-math><alternatives><inline-graphic xlink:href=\"24tvcg01-zhang-2744038-ieq-2-source.tif\" xmlns:xlink=\"http://www.w3.org/1999/xlink\"/></alternatives></inline-formula>-to-1 map to the original surface except at the<italic>ramification points</italic>, which correspond to the singularities in the rotational symmetry field. Understanding the notion and mathematical properties of branched covering spaces is important to researchers in tensor field visualization and geometry processing, and their application areas. In this paper, we provide a framework to interactively design and visualize the branched covering space (BCS) of an input mesh surface and a rotational symmetry field defined on it. In our framework, the user can visualize not only the BCSs but also their construction process. In addition, our system allows the user to design the geometric realization of the BCS using mesh deformation techniques as well as connecting tubes. This enables the user to verify important facts about BCSs such as that they are manifold surfaces around singularities, as well as the<italic>Riemann-Hurwitz formula</italic>which relates the Euler characteristic of the BCS to that of the original mesh. Our system is evaluated by student researchers in scientific visualization and geometry processing as well as faculty members in mathematics at our university who teach topology. We include their evaluations and feedback in the paper.",
            "url": "http://dx.doi.org/10.1109/TVCG.2017.2744038",
            "id": "r_230",
            "s_ids": [
                "s_4",
                "s_60",
                "s_602",
                "s_120",
                "s_311"
            ],
            "type": "rich",
            "x": 8.368074417114258,
            "y": 6.102084636688232
        },
        {
            "title": "Screen-Space Normal Distribution Function Caching for Consistent Multi-Resolution Rendering of Large Particle Data",
            "data": "Molecular dynamics (MD) simulations are crucial to investigating important processes in physics and thermodynamics. The simulated atoms are usually visualized as hard spheres with Phong shading, where individual particles and their local density can be perceived well in close-up views. However, for large-scale simulations with 10 million particles or more, the visualization of large fields-of-view usually suffers from strong aliasing artifacts, because the mismatch between data size and output resolution leads to severe under-sampling of the geometry. Excessive super-sampling can alleviate this problem, but is prohibitively expensive. This paper presents a novel visualization method for large-scale particle data that addresses aliasing while enabling interactive high-quality rendering. We introduce the novel concept of screen-space normal distribution functions (S-NDFs) for particle data. S-NDFs represent the distribution of surface normals that map to a given pixel in screen space, which enables high-quality re-lighting without re-rendering particles. In order to facilitate interactive zooming, we cache S-NDFs in a screen-space mipmap (S-MIP). Together, these two concepts enable interactive, scale-consistent re-lighting and shading changes, as well as zooming, without having to re-sample the particle data. We show how our method facilitates the interactive exploration of real-world large-scale MD simulation data in different scenarios.",
            "url": "http://dx.doi.org/10.1109/TVCG.2017.2743979",
            "id": "r_231",
            "s_ids": [
                "s_21",
                "s_107",
                "s_145",
                "s_15",
                "s_300"
            ],
            "type": "rich",
            "x": 9.769572257995605,
            "y": 5.059372901916504
        },
        {
            "title": "ManyVis: Multiple Applications in an Integrated Visualization Environment",
            "data": "As the visualization field matures, an increasing number of general toolkits are developed to cover a broad range of applications. However, no general tool can incorporate the latest capabilities for all possible applications, nor can the user interfaces and workflows be easily adjusted to accommodate all user communities. As a result, users will often chose either substandard solutions presented in familiar, customized tools or assemble a patchwork of individual applications glued through ad-hoc scripts and extensive, manual intervention. Instead, we need the ability to easily and rapidly assemble the best-in-task tools into custom interfaces and workflows to optimally serve any given application community. Unfortunately, creating such meta-applications at the API or SDK level is difficult, time consuming, and often infeasible due to the sheer variety of data models, design philosophies, limits in functionality, and the use of closed commercial systems. In this paper, we present the ManyVis framework which enables custom solutions to be built both rapidly and simply by allowing coordination and communication across existing unrelated applications. ManyVis allows users to combine software tools with complementary characteristics into one virtual application driven by a single, custom-designed interface.",
            "url": "http://dx.doi.org/10.1109/TVCG.2013.174",
            "id": "r_232",
            "s_ids": [
                "s_235",
                "s_356",
                "s_264",
                "s_392",
                "s_273"
            ],
            "type": "rich",
            "x": 11.535894393920898,
            "y": 4.603278636932373
        },
        {
            "title": "OpenSpace: Public dissemination of space mission profiles",
            "data": "This work presents a visualization system and its application to space missions. The system allows the public to disseminate the scientific findings of space craft and gain a greater understanding thereof. Instruments' field-of-views and their measurements are embedded in an accurate 3 dimensional rendering of the solar system to provide context to past measurements or the planning of future events. We tested our system with NASA's New Horizons at the Pluto Pallooza event in New York and will expose it to the greater public on the upcoming July 14th Pluto flyby.",
            "url": "http://dx.doi.org/10.1109/SciVis.2015.7429503",
            "id": "r_233",
            "s_ids": [
                "s_457",
                "s_138",
                "s_618",
                "s_620",
                "s_244"
            ],
            "type": "rich",
            "x": 10.69024658203125,
            "y": 4.618854522705078
        },
        {
            "title": "Analysis of the Near-Wall Flow in a Turbine Cascade by Splat Visualization",
            "data": "Turbines are essential components of jet planes and power plants. Therefore, their efficiency and service life are of central engineering interest. In the case of jet planes or thermal power plants, the heating of the turbines due to the hot gas flow is critical. Besides effective cooling, it is a major goal of engineers to minimize heat transfer between gas flow and turbine by design. Since it is known that splat events have a substantial impact on the heat transfer between flow and immersed surfaces, we adapt a splat detection and visualization method to a turbine cascade simulation in this case study. Because splat events are small phenomena, we use a direct numerical simulation resolving the turbulence in the flow as the base of our analysis. The outcome shows promising insights into splat formation and its relation to vortex structures. This may lead to better turbine design in the future.",
            "url": "http://dx.doi.org/10.1109/TVCG.2019.2934367",
            "id": "r_234",
            "s_ids": [
                "s_64",
                "s_116",
                "s_189",
                "s_267",
                "s_127",
                "s_328"
            ],
            "type": "rich",
            "x": 8.470778465270996,
            "y": 5.261552333831787
        },
        {
            "title": "Multiscale Visual Drilldown for the Analysis of Large Ensembles of Multi-Body Protein Complexes",
            "data": "When studying multi-body protein complexes, biochemists use computational tools that can suggest hundreds or thousands of their possible spatial configurations. However, it is not feasible to experimentally verify more than only a very small subset of them. In this paper, we propose a novel multiscale visual drilldown approach that was designed in tight collaboration with proteomic experts, enabling a systematic exploration of the configuration space. Our approach takes advantage of the hierarchical structure of the data \u2013 from the whole ensemble of protein complex configurations to the individual configurations, their contact interfaces, and the interacting amino acids. Our new solution is based on interactively linked 2D and 3D views for individual hierarchy levels. At each level, we offer a set of selection and filtering operations that enable the user to narrow down the number of configurations that need to be manually scrutinized. Furthermore, we offer a dedicated filter interface, which provides the users with an overview of the applied filtering operations and enables them to examine their impact on the explored ensemble. This way, we maintain the history of the exploration process and thus enable the user to return to an earlier point of the exploration. We demonstrate the effectiveness of our approach on two case studies conducted by collaborating proteomic experts.",
            "url": "http://dx.doi.org/10.1109/TVCG.2019.2934333",
            "id": "r_235",
            "s_ids": [
                "s_268",
                "s_253",
                "s_448",
                "s_338",
                "s_141"
            ],
            "type": "rich",
            "x": 11.881966590881348,
            "y": 3.2253782749176025
        },
        {
            "title": "Visualization of Flow Behavior in Earth Mantle Convection",
            "data": "A fundamental characteristic of fluid flow is that it causes mixing: introduce a dye into a flow, and it will disperse. Mixing can be used as a method to visualize and characterize flow. Because mixing is a process that occurs over time, it is a 4D problem that presents a challenge for computation, visualization, and analysis. Motivated by a mixing problem in geophysics, we introduce a combination of methods to analyze, transform, and finally visualize mixing in simulations of convection in a self-gravitating 3D spherical shell representing convection in the Earth's mantle. Geophysicists use tools such as the finite element model CitcomS to simulate convection, and introduce massless, passive tracers to model mixing. The output of geophysical flow simulation is hard to analyze for domain experts because of overall data size and complexity. In addition, information overload and occlusion are problems when visualizing a whole-earth model. To address the large size of the data, we rearrange the simulation data using intelligent indexing for fast file access and efficient caching. To address information overload and interpret mixing, we compute tracer concentration statistics, which are used to characterize mixing in mantle convection models. Our visualization uses a specially tailored version of Direct Volume Rendering. The most important adjustment is the use of constant opacity. Because of this special area of application, i. e. the rendering of a spherical shell, many computations for volume rendering can be optimized. These optimizations are essential to a smooth animation of the time-dependent simulation data. Our results show how our system can be used to quickly assess the simulation output and test hypotheses regarding Earth's mantle convection. The integrated processing pipeline helps geoscientists to focus on their main task of analyzing mantle homogenization.",
            "url": "http://dx.doi.org/10.1109/TVCG.2012.283",
            "id": "r_236",
            "s_ids": [
                "s_99",
                "s_513",
                "s_646",
                "s_601",
                "s_332",
                "s_365"
            ],
            "type": "rich",
            "x": 10.06442642211914,
            "y": 5.5345988273620605
        },
        {
            "title": "Cumulative Heat Diffusion Using Volume Gradient Operator for Volume Analysis",
            "data": "We introduce a simple, yet powerful method called the Cumulative Heat Diffusion for shape-based volume analysis, while drastically reducing the computational cost compared to conventional heat diffusion. Unlike the conventional heat diffusion process, where the diffusion is carried out by considering each node separately as the source, we simultaneously consider all the voxels as sources and carry out the diffusion, hence the term cumulative heat diffusion. In addition, we introduce a new operator that is used in the evaluation of cumulative heat diffusion called the Volume Gradient Operator (VGO). VGO is a combination of the LBO and a data-driven operator which is a function of the half gradient. The half gradient is the absolute value of the difference between the voxel intensities. The VGO by its definition captures the local shape information and is used to assign the initial heat values. Furthermore, VGO is also used as the weighting parameter for the heat diffusion process. We demonstrate that our approach can robustly extract shape-based features and thus forms the basis for an improved classification and exploration of features based on shape.",
            "url": "http://dx.doi.org/10.1109/TVCG.2012.210",
            "id": "r_237",
            "s_ids": [
                "s_464",
                "s_176",
                "s_13"
            ],
            "type": "rich",
            "x": 9.630565643310547,
            "y": 5.555126667022705
        },
        {
            "title": "Analysis of Streamline Separation at Infinity Using Time-Discrete Markov Chains",
            "data": "Existing methods for analyzing separation of streamlines are often restricted to a finite time or a local area. In our paper we introduce a new method that complements them by allowing an infinite-time-evaluation of steady planar vector fields. Our algorithm unifies combinatorial and probabilistic methods and introduces the concept of separation in time-discrete Markov-Chains. We compute particle distributions instead of the streamlines of single particles. We encode the flow into a map and then into a transition matrix for each time direction. Finally, we compare the results of our grid-independent algorithm to the popular Finite-Time-Lyapunov-Exponents and discuss the discrepancies.",
            "url": "http://dx.doi.org/10.1109/TVCG.2012.198",
            "id": "r_238",
            "s_ids": [
                "s_370",
                "s_116"
            ],
            "type": "rich",
            "x": 7.695365905761719,
            "y": 5.900307655334473
        },
        {
            "title": "Uncertainty in Continuous Scatterplots, Continuous Parallel Coordinates, and Fibers",
            "data": "In this paper, we introduce uncertainty to continuous scatterplots and continuous parallel coordinates. We derive respective models, validate them with sampling-based brute-force schemes, and present acceleration strategies for their computation. At the same time, we show that our approach lends itself as well for introducing uncertainty into the definition of fibers in bivariate data. Finally, we demonstrate the properties and the utility of our approach using specifically designed synthetic cases and simulated data.",
            "url": "http://dx.doi.org/10.1109/TVCG.2020.3030466",
            "id": "r_239",
            "s_ids": [
                "s_575",
                "s_641"
            ],
            "type": "rich",
            "x": 10.810347557067871,
            "y": 7.288801193237305
        },
        {
            "title": "IsoTrotter: Visually Guided Empirical Modelling of Atmospheric Convection",
            "data": "Empirical models, fitted to data from observations, are often used in natural sciences to describe physical behaviour and support discoveries. However, with more complex models, the regression of parameters quickly becomes insufficient, requiring a visual parameter space analysis to understand and optimize the models. In this work, we present a design study for building a model describing atmospheric convection. We present a mixed-initiative approach to visually guided modelling, integrating an interactive visual parameter space analysis with partial automatic parameter optimization. Our approach includes a new, semi-automatic technique called IsoTrotting, where we optimize the procedure by navigating along isocontours of the model. We evaluate the model with unique observational data of atmospheric convection based on flight trajectories of paragliders.",
            "url": "http://dx.doi.org/10.1109/TVCG.2020.3030389",
            "id": "r_240",
            "s_ids": [
                "s_449",
                "s_408",
                "s_338"
            ],
            "type": "rich",
            "x": 10.867530822753906,
            "y": 6.0701189041137695
        },
        {
            "title": "Multi-Scale Procedural Animations of Microtubule Dynamics Based on Measured Data",
            "data": "Biologists often use computer graphics to visualize structures, which due to physical limitations are not possible to image with a microscope. One example for such structures are microtubules, which are present in every eukaryotic cell. They are part of the cytoskeleton maintaining the shape of the cell and playing a key role in the cell division. In this paper, we propose a scientifically-accurate multi-scale procedural model of microtubule dynamics as a novel application scenario for procedural animation, which can generate visualizations of their overall shape, molecular structure, as well as animations of the dynamic behaviour of their growth and disassembly. The model is spanning from tens of micrometers down to atomic resolution. All the aspects of the model are driven by scientific data. The advantage over a traditional, manual animation approach is that when the underlying data change, for instance due to new evidence, the model can be recreated immediately. The procedural animation concept is presented in its generic form, with several novel extensions, facilitating an easy translation to other domains with emergent multi-scale behavior.",
            "url": "http://dx.doi.org/10.1109/TVCG.2019.2934612",
            "id": "r_241",
            "s_ids": [
                "s_402",
                "s_395",
                "s_474",
                "s_626"
            ],
            "type": "rich",
            "x": 11.814033508300781,
            "y": 3.6187949180603027
        },
        {
            "title": "The Effect of Data Transformations on Scalar Field Topological Analysis of High-Order FEM Solutions",
            "data": "High-order finite element methods (HO-FEM) are gaining popularity in the simulation community due to their success in solving complex flow dynamics. There is an increasing need to analyze the data produced as output by these simulations. Simultaneously, topological analysis tools are emerging as powerful methods for investigating simulation data. However, most of the current approaches to topological analysis have had limited application to HO-FEM simulation data for two reasons. First, the current topological tools are designed for linear data (polynomial degree one), but the polynomial degree of the data output by these simulations is typically higher (routinely up to polynomial degree six). Second, the simulation data and derived quantities of the simulation data have discontinuities at element boundaries, and these discontinuities do not match the input requirements for the topological tools. One solution to both issues is to transform the high-order data to achieve low-order, continuous inputs for topological analysis. Nevertheless, there has been little work evaluating the possible transformation choices and their downstream effect on the topological analysis. We perform an empirical study to evaluate two commonly used data transformation methodologies along with the recently introduced L-SIAC filter for processing high-order simulation data. Our results show diverse behaviors are possible. We offer some guidance about how best to consider a pipeline of topological analysis of HO-FEM simulations with the currently available implementations of topological analysis.",
            "url": "http://dx.doi.org/10.1109/TVCG.2019.2934338",
            "id": "r_242",
            "s_ids": [
                "s_489",
                "s_577",
                "s_453"
            ],
            "type": "rich",
            "x": 9.061636924743652,
            "y": 6.886024475097656
        },
        {
            "title": "Accelerated Monte Carlo Rendering of Finite-Time Lyapunov Exponents",
            "data": "Time-dependent fluid flows often contain numerous hyperbolic Lagrangian coherent structures, which act as transport barriers that guide the advection. The finite-time Lyapunov exponent is a commonly-used approximation to locate these repelling or attracting structures. Especially on large numerical simulations, the FTLE ridges can become arbitrarily sharp and very complex. Thus, the discrete sampling onto a grid for a subsequent direct volume rendering is likely to miss sharp ridges in the visualization. For this reason, an unbiased Monte Carlo-based rendering approach was recently proposed that treats the FTLE field as participating medium with single scattering. This method constructs a ground truth rendering without discretization, but it is prohibitively slow with render times in the order of days or weeks for a single image. In this paper, we accelerate the rendering process significantly, which allows us to compute video sequence of high-resolution FTLE animations in a much more reasonable time frame. For this, we follow two orthogonal approaches to improve on the rendering process: the volumetric light path integration in gradient domain and an acceleration of the transmittance estimation. We analyze the convergence and performance of the proposed method and demonstrate the approach by rendering complex FTLE fields in several 3D vector fields.",
            "url": "http://dx.doi.org/10.1109/TVCG.2019.2934313",
            "id": "r_243",
            "s_ids": [
                "s_84",
                "s_562",
                "s_443"
            ],
            "type": "rich",
            "x": 9.469539642333984,
            "y": 4.685255527496338
        },
        {
            "title": "DT-MRI Streamsurfaces Revisited",
            "data": "DT-MRI streamsurfaces, defined as surfaces that are everywhere tangential to the major and medium eigenvector fields, have been proposed as a tool for visualizing regions of predominantly planar behavior in diffusion tensor MRI. Even though it has long been known that their construction assumes that the involved eigenvector fields satisfy an integrability condition, it has never been tested systematically whether this condition is met in real-world data. We introduce a suitable and efficiently computable test to the visualization literature, demonstrate that it can be used to distinguish integrable from nonintegrable configurations in simulations, and apply it to whole-brain datasets of 15 healthy subjects. We conclude that streamsurface integrability is approximately satisfied in a substantial part of the brain, but not everywhere, including some regions of planarity. As a consequence, algorithms for streamsurface extraction should explicitly test local integrability. Finally, we propose a novel patch-based approach to streamsurface visualization that reduces visual artifacts, and is shown to more fully sample the extent of streamsurfaces.",
            "url": "http://dx.doi.org/10.1109/TVCG.2018.2864845",
            "id": "r_244",
            "s_ids": [
                "s_180",
                "s_558"
            ],
            "type": "rich",
            "x": 7.663745403289795,
            "y": 5.8162946701049805
        },
        {
            "title": "Firefly: Virtual Illumination Drones for Interactive Visualization",
            "data": "Light specification in three dimensional scenes is a complex problem and several approaches have been presented that aim to automate this process. However, there are many scenarios where a static light setup is insufficient, as the scene content and camera position may change. Simultaneous manual control over the camera and light position imposes a high cognitive load on the user. To address this challenge, we introduce a novel approach for automatic scene illumination with Fireflies. Fireflies are intelligent virtual light drones that illuminate the scene by traveling on a closed path. The Firefly path automatically adapts to changes in the scene based on an outcome-oriented energy function. To achieve interactive performance, we employ a parallel rendering pipeline for the light path evaluations. We provide a catalog of energy functions for various application scenarios and discuss the applicability of our method on several examples.",
            "url": "http://dx.doi.org/10.1109/TVCG.2018.2864656",
            "id": "r_245",
            "s_ids": [
                "s_502",
                "s_135",
                "s_162"
            ],
            "type": "rich",
            "x": 9.532069206237793,
            "y": 4.0227274894714355
        },
        {
            "title": "Effectiveness of Structured Textures on Dynamically Changing Terrain-like Surfaces",
            "data": "Previous perceptual research and human factors studies have identified several effective methods for texturing 3D surfaces to ensure that their curvature is accurately perceived by viewers. However, most of these studies examined the application of these techniques to static surfaces. This paper explores the effectiveness of applying these techniques to dynamically changing surfaces. When these surfaces change shape, common texturing methods, such as grids and contours, induce a range of different motion cues, which can draw attention and provide information about the size, shape, and rate of change. A human factors study was conducted to evaluate the relative effectiveness of these methods when applied to dynamically changing pseudo-terrain surfaces. The results indicate that, while no technique is most effective for all cases, contour lines generally perform best, and that the pseudo-contour lines induced by banded color scales convey the same benefits.",
            "url": "http://dx.doi.org/10.1109/TVCG.2015.2467962",
            "id": "r_246",
            "s_ids": [
                "s_605",
                "s_303"
            ],
            "type": "rich",
            "x": 9.400256156921387,
            "y": 3.2359814643859863
        },
        {
            "title": "Interactive Retro-Deformation of Terrain for Reconstructing 3D Fault Displacements",
            "data": "Planetary topography is the result of complex interactions between geological processes, of which faulting is a prominent component. Surface-rupturing earthquakes cut and move landforms which develop across active faults, producing characteristic surface displacements across the fault. Geometric models of faults and their associated surface displacements are commonly applied to reconstruct these offsets to enable interpretation of the observed topography. However, current 2D techniques are limited in their capability to convey both the three-dimensional kinematics of faulting and the incremental sequence of events required by a given reconstruction. Here we present a real-time system for interactive retro-deformation of faulted topography to enable reconstruction of fault displacement within a high-resolution (sub 1m/pixel) 3D terrain visualization. We employ geometry shaders on the GPU to intersect the surface mesh with fault-segments interactively specified by the user and transform the resulting surface blocks in realtime according to a kinematic model of fault motion. Our method facilitates a human-in-the-loop approach to reconstruction of fault displacements by providing instant visual feedback while exploring the parameter space. Thus, scientists can evaluate the validity of traditional point-to-point reconstructions by visually examining a smooth interpolation of the displacement in 3D. We show the efficacy of our approach by using it to reconstruct segments of the San Andreas fault, California as well as a graben structure in the Noctis Labyrinthus region on Mars.",
            "url": "http://dx.doi.org/10.1109/TVCG.2012.239",
            "id": "r_247",
            "s_ids": [
                "s_194",
                "s_382",
                "s_396",
                "s_584",
                "s_87",
                "s_295",
                "s_451",
                "s_365"
            ],
            "type": "rich",
            "x": 10.270195960998535,
            "y": 5.414629936218262
        },
        {
            "title": "Using Maximum Topology Matching to Explore Differences in Species Distribution Models",
            "data": "Species distribution models (SDM) are used to help understand what drives the distribution of various plant and animal species. These models are typically high dimensional scalar functions, where the dimensions of the domain correspond to predictor variables of the model algorithm. Understanding and exploring the differences between models help ecologists understand areas where their data or understanding of the system is incomplete and will help guide further investigation in these regions. These differences can also indicate an important source of model to model uncertainty. However, it is cumbersome and often impractical to perform this analysis using existing tools, which allows for manual exploration of the models usually as 1-dimensional curves. In this paper, we propose a topology-based framework to help ecologists explore the differences in various SDMs directly in the high dimensional domain. In order to accomplish this, we introduce the concept of maximum topology matching that computes a locality-aware correspondence between similar extrema of two scalar functions. The matching is then used to compute the similarity between two functions. We also design a visualization interface that allows ecologists to explore SDMs using their topological features and to study the differences between pairs of models found using maximum topological matching. We demonstrate the utility of the proposed framework through several use cases using different data sets and report the feedback obtained from ecologists.",
            "url": "http://dx.doi.org/10.1109/SciVis.2015.7429486",
            "id": "r_248",
            "s_ids": [
                "s_265",
                "s_27",
                "s_323",
                "s_232",
                "s_344"
            ],
            "type": "rich",
            "x": 10.784971237182617,
            "y": 6.350415229797363
        },
        {
            "title": "Comparing Cross-Sections and 3D Renderings for Surface Matching Tasks Using Physical Ground Truths",
            "data": "Within the visualization community there are some well-known techniques for visualizing 3D spatial data and some general assumptions about how perception affects the performance of these techniques in practice. However, there is a lack of empirical research backing up the possible performance differences among the basic techniques for general tasks. One such assumption is that 3D renderings are better for obtaining an overview, whereas cross sectional visualizations such as the commonly used Multi-Planar Reformation (MPR) are better for supporting detailed analysis tasks. In the present study we investigated this common assumption by examining the difference in performance between MPR and 3D rendering for correctly identifying a known surface. We also examined whether prior experience working with image data affects the participant's performance, and whether there was any difference between interactive or static versions of the visualizations. Answering this question is important because it can be used as part of a scientific and empirical basis for determining when to use which of the two techniques. An advantage of the present study compared to other studies is that several factors were taken into account to compare the two techniques. The problem was examined through an experiment with 45 participants, where physical objects were used as the known surface (ground truth). Our findings showed that: 1. The 3D renderings largely outperformed the cross sections; 2. Interactive visualizations were partially more effective than static visualizations; and 3. The high experience group did not generally outperform the low experience group.",
            "url": "http://dx.doi.org/10.1109/TVCG.2016.2598602",
            "id": "r_249",
            "s_ids": [
                "s_656",
                "s_162"
            ],
            "type": "rich",
            "x": 9.930131912231445,
            "y": 3.301217794418335
        },
        {
            "title": "Hairy Slices: Evaluating the Perceptual Effectiveness of Cutting Plane Glyphs for 3D Vector Fields",
            "data": "Three-dimensional vector fields are common datasets throughout the sciences. Visualizing these fields is inherently difficult due to issues such as visual clutter and self-occlusion. Cutting planes are often used to overcome these issues by presenting more manageable slices of data. The existing literature provides many techniques for visualizing the flow through these cutting planes; however, there is a lack of empirical studies focused on the underlying perceptual cues that make popular techniques successful. This paper presents a quantitative human factors study that evaluates static monoscopic depth and orientation cues in the context of cutting plane glyph designs for exploring and analyzing 3D flow fields. The goal of the study was to ascertain the relative effectiveness of various techniques for portraying the direction of flow through a cutting plane at a given point, and to identify the visual cues and combinations of cues involved, and how they contribute to accurate performance. It was found that increasing the dimensionality of line-based glyphs into tubular structures enhances their ability to convey orientation through shading, and that increasing their diameter intensifies this effect. These tube-based glyphs were also less sensitive to visual clutter issues at higher densities. Adding shadows to lines was also found to increase perception of flow direction. Implications of the experimental results are discussed and extrapolated into a number of guidelines for designing more perceptually effective glyphs for 3D vector field visualizations.",
            "url": "http://dx.doi.org/10.1109/TVCG.2016.2598448",
            "id": "r_250",
            "s_ids": [
                "s_303",
                "s_605",
                "s_333"
            ],
            "type": "rich",
            "x": 9.312348365783691,
            "y": 3.091069221496582
        },
        {
            "title": "Escape Maps",
            "data": "We present a technique to visualize the streamline-based mapping between the boundary of a simply-connected subregion of arbitrary 3D vector fields. While the streamlines are seeded on one part of the boundary, the remaining part serves as escape border. Hence, the seeding part of the boundary represents a map of streamline behavior, indicating if streamlines reach the escape border or not. Since the resulting maps typically exhibit a very fine and complex structure and are thus not amenable to direct sampling, our approach instead aims at topologically consistent extraction of their boundary. We show that isocline surfaces of the projected vector field provide a robust basis for stream-surface-based extraction of these boundaries. The utility of our technique is demonstrated in the context of transport processes using vector field data from different domains.",
            "url": "http://dx.doi.org/10.1109/TVCG.2014.2346442",
            "id": "r_251",
            "s_ids": [
                "s_90",
                "s_641",
                "s_211",
                "s_277"
            ],
            "type": "rich",
            "x": 7.733936309814453,
            "y": 5.815454006195068
        },
        {
            "title": "An evaluation of three methods for visualizing uncertainty in architecture and archaeology",
            "data": "This project explores the representation of uncertainty in visualizations for archaeological research and provides insights obtained from user feedback. Our 3D models brought together information from standing architecture and excavated remains, surveyed plans, ground penetrating radar (GPR) data from the Carthusian monastery of Bourgfontaine in northern France. We also included information from comparative Carthusian sites and a bird's eye representation of the site in an early modern painting. Each source was assigned a certainty value which was then mapped to a color or texture for the model. Certainty values between one and zero were assigned by one subject matter expert and should be considered qualitative. Students and faculty from the fields of architectural history and archaeology at two institutions interacted with the models and answered a short survey with four questions about each. We discovered equal preference for color and transparency and a strong dislike for the texture model. Discoveries during model building also led to changes of the excavation plans for summer 2015.",
            "url": "http://dx.doi.org/10.1109/SciVis.2015.7429507",
            "id": "r_252",
            "s_ids": [
                "s_362",
                "s_494",
                "s_363"
            ],
            "type": "rich",
            "x": 10.537936210632324,
            "y": 4.459981918334961
        },
        {
            "title": "Explicit Frequency Control for High-Quality Texture-Based Flow Visualization",
            "data": "In this work we propose an effective method for frequency-controlled dense flow visualization derived from a generalization of the Line Integral Convolution (LIC) technique. Our approach consists in considering the spectral properties of the dense flow visualization process as an integral operator defined in a local curvilinear coordinate system aligned with the flow. Exploring LIC from this point of view, we suggest a systematic way to design a flow visualization process with particular local spatial frequency properties of the resulting image. Our method is efficient, intuitive, and based on a long-standing model developed as a result of numerous perception studies. The method can be described as an iterative application of line integral convolution, followed by a one-dimensional Gabor filtering orthogonal to the flow. To demonstrate the utility of the technique, we generated novel adaptive multi-frequency flow visualizations, that according to our evaluation, feature a higher level of frequency control and higher quality scores than traditional approaches in texture-based flow visualization.",
            "url": "http://dx.doi.org/10.1109/SciVis.2015.7429490",
            "id": "r_253",
            "s_ids": [
                "s_111",
                "s_427"
            ],
            "type": "rich",
            "x": 8.056612968444824,
            "y": 5.648409843444824
        },
        {
            "title": "High performance flow field visualization with high-order access dependencies",
            "data": "We present a novel model based on high-order access dependencies for high performance pathline computation in flow field. The high-order access dependencies are defined as transition probabilities from one data block to other blocks based on a few historical data accesses. Compared with existing methods which employed first-order access dependencies, our approach takes the advantages of high order access dependencies with higher accuracy and reliability in data access prediction. In our work, high-order access dependencies are calculated by tracing densely-seeded pathlines. The efficiency of our proposed approach is demonstrated through a parallel particle tracing framework with high-order data prefetching. Results show that our method can achieve higher data locality than the first-order access dependencies based method, thereby reducing the I/O requests and improving the efficiency of pathline computation in various applications.",
            "url": "http://dx.doi.org/10.1109/SciVis.2015.7429515",
            "id": "r_254",
            "s_ids": [
                "s_108",
                "s_136",
                "s_434"
            ],
            "type": "rich",
            "x": 9.105880737304688,
            "y": 7.745019435882568
        },
        {
            "title": "Visualizing 3D flow through cutting planes",
            "data": "Studies have found conflicting results regarding the effectiveness of tube-like structures for representing 3D flow data. This paper presents the findings of a small-scale pilot study contrasting static monoscopic depth cues to ascertain their importance in perceiving the orientation of a three-dimensional glyph with respect to a cutting plane. A simple striped texture and shading were found to reduce judgement errors when used with a 3D tube glyph as compared to plain or shaded line glyphs. A discussion of considerations for a full-scale study and possible future work follows.",
            "url": "http://dx.doi.org/10.1109/SciVis.2015.7429513",
            "id": "r_255",
            "s_ids": [
                "s_333",
                "s_303"
            ],
            "type": "rich",
            "x": 9.313109397888184,
            "y": 3.1446022987365723
        },
        {
            "title": "PathlinesExplorer ??? Image-based exploration of large-scale pathline fields",
            "data": "PathlinesExplorer is a novel image-based tool, which has been designed to visualize large scale pathline fields on a single computer [7]. PathlinesExplorer integrates explorable images (EI) technique [4] with order-independent transparency (OIT) method [2]. What makes this method different is that it allows users to handle large data on a single workstation. Although it is a view-dependent method, PathlinesExplorer combines both exploration and modification of visual aspects without re-accessing the original huge data. Our approach is based on constructing a per-pixel linked list data structure in which each pixel contains a list of pathline segments. With this view-dependent method, it is possible to filter, color-code, and explore large-scale flow data in real-time. In addition, optimization techniques such as early-ray termination and deferred shading are applied, which further improves the performance and scalability of our approach.",
            "url": "http://dx.doi.org/10.1109/SciVis.2015.7429512",
            "id": "r_256",
            "s_ids": [
                "s_373",
                "s_300",
                "s_22"
            ],
            "type": "rich",
            "x": 9.242120742797852,
            "y": 6.360678672790527
        },
        {
            "title": "A bottom-up scheme for user-defined feature exploration in vector field ensembles",
            "data": "Most of the existing approaches to visualize vector field ensembles are achieved by visualizing the uncertainty of individual variables from different simulation runs. However, the comparison of the derived feature or user-defined feature, such as the vortex in ensemble flow is also of vital significance since they often make more sense according to the domain knowledge. In this work, we present a framework to extract user-defined feature from different simulation runs. Specially, we use a bottom-up searching scheme to help to extract vortex with a user-defined shape, and further compute the geometry information including the size, and the geo-spatial location of the extracted vortex. Finally we design some linked views to compare the feature between different runs.",
            "url": "http://dx.doi.org/10.1109/SciVis.2015.7429510",
            "id": "r_257",
            "s_ids": [
                "s_78",
                "s_136",
                "s_434"
            ],
            "type": "rich",
            "x": 11.138904571533203,
            "y": 6.6440277099609375
        },
        {
            "title": "Real-time interactive time correction on the GPU",
            "data": "The study of physical phenomena and their dynamic evolution is supported by the analysis and visualization of time-enabled data. In many applications, available data are sparsely distributed in the space-time domain, which leads to incomprehensible visualizations. We present an interactive approach for the dynamic tracking and visualization of measured data particles through advection in a simulated flow. We introduce a fully GPU-based technique for efficient spatio-temporal interpolation, using a kd-tree forest for acceleration. As the user interacts with the system using a time slider, particle positions are reconstructed for the time selected by the user. Our results show that the proposed technique achieves highly accurate parallel tracking for thousands of particles. The rendering performance is mainly affected by the size of the query set.",
            "url": "http://dx.doi.org/10.1109/SciVis.2015.7429505",
            "id": "r_258",
            "s_ids": [
                "s_287",
                "s_216",
                "s_132",
                "s_44",
                "s_40"
            ],
            "type": "rich",
            "x": 10.08668327331543,
            "y": 5.142521381378174
        },
        {
            "id": "s_0",
            "name": "Werner Purgathofer",
            "type": "sparse",
            "x": 10.022345542907715,
            "y": 3.189236640930176
        },
        {
            "id": "s_1",
            "name": "\u00c0lvar Vinacua",
            "type": "sparse",
            "x": 12.226906776428223,
            "y": 3.3621227741241455
        },
        {
            "id": "s_2",
            "name": "Alexander Hann",
            "type": "sparse",
            "x": 7.923369407653809,
            "y": 3.8280584812164307
        },
        {
            "id": "s_3",
            "name": "Bei Wang 0001",
            "type": "sparse",
            "x": 9.723274230957031,
            "y": 6.158268451690674
        },
        {
            "id": "s_4",
            "name": "Lawrence Roy",
            "type": "sparse",
            "x": 8.406547546386719,
            "y": 6.149629592895508
        },
        {
            "id": "s_5",
            "name": "John J. Socha",
            "type": "sparse",
            "x": 11.837074279785156,
            "y": 4.974132537841797
        },
        {
            "id": "s_6",
            "name": "Lucas Schutz",
            "type": "sparse",
            "x": 11.682938575744629,
            "y": 3.604092597961426
        },
        {
            "id": "s_7",
            "name": "Ben Torkian",
            "type": "sparse",
            "x": 11.046210289001465,
            "y": 5.584549427032471
        },
        {
            "id": "s_8",
            "name": "Andrzej Staszczak",
            "type": "sparse",
            "x": 9.687100410461426,
            "y": 5.438337326049805
        },
        {
            "id": "s_9",
            "name": "Tom Peterka",
            "type": "sparse",
            "x": 9.851946830749512,
            "y": 6.243366241455078
        },
        {
            "id": "s_10",
            "name": "Charles Gueunet",
            "type": "sparse",
            "x": 9.504298210144043,
            "y": 7.175880432128906
        },
        {
            "id": "s_11",
            "name": "Elizabeth H. Keating",
            "type": "sparse",
            "x": 11.046210289001465,
            "y": 5.584549427032471
        },
        {
            "id": "s_12",
            "name": "Marco C. DeRuiter",
            "type": "sparse",
            "x": 7.703056812286377,
            "y": 3.7510366439819336
        },
        {
            "id": "s_13",
            "name": "Arie E. Kaufman",
            "type": "sparse",
            "x": 9.314610481262207,
            "y": 4.502406597137451
        },
        {
            "id": "s_14",
            "name": "Joel Kronander",
            "type": "sparse",
            "x": 9.420313835144043,
            "y": 4.213506698608398
        },
        {
            "id": "s_15",
            "name": "Guido Reina",
            "type": "sparse",
            "x": 10.44697093963623,
            "y": 4.560357570648193
        },
        {
            "id": "s_16",
            "name": "Mahsa Mirzargar",
            "type": "sparse",
            "x": 10.927022933959961,
            "y": 6.487303733825684
        },
        {
            "id": "s_17",
            "name": "Joseph Marino",
            "type": "sparse",
            "x": 8.371740341186523,
            "y": 4.055400371551514
        },
        {
            "id": "s_18",
            "name": "Christoph Heinzl",
            "type": "sparse",
            "x": 9.63201904296875,
            "y": 4.962031841278076
        },
        {
            "id": "s_19",
            "name": "Tino Weinkauf",
            "type": "sparse",
            "x": 9.514324188232422,
            "y": 6.778389930725098
        },
        {
            "id": "s_20",
            "name": "Philipp Berg",
            "type": "sparse",
            "x": 7.429879188537598,
            "y": 4.097731113433838
        },
        {
            "id": "s_21",
            "name": "Mohamed Ibrahim",
            "type": "sparse",
            "x": 9.769572257995605,
            "y": 5.059372901916504
        },
        {
            "id": "s_22",
            "name": "Madhusudhanan Srinivasan",
            "type": "sparse",
            "x": 9.242120742797852,
            "y": 6.360678672790527
        },
        {
            "id": "s_23",
            "name": "Christian Dick",
            "type": "sparse",
            "x": 10.631356239318848,
            "y": 6.770925998687744
        },
        {
            "id": "s_24",
            "name": "Roxana Bujack",
            "type": "sparse",
            "x": 11.742826461791992,
            "y": 5.224259376525879
        },
        {
            "id": "s_25",
            "name": "Gunnar L\u00e4th\u00e9n",
            "type": "sparse",
            "x": 7.587300777435303,
            "y": 4.17347526550293
        },
        {
            "id": "s_26",
            "name": "Andre Waschk",
            "type": "sparse",
            "x": 9.98121452331543,
            "y": 3.217468738555908
        },
        {
            "id": "s_27",
            "name": "Harish Doraiswamy",
            "type": "sparse",
            "x": 10.583358764648438,
            "y": 5.919450759887695
        },
        {
            "id": "s_28",
            "name": "Nathaniel Fout",
            "type": "sparse",
            "x": 10.149543762207031,
            "y": 7.815645694732666
        },
        {
            "id": "s_29",
            "name": "Takahiro Yamamoto",
            "type": "sparse",
            "x": 8.604155540466309,
            "y": 6.688293933868408
        },
        {
            "id": "s_30",
            "name": "Jonas Lukasczyk",
            "type": "sparse",
            "x": 9.811539649963379,
            "y": 7.115602493286133
        },
        {
            "id": "s_31",
            "name": "Yusu Wang 0001",
            "type": "sparse",
            "x": 10.1434907913208,
            "y": 7.183420181274414
        },
        {
            "id": "s_32",
            "name": "Jan Reininghaus",
            "type": "sparse",
            "x": 9.439054489135742,
            "y": 6.879550457000732
        },
        {
            "id": "s_33",
            "name": "Luc Wilson",
            "type": "sparse",
            "x": 12.079547882080078,
            "y": 6.148656845092773
        },
        {
            "id": "s_34",
            "name": "Mingdong Zhang",
            "type": "sparse",
            "x": 11.183948516845703,
            "y": 6.4268107414245605
        },
        {
            "id": "s_35",
            "name": "Heike Leitte",
            "type": "sparse",
            "x": 10.451201438903809,
            "y": 6.272016525268555
        },
        {
            "id": "s_36",
            "name": "Tim Hewson",
            "type": "sparse",
            "x": 9.193537712097168,
            "y": 5.438432216644287
        },
        {
            "id": "s_37",
            "name": "Christian Tietjen",
            "type": "sparse",
            "x": 8.06396770477295,
            "y": 3.848623752593994
        },
        {
            "id": "s_38",
            "name": "Qi Wu 0015",
            "type": "sparse",
            "x": 9.856490135192871,
            "y": 4.772428512573242
        },
        {
            "id": "s_39",
            "name": "Kui Wu 0003",
            "type": "sparse",
            "x": 8.78370189666748,
            "y": 5.757442951202393
        },
        {
            "id": "s_40",
            "name": "Hicham G. Elmongui",
            "type": "sparse",
            "x": 10.08668327331543,
            "y": 5.142521381378174
        },
        {
            "id": "s_41",
            "name": "Saad Nadeem",
            "type": "sparse",
            "x": 8.3428316116333,
            "y": 4.206761837005615
        },
        {
            "id": "s_42",
            "name": "Tobias Rapp",
            "type": "sparse",
            "x": 10.616497039794922,
            "y": 7.0372395515441895
        },
        {
            "id": "s_43",
            "name": "Julia Contreras-Garc\u00eda",
            "type": "sparse",
            "x": 12.332874298095703,
            "y": 3.4666783809661865
        },
        {
            "id": "s_44",
            "name": "Junpeng Wang 0001",
            "type": "sparse",
            "x": 10.632567405700684,
            "y": 5.6575117111206055
        },
        {
            "id": "s_45",
            "name": "Andreas Sch\u00e4fler",
            "type": "sparse",
            "x": 10.636197090148926,
            "y": 5.775693893432617
        },
        {
            "id": "s_46",
            "name": "Julian Kreiser",
            "type": "sparse",
            "x": 7.923369407653809,
            "y": 3.8280584812164307
        },
        {
            "id": "s_47",
            "name": "Bastian Rieck",
            "type": "sparse",
            "x": 10.08009147644043,
            "y": 7.1562395095825195
        },
        {
            "id": "s_48",
            "name": "Mar\u00eda Virginia Sabando",
            "type": "sparse",
            "x": 12.367596626281738,
            "y": 3.4548985958099365
        },
        {
            "id": "s_49",
            "name": "Jens G. Magnus",
            "type": "sparse",
            "x": 9.485642433166504,
            "y": 4.147570610046387
        },
        {
            "id": "s_50",
            "name": "Michael Czabaj",
            "type": "sparse",
            "x": 9.158770561218262,
            "y": 5.200885772705078
        },
        {
            "id": "s_51",
            "name": "Duong B. Nguyen",
            "type": "sparse",
            "x": 8.355687141418457,
            "y": 5.508585453033447
        },
        {
            "id": "s_52",
            "name": "Lonni Besan\u00e7on",
            "type": "sparse",
            "x": 11.156147956848145,
            "y": 4.571768760681152
        },
        {
            "id": "s_53",
            "name": "Andrey Krekhov",
            "type": "sparse",
            "x": 9.994787216186523,
            "y": 3.189471483230591
        },
        {
            "id": "s_54",
            "name": "Rui Shi",
            "type": "sparse",
            "x": 8.207507133483887,
            "y": 4.407832145690918
        },
        {
            "id": "s_55",
            "name": "Florian Heimerl",
            "type": "sparse",
            "x": 10.081083297729492,
            "y": 3.169290065765381
        },
        {
            "id": "s_56",
            "name": "Andreas Glatz",
            "type": "sparse",
            "x": 7.550332546234131,
            "y": 5.180576801300049
        },
        {
            "id": "s_57",
            "name": "Michael Sedlmair",
            "type": "sparse",
            "x": 11.824739456176758,
            "y": 4.733576774597168
        },
        {
            "id": "s_58",
            "name": "Alexandru Romosan",
            "type": "sparse",
            "x": 11.046210289001465,
            "y": 5.584549427032471
        },
        {
            "id": "s_59",
            "name": "Uta Preim",
            "type": "sparse",
            "x": 7.481903553009033,
            "y": 4.430104732513428
        },
        {
            "id": "s_60",
            "name": "Prashant Kumar",
            "type": "sparse",
            "x": 8.37214469909668,
            "y": 6.103989601135254
        },
        {
            "id": "s_61",
            "name": "Matthias Labsch\u00fctz",
            "type": "sparse",
            "x": 9.338033676147461,
            "y": 8.028119087219238
        },
        {
            "id": "s_62",
            "name": "Andrea Gomes Campos Bianchi",
            "type": "sparse",
            "x": 9.268465042114258,
            "y": 5.183141231536865
        },
        {
            "id": "s_63",
            "name": "Charles Meneveau",
            "type": "sparse",
            "x": 8.745753288269043,
            "y": 5.485160827636719
        },
        {
            "id": "s_64",
            "name": "Baldwin Nsonga",
            "type": "sparse",
            "x": 8.470778465270996,
            "y": 5.261552333831787
        },
        {
            "id": "s_65",
            "name": "Yi Gu",
            "type": "sparse",
            "x": 11.722888946533203,
            "y": 6.014060020446777
        },
        {
            "id": "s_66",
            "name": "Rickard Englund",
            "type": "sparse",
            "x": 11.291733741760254,
            "y": 4.349414825439453
        },
        {
            "id": "s_67",
            "name": "Hongsen Liao",
            "type": "sparse",
            "x": 11.216442108154297,
            "y": 5.968529224395752
        },
        {
            "id": "s_68",
            "name": "Jennifer K. Ryan",
            "type": "sparse",
            "x": 9.869104385375977,
            "y": 5.354486465454102
        },
        {
            "id": "s_69",
            "name": "David H. Rogers 0001",
            "type": "sparse",
            "x": 11.693486213684082,
            "y": 5.291536331176758
        },
        {
            "id": "s_70",
            "name": "Ayan Biswas",
            "type": "sparse",
            "x": 10.793060302734375,
            "y": 6.8166680335998535
        },
        {
            "id": "s_71",
            "name": "Florian Friess",
            "type": "sparse",
            "x": 12.338919639587402,
            "y": 3.4439263343811035
        },
        {
            "id": "s_72",
            "name": "Pavol Klacansky",
            "type": "sparse",
            "x": 9.790903091430664,
            "y": 6.820262432098389
        },
        {
            "id": "s_73",
            "name": "Bernhard Sadransky",
            "type": "sparse",
            "x": 11.384389877319336,
            "y": 5.067293643951416
        },
        {
            "id": "s_74",
            "name": "Cagatay Turkay",
            "type": "sparse",
            "x": 9.74095344543457,
            "y": 3.124317169189453
        },
        {
            "id": "s_75",
            "name": "Marta Farre",
            "type": "sparse",
            "x": 11.57893180847168,
            "y": 3.877211570739746
        },
        {
            "id": "s_76",
            "name": "Charilaos Papadopoulos",
            "type": "sparse",
            "x": 9.976655960083008,
            "y": 3.5579166412353516
        },
        {
            "id": "s_77",
            "name": "Ladislav Cmol\u00edk",
            "type": "sparse",
            "x": 9.90875244140625,
            "y": 6.525917053222656
        },
        {
            "id": "s_78",
            "name": "Richen Liu",
            "type": "sparse",
            "x": 10.080697059631348,
            "y": 7.171631336212158
        },
        {
            "id": "s_79",
            "name": "Micah Acinapura",
            "type": "sparse",
            "x": 10.920976638793945,
            "y": 4.580874919891357
        },
        {
            "id": "s_80",
            "name": "Kimani C. Toussaint",
            "type": "sparse",
            "x": 9.859582901000977,
            "y": 4.024712085723877
        },
        {
            "id": "s_81",
            "name": "R\u00fcdiger Schernthaner",
            "type": "sparse",
            "x": 7.526188373565674,
            "y": 4.2119927406311035
        },
        {
            "id": "s_82",
            "name": "Narayanan Kasthuri",
            "type": "sparse",
            "x": 11.43094539642334,
            "y": 3.245638847351074
        },
        {
            "id": "s_83",
            "name": "Yu Ye 0002",
            "type": "sparse",
            "x": 12.077192306518555,
            "y": 6.150039196014404
        },
        {
            "id": "s_84",
            "name": "Irene Baeza Rojo",
            "type": "sparse",
            "x": 8.65684700012207,
            "y": 5.224247932434082
        },
        {
            "id": "s_85",
            "name": "Thomas M. Hamill",
            "type": "sparse",
            "x": 11.216442108154297,
            "y": 5.968529224395752
        },
        {
            "id": "s_86",
            "name": "Sebastian Mazza",
            "type": "sparse",
            "x": 10.493793487548828,
            "y": 4.1511454582214355
        },
        {
            "id": "s_87",
            "name": "Klaus Gwinner",
            "type": "sparse",
            "x": 10.270195960998535,
            "y": 5.414629936218262
        },
        {
            "id": "s_88",
            "name": "Haneen Mohammed",
            "type": "sparse",
            "x": 10.40843677520752,
            "y": 5.5256242752075195
        },
        {
            "id": "s_89",
            "name": "Elham Sakhaee",
            "type": "sparse",
            "x": 10.996253967285156,
            "y": 7.526345252990723
        },
        {
            "id": "s_90",
            "name": "Gustavo Mello Machado",
            "type": "sparse",
            "x": 7.733936309814453,
            "y": 5.815454006195068
        },
        {
            "id": "s_91",
            "name": "Saeed Boorboor",
            "type": "sparse",
            "x": 11.093092918395996,
            "y": 3.3198275566101074
        },
        {
            "id": "s_92",
            "name": "Christoph M\u00fcller 0001",
            "type": "sparse",
            "x": 9.232419967651367,
            "y": 5.177774429321289
        },
        {
            "id": "s_93",
            "name": "Mathias Kanzler",
            "type": "sparse",
            "x": 10.634483337402344,
            "y": 6.0569748878479
        },
        {
            "id": "s_94",
            "name": "Tim Biedert",
            "type": "sparse",
            "x": 9.961684226989746,
            "y": 7.1714935302734375
        },
        {
            "id": "s_95",
            "name": "Sabine Bauer 0001",
            "type": "sparse",
            "x": 8.000309944152832,
            "y": 3.6600561141967773
        },
        {
            "id": "s_96",
            "name": "Francesco Parisio",
            "type": "sparse",
            "x": 8.4170560836792,
            "y": 6.109373569488525
        },
        {
            "id": "s_97",
            "name": "Monique Meuschke",
            "type": "sparse",
            "x": 7.461888790130615,
            "y": 4.025900840759277
        },
        {
            "id": "s_98",
            "name": "Daniel Engel",
            "type": "sparse",
            "x": 10.316225051879883,
            "y": 6.546288967132568
        },
        {
            "id": "s_99",
            "name": "Simon Schr\u00f6der",
            "type": "sparse",
            "x": 10.06442642211914,
            "y": 5.5345988273620605
        },
        {
            "id": "s_100",
            "name": "Nate Morrical",
            "type": "sparse",
            "x": 10.56402587890625,
            "y": 3.962571144104004
        },
        {
            "id": "s_101",
            "name": "Christian R\u00f6ssl",
            "type": "sparse",
            "x": 8.258838653564453,
            "y": 6.078034400939941
        },
        {
            "id": "s_102",
            "name": "R\u00fcdiger Westermann",
            "type": "sparse",
            "x": 9.346491813659668,
            "y": 5.8495774269104
        },
        {
            "id": "s_103",
            "name": "Kresimir Matkovic",
            "type": "sparse",
            "x": 8.528419494628906,
            "y": 5.398994445800781
        },
        {
            "id": "s_104",
            "name": "Theodoros Damoulas",
            "type": "sparse",
            "x": 12.044306755065918,
            "y": 6.121316909790039
        },
        {
            "id": "s_105",
            "name": "Stefan Zellmann",
            "type": "sparse",
            "x": 9.819816589355469,
            "y": 4.715269565582275
        },
        {
            "id": "s_106",
            "name": "Roman Gurbat",
            "type": "sparse",
            "x": 11.384389877319336,
            "y": 5.067293643951416
        },
        {
            "id": "s_107",
            "name": "Patrick Wickenhauser",
            "type": "sparse",
            "x": 9.769572257995605,
            "y": 5.059372901916504
        },
        {
            "id": "s_108",
            "name": "Jiang Zhang 0002",
            "type": "sparse",
            "x": 9.02816104888916,
            "y": 7.683526992797852
        },
        {
            "id": "s_109",
            "name": "Nikolina Ban",
            "type": "sparse",
            "x": 10.54450511932373,
            "y": 5.727587699890137
        },
        {
            "id": "s_110",
            "name": "Alexander P. Auchus",
            "type": "sparse",
            "x": 9.786408424377441,
            "y": 3.1464149951934814
        },
        {
            "id": "s_111",
            "name": "Victor Matvienko",
            "type": "sparse",
            "x": 8.056612968444824,
            "y": 5.648409843444824
        },
        {
            "id": "s_112",
            "name": "Dirk J. Lehmann",
            "type": "sparse",
            "x": 7.511942386627197,
            "y": 4.444129943847656
        },
        {
            "id": "s_113",
            "name": "Guadalupe Canahuate",
            "type": "sparse",
            "x": 7.7534637451171875,
            "y": 3.6913716793060303
        },
        {
            "id": "s_114",
            "name": "Ellen Gasparovic",
            "type": "sparse",
            "x": 10.1434907913208,
            "y": 7.183420181274414
        },
        {
            "id": "s_115",
            "name": "Johann Kastner",
            "type": "sparse",
            "x": 9.63201904296875,
            "y": 4.962031841278076
        },
        {
            "id": "s_116",
            "name": "Gerik Scheuermann",
            "type": "sparse",
            "x": 9.40063762664795,
            "y": 5.9297099113464355
        },
        {
            "id": "s_117",
            "name": "Ivan Baclija",
            "type": "sparse",
            "x": 7.526188373565674,
            "y": 4.2119927406311035
        },
        {
            "id": "s_118",
            "name": "Carissa Mai-Ping Knipe",
            "type": "sparse",
            "x": 10.363268852233887,
            "y": 3.31115984916687
        },
        {
            "id": "s_119",
            "name": "Arthur J. Olson",
            "type": "sparse",
            "x": 10.939786911010742,
            "y": 4.956779479980469
        },
        {
            "id": "s_120",
            "name": "Yue Zhang 0009",
            "type": "sparse",
            "x": 8.406547546386719,
            "y": 6.149629592895508
        },
        {
            "id": "s_121",
            "name": "Joerg Meyer",
            "type": "sparse",
            "x": 11.046210289001465,
            "y": 5.584549427032471
        },
        {
            "id": "s_122",
            "name": "Gunther Heidemann",
            "type": "sparse",
            "x": 10.164490699768066,
            "y": 3.3520824909210205
        },
        {
            "id": "s_123",
            "name": "Jakob Troidl",
            "type": "sparse",
            "x": 8.21733283996582,
            "y": 5.677694797515869
        },
        {
            "id": "s_124",
            "name": "Sylvia Gla\u00dfer",
            "type": "sparse",
            "x": 7.434435844421387,
            "y": 4.188709259033203
        },
        {
            "id": "s_125",
            "name": "Subhashis Hazarika",
            "type": "sparse",
            "x": 10.865889549255371,
            "y": 7.137019157409668
        },
        {
            "id": "s_126",
            "name": "Erik Broberg",
            "type": "sparse",
            "x": 10.655271530151367,
            "y": 4.658353328704834
        },
        {
            "id": "s_127",
            "name": "Denis Koschichow",
            "type": "sparse",
            "x": 8.470778465270996,
            "y": 5.261552333831787
        },
        {
            "id": "s_128",
            "name": "Adam Summers",
            "type": "sparse",
            "x": 7.95355749130249,
            "y": 4.046621322631836
        },
        {
            "id": "s_129",
            "name": "Huamin Qu",
            "type": "sparse",
            "x": 11.834354400634766,
            "y": 5.988684177398682
        },
        {
            "id": "s_130",
            "name": "Daniel Weiskopf",
            "type": "sparse",
            "x": 9.886801719665527,
            "y": 4.405052661895752
        },
        {
            "id": "s_131",
            "name": "Christian Blecha",
            "type": "sparse",
            "x": 8.4170560836792,
            "y": 6.109373569488525
        },
        {
            "id": "s_132",
            "name": "Mohamed A. Gad",
            "type": "sparse",
            "x": 10.08668327331543,
            "y": 5.142521381378174
        },
        {
            "id": "s_133",
            "name": "Jonathan Komperda",
            "type": "sparse",
            "x": 11.634987831115723,
            "y": 4.945385932922363
        },
        {
            "id": "s_134",
            "name": "Elmar Eisemann",
            "type": "sparse",
            "x": 8.782272338867188,
            "y": 4.792993545532227
        },
        {
            "id": "s_135",
            "name": "Magnus Paulson Erga",
            "type": "sparse",
            "x": 9.532069206237793,
            "y": 4.0227274894714355
        },
        {
            "id": "s_136",
            "name": "Hanqi Guo 0001",
            "type": "sparse",
            "x": 9.547351837158203,
            "y": 6.567244052886963
        },
        {
            "id": "s_137",
            "name": "Jingshan Pan",
            "type": "sparse",
            "x": 9.022489547729492,
            "y": 7.699234962463379
        },
        {
            "id": "s_138",
            "name": "Michal Marcinkowski",
            "type": "sparse",
            "x": 10.69024658203125,
            "y": 4.618854522705078
        },
        {
            "id": "s_139",
            "name": "Andreas M. Tillmann",
            "type": "sparse",
            "x": 10.020633697509766,
            "y": 4.414642810821533
        },
        {
            "id": "s_140",
            "name": "Karl Bladin",
            "type": "sparse",
            "x": 10.655271530151367,
            "y": 4.658353328704834
        },
        {
            "id": "s_141",
            "name": "Jan Byska",
            "type": "sparse",
            "x": 11.67922592163086,
            "y": 4.101629734039307
        },
        {
            "id": "s_142",
            "name": "Sathish Kottravel",
            "type": "sparse",
            "x": 11.291733741760254,
            "y": 4.349414825439453
        },
        {
            "id": "s_143",
            "name": "David J. Duke",
            "type": "sparse",
            "x": 9.145627975463867,
            "y": 6.063315391540527
        },
        {
            "id": "s_144",
            "name": "Sikun Li",
            "type": "sparse",
            "x": 7.633826732635498,
            "y": 4.75159215927124
        },
        {
            "id": "s_145",
            "name": "Peter Rautek",
            "type": "sparse",
            "x": 9.33781909942627,
            "y": 6.144933223724365
        },
        {
            "id": "s_146",
            "name": "Andreas Just",
            "type": "sparse",
            "x": 7.815420627593994,
            "y": 5.328747272491455
        },
        {
            "id": "s_147",
            "name": "Marco Ament",
            "type": "sparse",
            "x": 9.651206970214844,
            "y": 4.357753276824951
        },
        {
            "id": "s_148",
            "name": "Erik Trostmann",
            "type": "sparse",
            "x": 8.79211139678955,
            "y": 3.6080563068389893
        },
        {
            "id": "s_149",
            "name": "Christoph Peters 0002",
            "type": "sparse",
            "x": 10.616497039794922,
            "y": 7.0372395515441895
        },
        {
            "id": "s_150",
            "name": "Lingyun Yu 0005",
            "type": "sparse",
            "x": 11.355864524841309,
            "y": 5.678099632263184
        },
        {
            "id": "s_151",
            "name": "Hongfeng Yu 0001",
            "type": "sparse",
            "x": 9.947415351867676,
            "y": 6.188593864440918
        },
        {
            "id": "s_152",
            "name": "Alireza Entezari",
            "type": "sparse",
            "x": 10.904932022094727,
            "y": 7.287757873535156
        },
        {
            "id": "s_153",
            "name": "Martina Maritan",
            "type": "sparse",
            "x": 11.946690559387207,
            "y": 3.6632518768310547
        },
        {
            "id": "s_154",
            "name": "Arnold K\u00f6chl",
            "type": "sparse",
            "x": 7.526188373565674,
            "y": 4.2119927406311035
        },
        {
            "id": "s_155",
            "name": "Feng Wang 0013",
            "type": "sparse",
            "x": 9.856490135192871,
            "y": 4.772428512573242
        },
        {
            "id": "s_156",
            "name": "Markus H\u00f6ferlin",
            "type": "sparse",
            "x": 10.164490699768066,
            "y": 3.3520824909210205
        },
        {
            "id": "s_157",
            "name": "Guoning Chen",
            "type": "sparse",
            "x": 8.432869911193848,
            "y": 5.917510986328125
        },
        {
            "id": "s_158",
            "name": "Jun Han 0010",
            "type": "sparse",
            "x": 9.51668930053711,
            "y": 5.881690979003906
        },
        {
            "id": "s_159",
            "name": "Ashley D. Spear",
            "type": "sparse",
            "x": 9.158770561218262,
            "y": 5.200885772705078
        },
        {
            "id": "s_160",
            "name": "Tadija Kekic",
            "type": "sparse",
            "x": 11.893961906433105,
            "y": 3.4554388523101807
        },
        {
            "id": "s_161",
            "name": "Dmitriy Morozov",
            "type": "sparse",
            "x": 9.268465042114258,
            "y": 5.183141231536865
        },
        {
            "id": "s_162",
            "name": "Stefan Bruckner",
            "type": "sparse",
            "x": 9.737253189086914,
            "y": 4.962800979614258
        },
        {
            "id": "s_163",
            "name": "Tim Gerrits",
            "type": "sparse",
            "x": 8.506619453430176,
            "y": 6.261783123016357
        },
        {
            "id": "s_164",
            "name": "Mala Ananth 0001",
            "type": "sparse",
            "x": 11.093092918395996,
            "y": 3.3198275566101074
        },
        {
            "id": "s_165",
            "name": "Marcos Lage",
            "type": "sparse",
            "x": 12.079547882080078,
            "y": 6.148656845092773
        },
        {
            "id": "s_166",
            "name": "Christian Gusenbauer",
            "type": "sparse",
            "x": 9.392159461975098,
            "y": 5.024239540100098
        },
        {
            "id": "s_167",
            "name": "Bireswar Laha",
            "type": "sparse",
            "x": 11.837074279785156,
            "y": 4.974132537841797
        },
        {
            "id": "s_168",
            "name": "Bo Ma 0002",
            "type": "sparse",
            "x": 10.813421249389648,
            "y": 6.905095100402832
        },
        {
            "id": "s_169",
            "name": "M. Leila Mays",
            "type": "sparse",
            "x": 11.090789794921875,
            "y": 6.104916572570801
        },
        {
            "id": "s_170",
            "name": "Francesca Samsel",
            "type": "sparse",
            "x": 11.472042083740234,
            "y": 4.8062005043029785
        },
        {
            "id": "s_171",
            "name": "John J. Baglino",
            "type": "sparse",
            "x": 9.158770561218262,
            "y": 5.200885772705078
        },
        {
            "id": "s_172",
            "name": "Annemieke Verbraeck",
            "type": "sparse",
            "x": 10.143728256225586,
            "y": 4.344464302062988
        },
        {
            "id": "s_173",
            "name": "Benjamin H\u00f6ferlin",
            "type": "sparse",
            "x": 10.164490699768066,
            "y": 3.3520824909210205
        },
        {
            "id": "s_174",
            "name": "Marzieh Berenjkoub",
            "type": "sparse",
            "x": 8.20684814453125,
            "y": 5.359190464019775
        },
        {
            "id": "s_175",
            "name": "Daniel Olson",
            "type": "sparse",
            "x": 11.250597953796387,
            "y": 4.320864677429199
        },
        {
            "id": "s_176",
            "name": "Lei Wang 0024",
            "type": "sparse",
            "x": 9.630565643310547,
            "y": 5.555126667022705
        },
        {
            "id": "s_177",
            "name": "Silvia Fademrecht",
            "type": "sparse",
            "x": 12.338919639587402,
            "y": 3.4439263343811035
        },
        {
            "id": "s_178",
            "name": "Roberto \u00c1lvarez Boto",
            "type": "sparse",
            "x": 12.332874298095703,
            "y": 3.4666783809661865
        },
        {
            "id": "s_179",
            "name": "Shreeraj Jadhav",
            "type": "sparse",
            "x": 11.093092918395996,
            "y": 3.3198275566101074
        },
        {
            "id": "s_180",
            "name": "Michael Ankele",
            "type": "sparse",
            "x": 7.663745403289795,
            "y": 5.8162946701049805
        },
        {
            "id": "s_181",
            "name": "Joseph Budin",
            "type": "sparse",
            "x": 9.152933120727539,
            "y": 7.513338088989258
        },
        {
            "id": "s_182",
            "name": "Jaebum Kim",
            "type": "sparse",
            "x": 11.57893180847168,
            "y": 3.877211570739746
        },
        {
            "id": "s_183",
            "name": "Timo Ropinski",
            "type": "sparse",
            "x": 10.634162902832031,
            "y": 4.406304359436035
        },
        {
            "id": "s_184",
            "name": "Christoph M. Sch\u00e4r",
            "type": "sparse",
            "x": 10.54450511932373,
            "y": 5.727587699890137
        },
        {
            "id": "s_185",
            "name": "Laura Monroe",
            "type": "sparse",
            "x": 11.046210289001465,
            "y": 5.584549427032471
        },
        {
            "id": "s_186",
            "name": "Harsh Bhatia",
            "type": "sparse",
            "x": 9.292150497436523,
            "y": 8.041324615478516
        },
        {
            "id": "s_187",
            "name": "Michael Krone",
            "type": "sparse",
            "x": 12.338919639587402,
            "y": 3.4439263343811035
        },
        {
            "id": "s_188",
            "name": "Liang Zhou 0001",
            "type": "sparse",
            "x": 10.013768196105957,
            "y": 6.791398525238037
        },
        {
            "id": "s_189",
            "name": "Stefan Gumhold",
            "type": "sparse",
            "x": 9.090378761291504,
            "y": 4.746812343597412
        },
        {
            "id": "s_190",
            "name": "Gunther H. Weber",
            "type": "sparse",
            "x": 9.615074157714844,
            "y": 6.1773176193237305
        },
        {
            "id": "s_191",
            "name": "Guillaume Favelier",
            "type": "sparse",
            "x": 9.917837142944336,
            "y": 7.043116569519043
        },
        {
            "id": "s_192",
            "name": "Wenping Wang",
            "type": "sparse",
            "x": 9.252543449401855,
            "y": 5.240782260894775
        },
        {
            "id": "s_193",
            "name": "Ruwayda Alharbi",
            "type": "sparse",
            "x": 11.946690559387207,
            "y": 3.6632518768310547
        },
        {
            "id": "s_194",
            "name": "Rolf Westerteiger",
            "type": "sparse",
            "x": 10.270195960998535,
            "y": 5.414629936218262
        },
        {
            "id": "s_195",
            "name": "Li Chen 0031",
            "type": "sparse",
            "x": 11.2001953125,
            "y": 6.197669982910156
        },
        {
            "id": "s_196",
            "name": "Guang Lin",
            "type": "sparse",
            "x": 10.91222095489502,
            "y": 6.26889705657959
        },
        {
            "id": "s_197",
            "name": "Peter Steneteg",
            "type": "sparse",
            "x": 11.291733741760254,
            "y": 4.349414825439453
        },
        {
            "id": "s_198",
            "name": "Paulo J. S. Silva",
            "type": "sparse",
            "x": 10.020956993103027,
            "y": 7.037785053253174
        },
        {
            "id": "s_199",
            "name": "Luke J. Gosink",
            "type": "sparse",
            "x": 11.165047645568848,
            "y": 6.473668575286865
        },
        {
            "id": "s_200",
            "name": "Kai Zhao",
            "type": "sparse",
            "x": 12.079547882080078,
            "y": 6.148656845092773
        },
        {
            "id": "s_201",
            "name": "Botong Qu",
            "type": "sparse",
            "x": 8.440950393676758,
            "y": 6.195269584655762
        },
        {
            "id": "s_202",
            "name": "Zhiguang Yang",
            "type": "sparse",
            "x": 11.355864524841309,
            "y": 5.678099632263184
        },
        {
            "id": "s_203",
            "name": "Nathan Mays",
            "type": "sparse",
            "x": 11.083663940429688,
            "y": 5.193977355957031
        },
        {
            "id": "s_204",
            "name": "Harry Yeh",
            "type": "sparse",
            "x": 8.546778678894043,
            "y": 6.32175350189209
        },
        {
            "id": "s_205",
            "name": "Daniel Patel",
            "type": "sparse",
            "x": 10.493793487548828,
            "y": 4.1511454582214355
        },
        {
            "id": "s_206",
            "name": "Claes Lundstr\u00f6m",
            "type": "sparse",
            "x": 8.00589370727539,
            "y": 3.8334102630615234
        },
        {
            "id": "s_207",
            "name": "Michael Wimmer 0001",
            "type": "sparse",
            "x": 7.526188373565674,
            "y": 4.2119927406311035
        },
        {
            "id": "s_208",
            "name": "Steven Schlegel",
            "type": "sparse",
            "x": 11.016633987426758,
            "y": 7.623682022094727
        },
        {
            "id": "s_209",
            "name": "Stefan Gunther",
            "type": "sparse",
            "x": 11.682938575744629,
            "y": 3.604092597961426
        },
        {
            "id": "s_210",
            "name": "Stefan M\u00fcller Arisona",
            "type": "sparse",
            "x": 12.077192306518555,
            "y": 6.150039196014404
        },
        {
            "id": "s_211",
            "name": "Thomas M\u00fcller 0005",
            "type": "sparse",
            "x": 9.193339347839355,
            "y": 5.192734718322754
        },
        {
            "id": "s_212",
            "name": "Khaled A. Al-Thelaya",
            "type": "sparse",
            "x": 9.605687141418457,
            "y": 7.465196132659912
        },
        {
            "id": "s_213",
            "name": "Fabian G\u00fcnther",
            "type": "sparse",
            "x": 8.4170560836792,
            "y": 6.109373569488525
        },
        {
            "id": "s_214",
            "name": "Samuel Leventhal",
            "type": "sparse",
            "x": 9.158770561218262,
            "y": 5.200885772705078
        },
        {
            "id": "s_215",
            "name": "Ronald Peikert",
            "type": "sparse",
            "x": 8.528419494628906,
            "y": 5.398994445800781
        },
        {
            "id": "s_216",
            "name": "Denis Gracanin",
            "type": "sparse",
            "x": 10.08668327331543,
            "y": 5.142521381378174
        },
        {
            "id": "s_217",
            "name": "Seth Johnson",
            "type": "sparse",
            "x": 11.250597953796387,
            "y": 4.320864677429199
        },
        {
            "id": "s_218",
            "name": "Elisa De Llano",
            "type": "sparse",
            "x": 11.893961906433105,
            "y": 3.4554388523101807
        },
        {
            "id": "s_219",
            "name": "James Harris",
            "type": "sparse",
            "x": 11.72203254699707,
            "y": 5.292431354522705
        },
        {
            "id": "s_220",
            "name": "Christoph Garth",
            "type": "sparse",
            "x": 10.159004211425781,
            "y": 6.889516353607178
        },
        {
            "id": "s_221",
            "name": "Xin Zhao 0015",
            "type": "sparse",
            "x": 9.550971984863281,
            "y": 6.565341472625732
        },
        {
            "id": "s_222",
            "name": "Florian Reichl",
            "type": "sparse",
            "x": 8.745753288269043,
            "y": 5.485160827636719
        },
        {
            "id": "s_223",
            "name": "Wenchao Wu",
            "type": "sparse",
            "x": 12.0700044631958,
            "y": 6.137913227081299
        },
        {
            "id": "s_224",
            "name": "Oliver Beuing",
            "type": "sparse",
            "x": 7.502920150756836,
            "y": 4.199100017547607
        },
        {
            "id": "s_225",
            "name": "Nicolas Schunck",
            "type": "sparse",
            "x": 9.687100410461426,
            "y": 5.438337326049805
        },
        {
            "id": "s_226",
            "name": "Doug A. Bowman",
            "type": "sparse",
            "x": 11.837074279785156,
            "y": 4.974132537841797
        },
        {
            "id": "s_227",
            "name": "Yixian Zheng",
            "type": "sparse",
            "x": 12.0700044631958,
            "y": 6.137913227081299
        },
        {
            "id": "s_228",
            "name": "Xiaomin Zhu",
            "type": "sparse",
            "x": 11.174348831176758,
            "y": 6.667314052581787
        },
        {
            "id": "s_229",
            "name": "Benjamin J. Isaac",
            "type": "sparse",
            "x": 8.78370189666748,
            "y": 5.757442951202393
        },
        {
            "id": "s_230",
            "name": "David Kouril",
            "type": "sparse",
            "x": 11.020855903625488,
            "y": 4.73865270614624
        },
        {
            "id": "s_231",
            "name": "Sarkis Halladjian",
            "type": "sparse",
            "x": 11.7498779296875,
            "y": 3.6756224632263184
        },
        {
            "id": "s_232",
            "name": "Jeffrey T. Morisette",
            "type": "sparse",
            "x": 10.784971237182617,
            "y": 6.350415229797363
        },
        {
            "id": "s_233",
            "name": "Shigeo Takahashi",
            "type": "sparse",
            "x": 8.604155540466309,
            "y": 6.688293933868408
        },
        {
            "id": "s_234",
            "name": "Bridger Herman",
            "type": "sparse",
            "x": 11.250597953796387,
            "y": 4.320864677429199
        },
        {
            "id": "s_235",
            "name": "Atul Rungta",
            "type": "sparse",
            "x": 11.535894393920898,
            "y": 4.603278636932373
        },
        {
            "id": "s_236",
            "name": "Mark R. Petersen",
            "type": "sparse",
            "x": 10.49360179901123,
            "y": 5.669396877288818
        },
        {
            "id": "s_237",
            "name": "E. Wes Bethel",
            "type": "sparse",
            "x": 10.157337188720703,
            "y": 5.383845329284668
        },
        {
            "id": "s_238",
            "name": "Marcus A. Magnor",
            "type": "sparse",
            "x": 10.020633697509766,
            "y": 4.414642810821533
        },
        {
            "id": "s_239",
            "name": "Martin Skalej",
            "type": "sparse",
            "x": 7.339260101318359,
            "y": 4.169096946716309
        },
        {
            "id": "s_240",
            "name": "Steffen Frey",
            "type": "sparse",
            "x": 9.78760814666748,
            "y": 5.645605564117432
        },
        {
            "id": "s_241",
            "name": "Andrew Wentzel",
            "type": "sparse",
            "x": 7.7534637451171875,
            "y": 3.6913716793060303
        },
        {
            "id": "s_242",
            "name": "Keshav Dasu",
            "type": "sparse",
            "x": 11.563887596130371,
            "y": 4.047283172607422
        },
        {
            "id": "s_243",
            "name": "Gregory P. Johnson",
            "type": "sparse",
            "x": 10.678239822387695,
            "y": 4.729365825653076
        },
        {
            "id": "s_244",
            "name": "Anders Ynnerman",
            "type": "sparse",
            "x": 10.209315299987793,
            "y": 4.804450035095215
        },
        {
            "id": "s_245",
            "name": "Anja C. Schunke",
            "type": "sparse",
            "x": 8.51894760131836,
            "y": 4.0471110343933105
        },
        {
            "id": "s_246",
            "name": "Jean-Philip Piquemal",
            "type": "sparse",
            "x": 12.332874298095703,
            "y": 3.4666783809661865
        },
        {
            "id": "s_247",
            "name": "Wenbin He",
            "type": "sparse",
            "x": 11.178451538085938,
            "y": 6.172502517700195
        },
        {
            "id": "s_248",
            "name": "Lionel M. Ni",
            "type": "sparse",
            "x": 12.0700044631958,
            "y": 6.137913227081299
        },
        {
            "id": "s_249",
            "name": "Min Chen 0001",
            "type": "sparse",
            "x": 11.757099151611328,
            "y": 5.224706649780273
        },
        {
            "id": "s_250",
            "name": "Erik Sund\u00e9n",
            "type": "sparse",
            "x": 10.461533546447754,
            "y": 4.772978782653809
        },
        {
            "id": "s_251",
            "name": "Xianfeng Gu",
            "type": "sparse",
            "x": 8.275169372558594,
            "y": 4.3072967529296875
        },
        {
            "id": "s_252",
            "name": "Teng-Yok Lee",
            "type": "sparse",
            "x": 9.650074005126953,
            "y": 7.513702869415283
        },
        {
            "id": "s_253",
            "name": "Adam Jurc\u00edk",
            "type": "sparse",
            "x": 11.881966590881348,
            "y": 3.2253782749176025
        },
        {
            "id": "s_254",
            "name": "David G\u00fcnther",
            "type": "sparse",
            "x": 10.351324081420898,
            "y": 5.6851887702941895
        },
        {
            "id": "s_255",
            "name": "Peter Lindstrom 0001",
            "type": "sparse",
            "x": 9.275537490844727,
            "y": 7.763484001159668
        },
        {
            "id": "s_256",
            "name": "Ronell Sicat",
            "type": "sparse",
            "x": 9.664959907531738,
            "y": 4.724928855895996
        },
        {
            "id": "s_257",
            "name": "Zhongjie Wang 0001",
            "type": "sparse",
            "x": 9.589593887329102,
            "y": 6.677229404449463
        },
        {
            "id": "s_258",
            "name": "Simon Schubiger",
            "type": "sparse",
            "x": 12.077192306518555,
            "y": 6.150039196014404
        },
        {
            "id": "s_259",
            "name": "Ulrich Lang 0002",
            "type": "sparse",
            "x": 9.819816589355469,
            "y": 4.715269565582275
        },
        {
            "id": "s_260",
            "name": "Remo Burkhard",
            "type": "sparse",
            "x": 12.077192306518555,
            "y": 6.150039196014404
        },
        {
            "id": "s_261",
            "name": "Hrvoje Ribicic",
            "type": "sparse",
            "x": 11.384389877319336,
            "y": 5.067293643951416
        },
        {
            "id": "s_262",
            "name": "Adrian Maries",
            "type": "sparse",
            "x": 11.083663940429688,
            "y": 5.193977355957031
        },
        {
            "id": "s_263",
            "name": "Matias Nicol\u00e1s Selzer",
            "type": "sparse",
            "x": 12.367596626281738,
            "y": 3.4548985958099365
        },
        {
            "id": "s_264",
            "name": "Dogan Demir",
            "type": "sparse",
            "x": 11.535894393920898,
            "y": 4.603278636932373
        },
        {
            "id": "s_265",
            "name": "Jorge Poco",
            "type": "sparse",
            "x": 10.784971237182617,
            "y": 6.350415229797363
        },
        {
            "id": "s_266",
            "name": "Dmitry A. Storchak",
            "type": "sparse",
            "x": 11.72203254699707,
            "y": 5.292431354522705
        },
        {
            "id": "s_267",
            "name": "Jordi Ventosa-Molina",
            "type": "sparse",
            "x": 8.470778465270996,
            "y": 5.261552333831787
        },
        {
            "id": "s_268",
            "name": "Katar\u00edna Furmanov\u00e1",
            "type": "sparse",
            "x": 11.881966590881348,
            "y": 3.2253782749176025
        },
        {
            "id": "s_269",
            "name": "Petra Isenberg",
            "type": "sparse",
            "x": 11.639415740966797,
            "y": 5.164773464202881
        },
        {
            "id": "s_270",
            "name": "Thomas Wilde",
            "type": "sparse",
            "x": 8.011056900024414,
            "y": 5.894285678863525
        },
        {
            "id": "s_271",
            "name": "Terece L. Turton",
            "type": "sparse",
            "x": 11.693486213684082,
            "y": 5.291536331176758
        },
        {
            "id": "s_272",
            "name": "Frederick Federer",
            "type": "sparse",
            "x": 11.264293670654297,
            "y": 3.2105932235717773
        },
        {
            "id": "s_273",
            "name": "Valerio Pascucci",
            "type": "sparse",
            "x": 9.687941551208496,
            "y": 5.9135637283325195
        },
        {
            "id": "s_274",
            "name": "Jeff W. Lichtman",
            "type": "sparse",
            "x": 11.43094539642334,
            "y": 3.245638847351074
        },
        {
            "id": "s_275",
            "name": "Daniel Toloudis",
            "type": "sparse",
            "x": 11.403936386108398,
            "y": 4.0144171714782715
        },
        {
            "id": "s_276",
            "name": "Andrew Burks",
            "type": "sparse",
            "x": 11.634987831115723,
            "y": 4.945385932922363
        },
        {
            "id": "s_277",
            "name": "Thomas Ertl",
            "type": "sparse",
            "x": 9.817098617553711,
            "y": 5.023608207702637
        },
        {
            "id": "s_278",
            "name": "Blake Nelson",
            "type": "sparse",
            "x": 9.855810165405273,
            "y": 5.229278564453125
        },
        {
            "id": "s_279",
            "name": "Xiangfei Meng",
            "type": "sparse",
            "x": 9.022489547729492,
            "y": 7.699234962463379
        },
        {
            "id": "s_280",
            "name": "Haichao Miao",
            "type": "sparse",
            "x": 11.821920394897461,
            "y": 3.565530776977539
        },
        {
            "id": "s_281",
            "name": "Jie Gao 0001",
            "type": "sparse",
            "x": 9.550971984863281,
            "y": 6.565341472625732
        },
        {
            "id": "s_282",
            "name": "Jorge Estrada",
            "type": "sparse",
            "x": 12.262203216552734,
            "y": 3.419975996017456
        },
        {
            "id": "s_283",
            "name": "Ludovic Autin",
            "type": "sparse",
            "x": 11.958756446838379,
            "y": 3.525447130203247
        },
        {
            "id": "s_284",
            "name": "Christophe Lenglet",
            "type": "sparse",
            "x": 11.250597953796387,
            "y": 4.320864677429199
        },
        {
            "id": "s_285",
            "name": "Xianfeng David Gu",
            "type": "sparse",
            "x": 9.550971984863281,
            "y": 6.565341472625732
        },
        {
            "id": "s_286",
            "name": "Yubo Zhang 0001",
            "type": "sparse",
            "x": 9.972555160522461,
            "y": 4.135494709014893
        },
        {
            "id": "s_287",
            "name": "Mai Elshehaly",
            "type": "sparse",
            "x": 10.08668327331543,
            "y": 5.142521381378174
        },
        {
            "id": "s_288",
            "name": "Yunhai Wang",
            "type": "sparse",
            "x": 11.216442108154297,
            "y": 5.968529224395752
        },
        {
            "id": "s_289",
            "name": "Ngan V. T. Nguyen",
            "type": "sparse",
            "x": 11.946690559387207,
            "y": 3.6632518768310547
        },
        {
            "id": "s_290",
            "name": "Rocco Gasteiger",
            "type": "sparse",
            "x": 7.496922969818115,
            "y": 4.437117576599121
        },
        {
            "id": "s_291",
            "name": "Michael J. Henry",
            "type": "sparse",
            "x": 11.165047645568848,
            "y": 6.473668575286865
        },
        {
            "id": "s_292",
            "name": "Haipeng Zeng",
            "type": "sparse",
            "x": 12.0700044631958,
            "y": 6.137913227081299
        },
        {
            "id": "s_293",
            "name": "Markus Stommel",
            "type": "sparse",
            "x": 8.714441299438477,
            "y": 5.817866802215576
        },
        {
            "id": "s_294",
            "name": "Ian Gorton",
            "type": "sparse",
            "x": 11.046210289001465,
            "y": 5.584549427032471
        },
        {
            "id": "s_295",
            "name": "Bernd Hamann",
            "type": "sparse",
            "x": 10.293210983276367,
            "y": 5.980459213256836
        },
        {
            "id": "s_296",
            "name": "Victor Guallar",
            "type": "sparse",
            "x": 12.278568267822266,
            "y": 3.462491512298584
        },
        {
            "id": "s_297",
            "name": "Hubert Mara",
            "type": "sparse",
            "x": 9.946340560913086,
            "y": 7.179619312286377
        },
        {
            "id": "s_298",
            "name": "Torin McDonald",
            "type": "sparse",
            "x": 11.308235168457031,
            "y": 3.2098724842071533
        },
        {
            "id": "s_299",
            "name": "James P. Ahrens",
            "type": "sparse",
            "x": 11.093544006347656,
            "y": 5.480466842651367
        },
        {
            "id": "s_300",
            "name": "Markus Hadwiger",
            "type": "sparse",
            "x": 9.916354179382324,
            "y": 5.358111381530762
        },
        {
            "id": "s_301",
            "name": "Emily Delahaye",
            "type": "sparse",
            "x": 11.72203254699707,
            "y": 5.292431354522705
        },
        {
            "id": "s_302",
            "name": "Jakob Jakob",
            "type": "sparse",
            "x": 8.901309967041016,
            "y": 5.460984230041504
        },
        {
            "id": "s_303",
            "name": "Andrew H. Stevens",
            "type": "sparse",
            "x": 9.341904640197754,
            "y": 3.1572177410125732
        },
        {
            "id": "s_304",
            "name": "Cheng Li",
            "type": "sparse",
            "x": 9.446934700012207,
            "y": 3.0258796215057373
        },
        {
            "id": "s_305",
            "name": "Pascal Nardini",
            "type": "sparse",
            "x": 11.792166709899902,
            "y": 5.156982421875
        },
        {
            "id": "s_306",
            "name": "Jan Mican",
            "type": "sparse",
            "x": 12.367596626281738,
            "y": 3.4548985958099365
        },
        {
            "id": "s_307",
            "name": "Annelot Kraima",
            "type": "sparse",
            "x": 7.703056812286377,
            "y": 3.7510366439819336
        },
        {
            "id": "s_308",
            "name": "Chris Bryan",
            "type": "sparse",
            "x": 11.57893180847168,
            "y": 3.877211570739746
        },
        {
            "id": "s_309",
            "name": "Chris R. Johnson 0001",
            "type": "sparse",
            "x": 10.450019836425781,
            "y": 6.657844543457031
        },
        {
            "id": "s_310",
            "name": "Arin M. Ellingson",
            "type": "sparse",
            "x": 10.363268852233887,
            "y": 3.31115984916687
        },
        {
            "id": "s_311",
            "name": "Eugene Zhang",
            "type": "sparse",
            "x": 8.406547546386719,
            "y": 6.149629592895508
        },
        {
            "id": "s_312",
            "name": "Timothy Luciani",
            "type": "sparse",
            "x": 9.694225311279297,
            "y": 4.318378925323486
        },
        {
            "id": "s_313",
            "name": "Yunhao Xing",
            "type": "sparse",
            "x": 9.51290512084961,
            "y": 5.84752082824707
        },
        {
            "id": "s_314",
            "name": "Martin Imre",
            "type": "sparse",
            "x": 10.165812492370605,
            "y": 6.638605117797852
        },
        {
            "id": "s_315",
            "name": "Luis Gustavo Nonato",
            "type": "sparse",
            "x": 8.91818904876709,
            "y": 6.1832661628723145
        },
        {
            "id": "s_316",
            "name": "Baher Elgohari",
            "type": "sparse",
            "x": 7.7534637451171875,
            "y": 3.6913716793060303
        },
        {
            "id": "s_317",
            "name": "Lauren Thorson",
            "type": "sparse",
            "x": 10.363268852233887,
            "y": 3.31115984916687
        },
        {
            "id": "s_318",
            "name": "Han-Wei Shen",
            "type": "sparse",
            "x": 10.106372833251953,
            "y": 6.147345066070557
        },
        {
            "id": "s_319",
            "name": "Steffen Lemke 0002",
            "type": "sparse",
            "x": 11.682938575744629,
            "y": 3.604092597961426
        },
        {
            "id": "s_320",
            "name": "Ko-Chih Wang",
            "type": "sparse",
            "x": 11.178451538085938,
            "y": 6.172502517700195
        },
        {
            "id": "s_321",
            "name": "Katrin Scharnowski",
            "type": "sparse",
            "x": 12.338919639587402,
            "y": 3.4439263343811035
        },
        {
            "id": "s_322",
            "name": "Carson Brownlee",
            "type": "sparse",
            "x": 11.234898567199707,
            "y": 4.302945137023926
        },
        {
            "id": "s_323",
            "name": "Marian Talbert",
            "type": "sparse",
            "x": 10.784971237182617,
            "y": 6.350415229797363
        },
        {
            "id": "s_324",
            "name": "Konstantinos Efstathiou 0001",
            "type": "sparse",
            "x": 11.454092025756836,
            "y": 5.5959696769714355
        },
        {
            "id": "s_325",
            "name": "Benjamin K\u00f6hler 0001",
            "type": "sparse",
            "x": 7.481903553009033,
            "y": 4.430104732513428
        },
        {
            "id": "s_326",
            "name": "Charles Rozhon",
            "type": "sparse",
            "x": 10.944116592407227,
            "y": 4.288697719573975
        },
        {
            "id": "s_327",
            "name": "Pierre J. Magistretti",
            "type": "sparse",
            "x": 11.295099258422852,
            "y": 3.2402255535125732
        },
        {
            "id": "s_328",
            "name": "Jochen Fr\u00f6hlich",
            "type": "sparse",
            "x": 8.470778465270996,
            "y": 5.261552333831787
        },
        {
            "id": "s_329",
            "name": "Peter Hanula",
            "type": "sparse",
            "x": 7.7534637451171875,
            "y": 3.6913716793060303
        },
        {
            "id": "s_330",
            "name": "Feng Luo 0002",
            "type": "sparse",
            "x": 9.550971984863281,
            "y": 6.565341472625732
        },
        {
            "id": "s_331",
            "name": "Carolyn L. Phillips",
            "type": "sparse",
            "x": 7.550332546234131,
            "y": 5.180576801300049
        },
        {
            "id": "s_332",
            "name": "Kenneth I. Joy",
            "type": "sparse",
            "x": 10.09239387512207,
            "y": 6.063436508178711
        },
        {
            "id": "s_333",
            "name": "Colin Ware",
            "type": "sparse",
            "x": 10.106314659118652,
            "y": 3.842402696609497
        },
        {
            "id": "s_334",
            "name": "Raffaele De Simone",
            "type": "sparse",
            "x": 7.476317882537842,
            "y": 4.20993709564209
        },
        {
            "id": "s_335",
            "name": "Matthias Gutberlet",
            "type": "sparse",
            "x": 7.481903553009033,
            "y": 4.430104732513428
        },
        {
            "id": "s_336",
            "name": "Raphael Fuchs",
            "type": "sparse",
            "x": 8.528419494628906,
            "y": 5.398994445800781
        },
        {
            "id": "s_337",
            "name": "David G. C. Hildebrand",
            "type": "sparse",
            "x": 11.268532752990723,
            "y": 4.6747145652771
        },
        {
            "id": "s_338",
            "name": "Helwig Hauser",
            "type": "sparse",
            "x": 11.046195030212402,
            "y": 5.589327812194824
        },
        {
            "id": "s_339",
            "name": "Hai Ah Nam",
            "type": "sparse",
            "x": 9.687100410461426,
            "y": 5.438337326049805
        },
        {
            "id": "s_340",
            "name": "Stefan Jordan",
            "type": "sparse",
            "x": 9.234081268310547,
            "y": 4.9493818283081055
        },
        {
            "id": "s_341",
            "name": "Ross T. Whitaker",
            "type": "sparse",
            "x": 10.927022933959961,
            "y": 6.487303733825684
        },
        {
            "id": "s_342",
            "name": "Jian Sun 0002",
            "type": "sparse",
            "x": 9.550971984863281,
            "y": 6.565341472625732
        },
        {
            "id": "s_343",
            "name": "Alexander S. Szalay",
            "type": "sparse",
            "x": 8.745753288269043,
            "y": 5.485160827636719
        },
        {
            "id": "s_344",
            "name": "Cl\u00e1udio T. Silva",
            "type": "sparse",
            "x": 10.634652137756348,
            "y": 5.57827091217041
        },
        {
            "id": "s_345",
            "name": "Jen-Ping Chen",
            "type": "sparse",
            "x": 9.389508247375488,
            "y": 5.747000217437744
        },
        {
            "id": "s_346",
            "name": "Dominik Engel",
            "type": "sparse",
            "x": 9.60118579864502,
            "y": 5.73504638671875
        },
        {
            "id": "s_347",
            "name": "Daisuke Sakurai",
            "type": "sparse",
            "x": 8.604155540466309,
            "y": 6.688293933868408
        },
        {
            "id": "s_348",
            "name": "Caterina Rosano",
            "type": "sparse",
            "x": 11.083663940429688,
            "y": 5.193977355957031
        },
        {
            "id": "s_349",
            "name": "Hessam Sokooti",
            "type": "sparse",
            "x": 7.703056812286377,
            "y": 3.7510366439819336
        },
        {
            "id": "s_350",
            "name": "Jian Chen 0006",
            "type": "sparse",
            "x": 11.145295143127441,
            "y": 4.204522609710693
        },
        {
            "id": "s_351",
            "name": "Valentin Zobel",
            "type": "sparse",
            "x": 9.011826515197754,
            "y": 5.526360034942627
        },
        {
            "id": "s_352",
            "name": "Won-Ki Jeong",
            "type": "sparse",
            "x": 10.319865226745605,
            "y": 4.958520889282227
        },
        {
            "id": "s_353",
            "name": "Olaf Kolditz",
            "type": "sparse",
            "x": 8.4170560836792,
            "y": 6.109373569488525
        },
        {
            "id": "s_354",
            "name": "Olga Sorkine-Hornung",
            "type": "sparse",
            "x": 9.439054489135742,
            "y": 6.879550457000732
        },
        {
            "id": "s_355",
            "name": "Bing Ni",
            "type": "sparse",
            "x": 12.0700044631958,
            "y": 6.137913227081299
        },
        {
            "id": "s_356",
            "name": "Brian Summa",
            "type": "sparse",
            "x": 10.390862464904785,
            "y": 6.514474868774414
        },
        {
            "id": "s_357",
            "name": "Harinarayan Krishnan",
            "type": "sparse",
            "x": 11.046210289001465,
            "y": 5.584549427032471
        },
        {
            "id": "s_358",
            "name": "Ivan Koles\u00e1r",
            "type": "sparse",
            "x": 11.012639999389648,
            "y": 6.638277530670166
        },
        {
            "id": "s_359",
            "name": "Simon J. Walton",
            "type": "sparse",
            "x": 11.72203254699707,
            "y": 5.292431354522705
        },
        {
            "id": "s_360",
            "name": "Ivan Barisic",
            "type": "sparse",
            "x": 11.893961906433105,
            "y": 3.4554388523101807
        },
        {
            "id": "s_361",
            "name": "Keith Bein",
            "type": "sparse",
            "x": 10.316225051879883,
            "y": 6.546288967132568
        },
        {
            "id": "s_362",
            "name": "Scott Houde",
            "type": "sparse",
            "x": 10.537936210632324,
            "y": 4.459981918334961
        },
        {
            "id": "s_363",
            "name": "David H. Laidlaw",
            "type": "sparse",
            "x": 10.720473289489746,
            "y": 4.193509578704834
        },
        {
            "id": "s_364",
            "name": "Jian Huang 0007",
            "type": "sparse",
            "x": 10.098419189453125,
            "y": 7.183274269104004
        },
        {
            "id": "s_365",
            "name": "Hans Hagen",
            "type": "sparse",
            "x": 10.286111831665039,
            "y": 5.791228294372559
        },
        {
            "id": "s_366",
            "name": "Matej Mlejnek",
            "type": "sparse",
            "x": 8.124481201171875,
            "y": 5.556093692779541
        },
        {
            "id": "s_367",
            "name": "Hyungsuk Choi",
            "type": "sparse",
            "x": 11.268532752990723,
            "y": 4.6747145652771
        },
        {
            "id": "s_368",
            "name": "Kenneth Weiss 0001",
            "type": "sparse",
            "x": 9.295135498046875,
            "y": 7.081155776977539
        },
        {
            "id": "s_369",
            "name": "Thomas H\u00f6llt",
            "type": "sparse",
            "x": 10.297612190246582,
            "y": 5.513439655303955
        },
        {
            "id": "s_370",
            "name": "Wieland Reich",
            "type": "sparse",
            "x": 7.695365905761719,
            "y": 5.900307655334473
        },
        {
            "id": "s_371",
            "name": "Denis M. Larkin",
            "type": "sparse",
            "x": 11.57893180847168,
            "y": 3.877211570739746
        },
        {
            "id": "s_372",
            "name": "Anna Vilanova",
            "type": "sparse",
            "x": 7.811160087585449,
            "y": 4.6717424392700195
        },
        {
            "id": "s_373",
            "name": "Omniah H. Nagoor",
            "type": "sparse",
            "x": 9.242120742797852,
            "y": 6.360678672790527
        },
        {
            "id": "s_374",
            "name": "John Patchett",
            "type": "sparse",
            "x": 10.49360179901123,
            "y": 5.669396877288818
        },
        {
            "id": "s_375",
            "name": "Bret Jackson",
            "type": "sparse",
            "x": 9.859582901000977,
            "y": 4.024712085723877
        },
        {
            "id": "s_376",
            "name": "Pavol Ulbrich",
            "type": "sparse",
            "x": 12.367596626281738,
            "y": 3.4548985958099365
        },
        {
            "id": "s_377",
            "name": "Lorna Role",
            "type": "sparse",
            "x": 11.093092918395996,
            "y": 3.3198275566101074
        },
        {
            "id": "s_378",
            "name": "Jiayi Xu 0001",
            "type": "sparse",
            "x": 12.0700044631958,
            "y": 6.137913227081299
        },
        {
            "id": "s_379",
            "name": "Stefan Barp",
            "type": "sparse",
            "x": 8.528419494628906,
            "y": 5.398994445800781
        },
        {
            "id": "s_380",
            "name": "Elizabeth Munch",
            "type": "sparse",
            "x": 10.1434907913208,
            "y": 7.183420181274414
        },
        {
            "id": "s_381",
            "name": "Zhengyu Su",
            "type": "sparse",
            "x": 9.550971984863281,
            "y": 6.565341472625732
        },
        {
            "id": "s_382",
            "name": "Tracy Compton",
            "type": "sparse",
            "x": 10.270195960998535,
            "y": 5.414629936218262
        },
        {
            "id": "s_383",
            "name": "Clifton D. Fuller",
            "type": "sparse",
            "x": 7.7534637451171875,
            "y": 3.6913716793060303
        },
        {
            "id": "s_384",
            "name": "Haipeng Cai",
            "type": "sparse",
            "x": 9.786408424377441,
            "y": 3.1464149951934814
        },
        {
            "id": "s_385",
            "name": "Dilip Mathew Thomas",
            "type": "sparse",
            "x": 8.983175277709961,
            "y": 6.546221733093262
        },
        {
            "id": "s_386",
            "name": "Chufan Lai",
            "type": "sparse",
            "x": 7.633826732635498,
            "y": 4.75159215927124
        },
        {
            "id": "s_387",
            "name": "Lingyun Yu 0001",
            "type": "sparse",
            "x": 11.454092025756836,
            "y": 5.5959696769714355
        },
        {
            "id": "s_388",
            "name": "Mukund Raj",
            "type": "sparse",
            "x": 11.178451538085938,
            "y": 6.172502517700195
        },
        {
            "id": "s_389",
            "name": "Stefan Lindholm",
            "type": "sparse",
            "x": 8.765989303588867,
            "y": 5.35978889465332
        },
        {
            "id": "s_390",
            "name": "Daniel Haehn",
            "type": "sparse",
            "x": 11.437768936157227,
            "y": 3.2347655296325684
        },
        {
            "id": "s_391",
            "name": "Fedor Korsakov",
            "type": "sparse",
            "x": 10.363268852233887,
            "y": 3.31115984916687
        },
        {
            "id": "s_392",
            "name": "Peer-Timo Bremer",
            "type": "sparse",
            "x": 9.732378005981445,
            "y": 6.36093282699585
        },
        {
            "id": "s_393",
            "name": "Timothy C. Johnson",
            "type": "sparse",
            "x": 11.046210289001465,
            "y": 5.584549427032471
        },
        {
            "id": "s_394",
            "name": "Seymour Knowles-Barley",
            "type": "sparse",
            "x": 11.515854835510254,
            "y": 3.2373809814453125
        },
        {
            "id": "s_395",
            "name": "Ivan Viola",
            "type": "sparse",
            "x": 11.166874885559082,
            "y": 4.062230587005615
        },
        {
            "id": "s_396",
            "name": "Tony Bernardin",
            "type": "sparse",
            "x": 10.270195960998535,
            "y": 5.414629936218262
        },
        {
            "id": "s_397",
            "name": "Hao Zheng 0006",
            "type": "sparse",
            "x": 9.51290512084961,
            "y": 5.84752082824707
        },
        {
            "id": "s_398",
            "name": "Kaoji Xu",
            "type": "sparse",
            "x": 8.736074447631836,
            "y": 6.8847575187683105
        },
        {
            "id": "s_399",
            "name": "Asher Pembroke",
            "type": "sparse",
            "x": 11.090789794921875,
            "y": 6.104916572570801
        },
        {
            "id": "s_400",
            "name": "Jennifer Frazier",
            "type": "sparse",
            "x": 11.563887596130371,
            "y": 4.047283172607422
        },
        {
            "id": "s_401",
            "name": "Kan Dai",
            "type": "sparse",
            "x": 11.216442108154297,
            "y": 5.968529224395752
        },
        {
            "id": "s_402",
            "name": "Tobias Klein",
            "type": "sparse",
            "x": 11.910514831542969,
            "y": 3.556563138961792
        },
        {
            "id": "s_403",
            "name": "Lutz Rastaetter",
            "type": "sparse",
            "x": 11.090789794921875,
            "y": 6.104916572570801
        },
        {
            "id": "s_404",
            "name": "Phil Moore",
            "type": "sparse",
            "x": 11.046210289001465,
            "y": 5.584549427032471
        },
        {
            "id": "s_405",
            "name": "Hank Childs",
            "type": "sparse",
            "x": 11.165047645568848,
            "y": 6.473668575286865
        },
        {
            "id": "s_406",
            "name": "Hans-Peter Seidel",
            "type": "sparse",
            "x": 9.514324188232422,
            "y": 6.778389930725098
        },
        {
            "id": "s_407",
            "name": "Bernhard Fr\u00f6hler",
            "type": "sparse",
            "x": 9.871879577636719,
            "y": 4.899824142456055
        },
        {
            "id": "s_408",
            "name": "Thomas Spengler",
            "type": "sparse",
            "x": 10.867530822753906,
            "y": 6.0701189041137695
        },
        {
            "id": "s_409",
            "name": "Phillip J. Wolfram",
            "type": "sparse",
            "x": 11.250597953796387,
            "y": 4.320864677429199
        },
        {
            "id": "s_410",
            "name": "G. Elisabeta Marai",
            "type": "sparse",
            "x": 10.493793487548828,
            "y": 4.715527057647705
        },
        {
            "id": "s_411",
            "name": "Carsten Dachsbacher",
            "type": "sparse",
            "x": 10.064342498779297,
            "y": 5.666855812072754
        },
        {
            "id": "s_412",
            "name": "Wei Zeng 0002",
            "type": "sparse",
            "x": 8.207507133483887,
            "y": 4.407832145690918
        },
        {
            "id": "s_413",
            "name": "Klaus Greff",
            "type": "sparse",
            "x": 10.316225051879883,
            "y": 6.546288967132568
        },
        {
            "id": "s_414",
            "name": "Osamu Saeki",
            "type": "sparse",
            "x": 8.604155540466309,
            "y": 6.688293933868408
        },
        {
            "id": "s_415",
            "name": "Dane M. Coffey",
            "type": "sparse",
            "x": 11.206650733947754,
            "y": 5.000423908233643
        },
        {
            "id": "s_416",
            "name": "Christian Godenschwager",
            "type": "sparse",
            "x": 7.546726226806641,
            "y": 4.204033851623535
        },
        {
            "id": "s_417",
            "name": "Vitalis Wiens",
            "type": "sparse",
            "x": 8.527817726135254,
            "y": 6.2679829597473145
        },
        {
            "id": "s_418",
            "name": "Tung Yuen Lau",
            "type": "sparse",
            "x": 9.859582901000977,
            "y": 4.024712085723877
        },
        {
            "id": "s_419",
            "name": "Ignacio Ponzoni",
            "type": "sparse",
            "x": 12.367596626281738,
            "y": 3.4548985958099365
        },
        {
            "id": "s_420",
            "name": "Ismail Demir",
            "type": "sparse",
            "x": 10.631356239318848,
            "y": 6.770925998687744
        },
        {
            "id": "s_421",
            "name": "Daniel F. Keefe",
            "type": "sparse",
            "x": 10.771344184875488,
            "y": 4.204452037811279
        },
        {
            "id": "s_422",
            "name": "Xiaotong Liu",
            "type": "sparse",
            "x": 10.0431547164917,
            "y": 6.090481281280518
        },
        {
            "id": "s_423",
            "name": "Franz Sauer",
            "type": "sparse",
            "x": 9.947415351867676,
            "y": 6.188593864440918
        },
        {
            "id": "s_424",
            "name": "Rodolfo Ostilla Monico",
            "type": "sparse",
            "x": 8.281267166137695,
            "y": 5.433887958526611
        },
        {
            "id": "s_425",
            "name": "Andrew J. Solis",
            "type": "sparse",
            "x": 11.250597953796387,
            "y": 4.320864677429199
        },
        {
            "id": "s_426",
            "name": "Fabio Miranda 0001",
            "type": "sparse",
            "x": 12.079547882080078,
            "y": 6.148656845092773
        },
        {
            "id": "s_427",
            "name": "Jens H. Kr\u00fcger",
            "type": "sparse",
            "x": 9.427786827087402,
            "y": 4.188070297241211
        },
        {
            "id": "s_428",
            "name": "Quan Li",
            "type": "sparse",
            "x": 11.183948516845703,
            "y": 6.4268107414245605
        },
        {
            "id": "s_429",
            "name": "Tobias Isenberg 0001",
            "type": "sparse",
            "x": 11.110907554626465,
            "y": 4.571280479431152
        },
        {
            "id": "s_430",
            "name": "Robert Carnecky",
            "type": "sparse",
            "x": 8.528419494628906,
            "y": 5.398994445800781
        },
        {
            "id": "s_431",
            "name": "Stefan Guthe",
            "type": "sparse",
            "x": 10.020633697509766,
            "y": 4.414642810821533
        },
        {
            "id": "s_432",
            "name": "Matthias Bernhard",
            "type": "sparse",
            "x": 10.022345542907715,
            "y": 3.189236640930176
        },
        {
            "id": "s_433",
            "name": "Emil Axelsson",
            "type": "sparse",
            "x": 10.788124084472656,
            "y": 4.619614124298096
        },
        {
            "id": "s_434",
            "name": "Xiaoru Yuan",
            "type": "sparse",
            "x": 9.745073318481445,
            "y": 6.791474342346191
        },
        {
            "id": "s_435",
            "name": "Johannes Roth",
            "type": "sparse",
            "x": 9.232419967651367,
            "y": 5.177774429321289
        },
        {
            "id": "s_436",
            "name": "Holger Steeb",
            "type": "sparse",
            "x": 9.252543449401855,
            "y": 5.240782260894775
        },
        {
            "id": "s_437",
            "name": "Chi-Lun Lin",
            "type": "sparse",
            "x": 11.206650733947754,
            "y": 5.000423908233643
        },
        {
            "id": "s_438",
            "name": "Jan Kretschmer",
            "type": "sparse",
            "x": 7.805346965789795,
            "y": 4.026329040527344
        },
        {
            "id": "s_439",
            "name": "Francis Kilian",
            "type": "sparse",
            "x": 8.000309944152832,
            "y": 3.6600561141967773
        },
        {
            "id": "s_440",
            "name": "MeganOlson Hunt",
            "type": "sparse",
            "x": 11.083663940429688,
            "y": 5.193977355957031
        },
        {
            "id": "s_441",
            "name": "Harris A. Lewin",
            "type": "sparse",
            "x": 11.57893180847168,
            "y": 3.877211570739746
        },
        {
            "id": "s_442",
            "name": "Michael S\u00fchling",
            "type": "sparse",
            "x": 8.06396770477295,
            "y": 3.848623752593994
        },
        {
            "id": "s_443",
            "name": "Tobias G\u00fcnther",
            "type": "sparse",
            "x": 8.314108848571777,
            "y": 5.220251560211182
        },
        {
            "id": "s_444",
            "name": "Robin Sk\u00e5nberg",
            "type": "sparse",
            "x": 12.29493236541748,
            "y": 3.505007028579712
        },
        {
            "id": "s_445",
            "name": "Hamish A. Carr",
            "type": "sparse",
            "x": 9.004667282104492,
            "y": 6.274352073669434
        },
        {
            "id": "s_446",
            "name": "Wei-Hsien Hsu",
            "type": "sparse",
            "x": 10.373123168945312,
            "y": 4.033430576324463
        },
        {
            "id": "s_447",
            "name": "Xin Tong",
            "type": "sparse",
            "x": 9.446934700012207,
            "y": 3.0258796215057373
        },
        {
            "id": "s_448",
            "name": "Barbora Kozl\u00edkov\u00e1",
            "type": "sparse",
            "x": 11.727574348449707,
            "y": 3.8668019771575928
        },
        {
            "id": "s_449",
            "name": "Juraj P\u00e1lenik",
            "type": "sparse",
            "x": 10.645088195800781,
            "y": 6.246827125549316
        },
        {
            "id": "s_450",
            "name": "Hsiang-Yun Wu",
            "type": "sparse",
            "x": 9.256454467773438,
            "y": 6.607105255126953
        },
        {
            "id": "s_451",
            "name": "Andreas Gerndt",
            "type": "sparse",
            "x": 10.270195960998535,
            "y": 5.414629936218262
        },
        {
            "id": "s_452",
            "name": "Pepe Eulzer",
            "type": "sparse",
            "x": 7.738313674926758,
            "y": 3.9349966049194336
        },
        {
            "id": "s_453",
            "name": "Robert M. Kirby",
            "type": "sparse",
            "x": 10.128119468688965,
            "y": 6.088879585266113
        },
        {
            "id": "s_454",
            "name": "David S. Goodsell",
            "type": "sparse",
            "x": 11.275421142578125,
            "y": 4.525603771209717
        },
        {
            "id": "s_455",
            "name": "Andreas Reh",
            "type": "sparse",
            "x": 9.392159461975098,
            "y": 5.024239540100098
        },
        {
            "id": "s_456",
            "name": "Robert L. Jacob",
            "type": "sparse",
            "x": 11.722888946533203,
            "y": 6.014060020446777
        },
        {
            "id": "s_457",
            "name": "Alexander Bock 0002",
            "type": "sparse",
            "x": 10.225774765014648,
            "y": 4.852627277374268
        },
        {
            "id": "s_458",
            "name": "Anders Persson",
            "type": "sparse",
            "x": 7.587300777435303,
            "y": 4.17347526550293
        },
        {
            "id": "s_459",
            "name": "Dmitry A. Karpeyev",
            "type": "sparse",
            "x": 7.550332546234131,
            "y": 5.180576801300049
        },
        {
            "id": "s_460",
            "name": "Junhai Yong",
            "type": "sparse",
            "x": 11.183948516845703,
            "y": 6.4268107414245605
        },
        {
            "id": "s_461",
            "name": "Mike Roberts 0001",
            "type": "sparse",
            "x": 11.515854835510254,
            "y": 3.2373809814453125
        },
        {
            "id": "s_462",
            "name": "Benjamin Schindler",
            "type": "sparse",
            "x": 8.528419494628906,
            "y": 5.398994445800781
        },
        {
            "id": "s_463",
            "name": "Richard Strelitz",
            "type": "sparse",
            "x": 11.046210289001465,
            "y": 5.584549427032471
        },
        {
            "id": "s_464",
            "name": "Krishna Chaitanya Gurijala",
            "type": "sparse",
            "x": 8.919036865234375,
            "y": 4.981479644775391
        },
        {
            "id": "s_465",
            "name": "Robert Boudreau",
            "type": "sparse",
            "x": 11.083663940429688,
            "y": 5.193977355957031
        },
        {
            "id": "s_466",
            "name": "Steve Petruzza",
            "type": "sparse",
            "x": 10.233503341674805,
            "y": 4.205379009246826
        },
        {
            "id": "s_467",
            "name": "Johannes G\u00fcnther 0001",
            "type": "sparse",
            "x": 11.234898567199707,
            "y": 4.302945137023926
        },
        {
            "id": "s_468",
            "name": "Eugen Zizer",
            "type": "sparse",
            "x": 7.923369407653809,
            "y": 3.8280584812164307
        },
        {
            "id": "s_469",
            "name": "Amin Abbasloo",
            "type": "sparse",
            "x": 8.527817726135254,
            "y": 6.2679829597473145
        },
        {
            "id": "s_470",
            "name": "Marc Treib",
            "type": "sparse",
            "x": 8.745753288269043,
            "y": 5.485160827636719
        },
        {
            "id": "s_471",
            "name": "Hans-Rainer Trebin",
            "type": "sparse",
            "x": 9.232419967651367,
            "y": 5.177774429321289
        },
        {
            "id": "s_472",
            "name": "Nico Korn",
            "type": "sparse",
            "x": 11.016633987426758,
            "y": 7.623682022094727
        },
        {
            "id": "s_473",
            "name": "Florian Ferstl",
            "type": "sparse",
            "x": 9.157384872436523,
            "y": 5.982255935668945
        },
        {
            "id": "s_474",
            "name": "M. Eduard Gr\u00f6ller",
            "type": "sparse",
            "x": 10.742147445678711,
            "y": 4.604201793670654
        },
        {
            "id": "s_475",
            "name": "Danny Z. Chen",
            "type": "sparse",
            "x": 9.51290512084961,
            "y": 5.84752082824707
        },
        {
            "id": "s_476",
            "name": "Vivian Trakinski",
            "type": "sparse",
            "x": 10.920976638793945,
            "y": 4.580874919891357
        },
        {
            "id": "s_477",
            "name": "Johannes Sorger",
            "type": "sparse",
            "x": 11.648948669433594,
            "y": 3.7349281311035156
        },
        {
            "id": "s_478",
            "name": "Wei Chen 0001",
            "type": "sparse",
            "x": 11.216442108154297,
            "y": 5.968529224395752
        },
        {
            "id": "s_479",
            "name": "Hui Zhang 0027",
            "type": "sparse",
            "x": 9.252543449401855,
            "y": 5.240782260894775
        },
        {
            "id": "s_480",
            "name": "Mark C. Price",
            "type": "sparse",
            "x": 9.74095344543457,
            "y": 3.124317169189453
        },
        {
            "id": "s_481",
            "name": "Michael Michaux",
            "type": "sparse",
            "x": 9.504298210144043,
            "y": 7.175880432128906
        },
        {
            "id": "s_482",
            "name": "Noura Faraj",
            "type": "sparse",
            "x": 10.331377029418945,
            "y": 6.91035270690918
        },
        {
            "id": "s_483",
            "name": "Anthony S. Wexler",
            "type": "sparse",
            "x": 10.316225051879883,
            "y": 6.546288967132568
        },
        {
            "id": "s_484",
            "name": "Steffen Oeltze-Jafra",
            "type": "sparse",
            "x": 7.416557312011719,
            "y": 4.407098770141602
        },
        {
            "id": "s_485",
            "name": "Chaoli Wang 0001",
            "type": "sparse",
            "x": 10.230520248413086,
            "y": 6.104011535644531
        },
        {
            "id": "s_486",
            "name": "Alessandra Angelucci",
            "type": "sparse",
            "x": 11.264293670654297,
            "y": 3.2105932235717773
        },
        {
            "id": "s_487",
            "name": "Arthur G. Erdman",
            "type": "sparse",
            "x": 11.206650733947754,
            "y": 5.000423908233643
        },
        {
            "id": "s_488",
            "name": "Lars Hufnagel",
            "type": "sparse",
            "x": 11.682938575744629,
            "y": 3.604092597961426
        },
        {
            "id": "s_489",
            "name": "Ashok Jallepalli",
            "type": "sparse",
            "x": 9.465370178222656,
            "y": 6.120255470275879
        },
        {
            "id": "s_490",
            "name": "Seung Hyun Kim",
            "type": "sparse",
            "x": 10.944351196289062,
            "y": 6.3263325691223145
        },
        {
            "id": "s_491",
            "name": "Peter Wonka",
            "type": "sparse",
            "x": 11.946690559387207,
            "y": 3.6632518768310547
        },
        {
            "id": "s_492",
            "name": "Sandy Engelhardt",
            "type": "sparse",
            "x": 7.476317882537842,
            "y": 4.20993709564209
        },
        {
            "id": "s_493",
            "name": "Michael B\u00f6ttinger",
            "type": "sparse",
            "x": 11.792166709899902,
            "y": 5.156982421875
        },
        {
            "id": "s_494",
            "name": "Sheila Bonde",
            "type": "sparse",
            "x": 10.537936210632324,
            "y": 4.459981918334961
        },
        {
            "id": "s_495",
            "name": "J\u00fcrgen Pleiss",
            "type": "sparse",
            "x": 12.338919639587402,
            "y": 3.4439263343811035
        },
        {
            "id": "s_496",
            "name": "Susan S. Hubbard",
            "type": "sparse",
            "x": 11.046210289001465,
            "y": 5.584549427032471
        },
        {
            "id": "s_497",
            "name": "Jules Vidal",
            "type": "sparse",
            "x": 9.152933120727539,
            "y": 7.513338088989258
        },
        {
            "id": "s_498",
            "name": "Gregory Guterman",
            "type": "sparse",
            "x": 11.57893180847168,
            "y": 3.877211570739746
        },
        {
            "id": "s_499",
            "name": "Yingcai Wu",
            "type": "sparse",
            "x": 11.216442108154297,
            "y": 5.968529224395752
        },
        {
            "id": "s_500",
            "name": "Christian Heine 0002",
            "type": "sparse",
            "x": 10.135826110839844,
            "y": 7.112730503082275
        },
        {
            "id": "s_501",
            "name": "Gene Payne",
            "type": "sparse",
            "x": 10.920976638793945,
            "y": 4.580874919891357
        },
        {
            "id": "s_502",
            "name": "Sergej Stoppel",
            "type": "sparse",
            "x": 10.302505493164062,
            "y": 4.241821765899658
        },
        {
            "id": "s_503",
            "name": "Haejin Jeong",
            "type": "sparse",
            "x": 9.643988609313965,
            "y": 5.752618312835693
        },
        {
            "id": "s_504",
            "name": "Shih-Hsuan Hung",
            "type": "sparse",
            "x": 8.546778678894043,
            "y": 6.32175350189209
        },
        {
            "id": "s_505",
            "name": "Robert S. Laramee",
            "type": "sparse",
            "x": 8.376813888549805,
            "y": 5.840472221374512
        },
        {
            "id": "s_506",
            "name": "Mehdi Ammi",
            "type": "sparse",
            "x": 11.156147956848145,
            "y": 4.571768760681152
        },
        {
            "id": "s_507",
            "name": "Nitesh V. Chawla",
            "type": "sparse",
            "x": 10.165812492370605,
            "y": 6.638605117797852
        },
        {
            "id": "s_508",
            "name": "Hesham Elhalawani",
            "type": "sparse",
            "x": 7.7534637451171875,
            "y": 3.6913716793060303
        },
        {
            "id": "s_509",
            "name": "Gabor Heinemann",
            "type": "sparse",
            "x": 10.297612190246582,
            "y": 5.513439655303955
        },
        {
            "id": "s_510",
            "name": "Andre Schmei\u00dfer",
            "type": "sparse",
            "x": 10.49360179901123,
            "y": 5.669396877288818
        },
        {
            "id": "s_511",
            "name": "Patric Ljung",
            "type": "sparse",
            "x": 10.655271530151367,
            "y": 4.658353328704834
        },
        {
            "id": "s_512",
            "name": "Hui Zhang 0051",
            "type": "sparse",
            "x": 11.216442108154297,
            "y": 5.968529224395752
        },
        {
            "id": "s_513",
            "name": "John A. Peterson",
            "type": "sparse",
            "x": 10.06442642211914,
            "y": 5.5345988273620605
        },
        {
            "id": "s_514",
            "name": "David M. Vock",
            "type": "sparse",
            "x": 7.7534637451171875,
            "y": 3.6913716793060303
        },
        {
            "id": "s_515",
            "name": "Marc Stamminger",
            "type": "sparse",
            "x": 7.805346965789795,
            "y": 4.026329040527344
        },
        {
            "id": "s_516",
            "name": "Sebastian Cmentowski",
            "type": "sparse",
            "x": 9.98121452331543,
            "y": 3.217468738555908
        },
        {
            "id": "s_517",
            "name": "Enya Shen",
            "type": "sparse",
            "x": 7.633826732635498,
            "y": 4.75159215927124
        },
        {
            "id": "s_518",
            "name": "Wei Zeng 0004",
            "type": "sparse",
            "x": 11.716527938842773,
            "y": 5.914069175720215
        },
        {
            "id": "s_519",
            "name": "Reiner Lenz",
            "type": "sparse",
            "x": 7.587300777435303,
            "y": 4.17347526550293
        },
        {
            "id": "s_520",
            "name": "Stefan R\u00fcdis\u00fchli",
            "type": "sparse",
            "x": 10.54450511932373,
            "y": 5.727587699890137
        },
        {
            "id": "s_521",
            "name": "Soumya Dutta",
            "type": "sparse",
            "x": 9.705121994018555,
            "y": 6.092006206512451
        },
        {
            "id": "s_522",
            "name": "Felix Raith",
            "type": "sparse",
            "x": 8.4170560836792,
            "y": 6.109373569488525
        },
        {
            "id": "s_523",
            "name": "Tran Minh Quan",
            "type": "sparse",
            "x": 10.456260681152344,
            "y": 5.2136664390563965
        },
        {
            "id": "s_524",
            "name": "Stephan Wenger",
            "type": "sparse",
            "x": 10.020633697509766,
            "y": 4.414642810821533
        },
        {
            "id": "s_525",
            "name": "Jeff Yarch",
            "type": "sparse",
            "x": 11.220353126525879,
            "y": 3.2113137245178223
        },
        {
            "id": "s_526",
            "name": "Glenn Taylor",
            "type": "sparse",
            "x": 11.046210289001465,
            "y": 5.584549427032471
        },
        {
            "id": "s_527",
            "name": "Sebastian Grottel",
            "type": "sparse",
            "x": 9.232419967651367,
            "y": 5.177774429321289
        },
        {
            "id": "s_528",
            "name": "Jim Jeffers",
            "type": "sparse",
            "x": 11.234898567199707,
            "y": 4.302945137023926
        },
        {
            "id": "s_529",
            "name": "Chun-Ming Chen",
            "type": "sparse",
            "x": 8.698307037353516,
            "y": 5.128701210021973
        },
        {
            "id": "s_530",
            "name": "Reinhard Klein",
            "type": "sparse",
            "x": 8.51894760131836,
            "y": 4.0471110343933105
        },
        {
            "id": "s_531",
            "name": "Yasaman Ahmadi",
            "type": "sparse",
            "x": 11.893961906433105,
            "y": 3.4554388523101807
        },
        {
            "id": "s_532",
            "name": "Magnus Borga",
            "type": "sparse",
            "x": 7.587300777435303,
            "y": 4.17347526550293
        },
        {
            "id": "s_533",
            "name": "Marcel Hlawatsch",
            "type": "sparse",
            "x": 10.081083297729492,
            "y": 3.169290065765381
        },
        {
            "id": "s_534",
            "name": "Duong Hoang",
            "type": "sparse",
            "x": 9.292150497436523,
            "y": 8.041324615478516
        },
        {
            "id": "s_535",
            "name": "David Talmage",
            "type": "sparse",
            "x": 11.093092918395996,
            "y": 3.3198275566101074
        },
        {
            "id": "s_536",
            "name": "Dirk A. Lorenz",
            "type": "sparse",
            "x": 10.020633697509766,
            "y": 4.414642810821533
        },
        {
            "id": "s_537",
            "name": "James A. Sethian",
            "type": "sparse",
            "x": 9.268465042114258,
            "y": 5.183141231536865
        },
        {
            "id": "s_538",
            "name": "J\u00fcrgen Waser",
            "type": "sparse",
            "x": 9.956404685974121,
            "y": 5.2331438064575195
        },
        {
            "id": "s_539",
            "name": "Antoni Sagrist\u00e0",
            "type": "sparse",
            "x": 9.234081268310547,
            "y": 4.9493818283081055
        },
        {
            "id": "s_540",
            "name": "Wolfgang Freiler",
            "type": "sparse",
            "x": 10.297612190246582,
            "y": 5.513439655303955
        },
        {
            "id": "s_541",
            "name": "William J. Layton",
            "type": "sparse",
            "x": 11.083663940429688,
            "y": 5.193977355957031
        },
        {
            "id": "s_542",
            "name": "Julia Docampo-S\u00e1nchez",
            "type": "sparse",
            "x": 9.869104385375977,
            "y": 5.354486465454102
        },
        {
            "id": "s_543",
            "name": "Ravi S. Nanjundiah",
            "type": "sparse",
            "x": 10.616813659667969,
            "y": 5.81190824508667
        },
        {
            "id": "s_544",
            "name": "Ali K. Al-Awami",
            "type": "sparse",
            "x": 10.574287414550781,
            "y": 5.0247955322265625
        },
        {
            "id": "s_545",
            "name": "Maik Schulze",
            "type": "sparse",
            "x": 7.530010223388672,
            "y": 5.222029209136963
        },
        {
            "id": "s_546",
            "name": "Martin Falk",
            "type": "sparse",
            "x": 10.192166328430176,
            "y": 4.226445198059082
        },
        {
            "id": "s_547",
            "name": "Kim F. Wong",
            "type": "sparse",
            "x": 11.083663940429688,
            "y": 5.193977355957031
        },
        {
            "id": "s_548",
            "name": "Pedro Hermosilla",
            "type": "sparse",
            "x": 12.226906776428223,
            "y": 3.3621227741241455
        },
        {
            "id": "s_549",
            "name": "David Gro\u00df",
            "type": "sparse",
            "x": 9.709979057312012,
            "y": 4.232072353363037
        },
        {
            "id": "s_550",
            "name": "Fritz Gschwantner",
            "type": "sparse",
            "x": 10.297612190246582,
            "y": 5.513439655303955
        },
        {
            "id": "s_551",
            "name": "Kah Chun Lau",
            "type": "sparse",
            "x": 9.303056716918945,
            "y": 5.133116722106934
        },
        {
            "id": "s_552",
            "name": "Johannes Weissenbock",
            "type": "sparse",
            "x": 9.871879577636719,
            "y": 4.899824142456055
        },
        {
            "id": "s_553",
            "name": "Michael Burch",
            "type": "sparse",
            "x": 10.081083297729492,
            "y": 3.169290065765381
        },
        {
            "id": "s_554",
            "name": "Chi-Wing Fu",
            "type": "sparse",
            "x": 11.355864524841309,
            "y": 5.678099632263184
        },
        {
            "id": "s_555",
            "name": "Ralph Wickenh\u00f6fer",
            "type": "sparse",
            "x": 7.429879188537598,
            "y": 4.097731113433838
        },
        {
            "id": "s_556",
            "name": "Woohyuk Choi",
            "type": "sparse",
            "x": 11.268532752990723,
            "y": 4.6747145652771
        },
        {
            "id": "s_557",
            "name": "Johanna Beyer",
            "type": "sparse",
            "x": 10.331462860107422,
            "y": 4.810910224914551
        },
        {
            "id": "s_558",
            "name": "Thomas Schultz 0001",
            "type": "sparse",
            "x": 8.302635192871094,
            "y": 5.603716850280762
        },
        {
            "id": "s_559",
            "name": "G\u00e1bor Janiga",
            "type": "sparse",
            "x": 7.464249610900879,
            "y": 4.425614356994629
        },
        {
            "id": "s_560",
            "name": "Ondrej Strnad",
            "type": "sparse",
            "x": 11.946690559387207,
            "y": 3.6632518768310547
        },
        {
            "id": "s_561",
            "name": "Hanspeter Pfister",
            "type": "sparse",
            "x": 10.43558120727539,
            "y": 4.795777797698975
        },
        {
            "id": "s_562",
            "name": "Markus Gross 0001",
            "type": "sparse",
            "x": 9.1854248046875,
            "y": 5.0731201171875
        },
        {
            "id": "s_563",
            "name": "Roy van Pelt",
            "type": "sparse",
            "x": 7.511942386627197,
            "y": 4.444129943847656
        },
        {
            "id": "s_564",
            "name": "Armin Pobitzer",
            "type": "sparse",
            "x": 8.528419494628906,
            "y": 5.398994445800781
        },
        {
            "id": "s_565",
            "name": "Joyce Ma",
            "type": "sparse",
            "x": 11.563887596130371,
            "y": 4.047283172607422
        },
        {
            "id": "s_566",
            "name": "Grzegorz Soza",
            "type": "sparse",
            "x": 8.06396770477295,
            "y": 3.848623752593994
        },
        {
            "id": "s_567",
            "name": "Pere-Pau V\u00e1zquez",
            "type": "sparse",
            "x": 12.249581336975098,
            "y": 3.4097509384155273
        },
        {
            "id": "s_568",
            "name": "Mondrian Hsieh",
            "type": "sparse",
            "x": 12.079547882080078,
            "y": 6.148656845092773
        },
        {
            "id": "s_569",
            "name": "Jian Ma 0004",
            "type": "sparse",
            "x": 11.57893180847168,
            "y": 3.877211570739746
        },
        {
            "id": "s_570",
            "name": "Thomas Theu\u00dfl",
            "type": "sparse",
            "x": 8.124481201171875,
            "y": 5.556093692779541
        },
        {
            "id": "s_571",
            "name": "Daniela Mayumi Ushizima",
            "type": "sparse",
            "x": 9.268465042114258,
            "y": 5.183141231536865
        },
        {
            "id": "s_572",
            "name": "Julien Tierny",
            "type": "sparse",
            "x": 9.757028579711914,
            "y": 6.6818389892578125
        },
        {
            "id": "s_573",
            "name": "Ulderico Fugacci",
            "type": "sparse",
            "x": 10.213842391967773,
            "y": 7.132859230041504
        },
        {
            "id": "s_574",
            "name": "Graham Johnson",
            "type": "sparse",
            "x": 10.656344413757324,
            "y": 5.270167350769043
        },
        {
            "id": "s_575",
            "name": "Boyan Zheng",
            "type": "sparse",
            "x": 10.810347557067871,
            "y": 7.288801193237305
        },
        {
            "id": "s_576",
            "name": "Will Usher 0001",
            "type": "sparse",
            "x": 10.271965026855469,
            "y": 4.849077224731445
        },
        {
            "id": "s_577",
            "name": "Joshua A. Levine",
            "type": "sparse",
            "x": 9.282660484313965,
            "y": 6.923747539520264
        },
        {
            "id": "s_578",
            "name": "Marco Agus",
            "type": "sparse",
            "x": 9.46834945678711,
            "y": 7.616470813751221
        },
        {
            "id": "s_579",
            "name": "Gokhan Sever",
            "type": "sparse",
            "x": 10.165812492370605,
            "y": 6.638605117797852
        },
        {
            "id": "s_580",
            "name": "Maria Luj\u00e1n Ganuza",
            "type": "sparse",
            "x": 12.367596626281738,
            "y": 3.4548985958099365
        },
        {
            "id": "s_581",
            "name": "Manuela Waldner",
            "type": "sparse",
            "x": 10.022345542907715,
            "y": 3.189236640930176
        },
        {
            "id": "s_582",
            "name": "Larry A. Curtiss",
            "type": "sparse",
            "x": 9.303056716918945,
            "y": 5.133116722106934
        },
        {
            "id": "s_583",
            "name": "Axel J. Soto",
            "type": "sparse",
            "x": 12.367596626281738,
            "y": 3.4548985958099365
        },
        {
            "id": "s_584",
            "name": "Eric S. Cowgill",
            "type": "sparse",
            "x": 10.270195960998535,
            "y": 5.414629936218262
        },
        {
            "id": "s_585",
            "name": "Bernhard Preim",
            "type": "sparse",
            "x": 7.660585880279541,
            "y": 4.13712739944458
        },
        {
            "id": "s_586",
            "name": "Max Hermann",
            "type": "sparse",
            "x": 8.523382186889648,
            "y": 5.1575469970703125
        },
        {
            "id": "s_587",
            "name": "Kevin Bensema",
            "type": "sparse",
            "x": 11.165047645568848,
            "y": 6.473668575286865
        },
        {
            "id": "s_588",
            "name": "Deng Luo",
            "type": "sparse",
            "x": 11.946690559387207,
            "y": 3.6632518768310547
        },
        {
            "id": "s_589",
            "name": "Klaus Hildebrandt",
            "type": "sparse",
            "x": 8.79211139678955,
            "y": 3.6080563068389893
        },
        {
            "id": "s_590",
            "name": "Thomas Nagel",
            "type": "sparse",
            "x": 8.4170560836792,
            "y": 6.109373569488525
        },
        {
            "id": "s_591",
            "name": "Gabriel Mistelbauer",
            "type": "sparse",
            "x": 7.526188373565674,
            "y": 4.2119927406311035
        },
        {
            "id": "s_592",
            "name": "Juliana Freire",
            "type": "sparse",
            "x": 12.044306755065918,
            "y": 6.121316909790039
        },
        {
            "id": "s_593",
            "name": "Christopher P. Kappe",
            "type": "sparse",
            "x": 11.682938575744629,
            "y": 3.604092597961426
        },
        {
            "id": "s_594",
            "name": "Blair Lyons",
            "type": "sparse",
            "x": 11.403936386108398,
            "y": 4.0144171714782715
        },
        {
            "id": "s_595",
            "name": "Marc Rautenhaus",
            "type": "sparse",
            "x": 9.67385196685791,
            "y": 5.644613265991211
        },
        {
            "id": "s_596",
            "name": "Min Shih",
            "type": "sparse",
            "x": 10.944116592407227,
            "y": 4.288697719573975
        },
        {
            "id": "s_597",
            "name": "Jefferson Amstutz",
            "type": "sparse",
            "x": 11.234898567199707,
            "y": 4.302945137023926
        },
        {
            "id": "s_598",
            "name": "Tobias Kulschewski",
            "type": "sparse",
            "x": 12.338919639587402,
            "y": 3.4439263343811035
        },
        {
            "id": "s_599",
            "name": "Charles D. Hansen",
            "type": "sparse",
            "x": 10.501301765441895,
            "y": 5.2964019775390625
        },
        {
            "id": "s_600",
            "name": "Nivan Ferreira",
            "type": "sparse",
            "x": 12.044306755065918,
            "y": 6.121316909790039
        },
        {
            "id": "s_601",
            "name": "Louise H. Kellogg",
            "type": "sparse",
            "x": 10.06442642211914,
            "y": 5.5345988273620605
        },
        {
            "id": "s_602",
            "name": "Sanaz Golbabaei",
            "type": "sparse",
            "x": 8.368074417114258,
            "y": 6.102084636688232
        },
        {
            "id": "s_603",
            "name": "Bruno Gon\u00e7alves",
            "type": "sparse",
            "x": 12.079547882080078,
            "y": 6.148656845092773
        },
        {
            "id": "s_604",
            "name": "Bingchen Liu",
            "type": "sparse",
            "x": 9.631333351135254,
            "y": 5.196542263031006
        },
        {
            "id": "s_605",
            "name": "Thomas Butkiewicz",
            "type": "sparse",
            "x": 9.356302261352539,
            "y": 3.163525342941284
        },
        {
            "id": "s_606",
            "name": "Gregory Heinlein",
            "type": "sparse",
            "x": 8.698307037353516,
            "y": 5.128701210021973
        },
        {
            "id": "s_607",
            "name": "Lars Huettenberger",
            "type": "sparse",
            "x": 10.135826110839844,
            "y": 7.112730503082275
        },
        {
            "id": "s_608",
            "name": "Jonathan Woodring",
            "type": "sparse",
            "x": 10.500347137451172,
            "y": 6.280033111572266
        },
        {
            "id": "s_609",
            "name": "Paul Issartel",
            "type": "sparse",
            "x": 11.156147956848145,
            "y": 4.571768760681152
        },
        {
            "id": "s_610",
            "name": "Changgong Zhang",
            "type": "sparse",
            "x": 8.500031471252441,
            "y": 6.283479690551758
        },
        {
            "id": "s_611",
            "name": "John V. Carlis",
            "type": "sparse",
            "x": 10.363268852233887,
            "y": 3.31115984916687
        },
        {
            "id": "s_612",
            "name": "Juan R. Cebral",
            "type": "sparse",
            "x": 7.416557312011719,
            "y": 4.407098770141602
        },
        {
            "id": "s_613",
            "name": "Fariba Khan",
            "type": "sparse",
            "x": 8.546778678894043,
            "y": 6.32175350189209
        },
        {
            "id": "s_614",
            "name": "David Uribe",
            "type": "sparse",
            "x": 9.252543449401855,
            "y": 5.240782260894775
        },
        {
            "id": "s_615",
            "name": "Cassiano Sugiyama",
            "type": "sparse",
            "x": 11.634987831115723,
            "y": 4.945385932922363
        },
        {
            "id": "s_616",
            "name": "Kai B\u00fcrger",
            "type": "sparse",
            "x": 8.213019371032715,
            "y": 5.696349143981934
        },
        {
            "id": "s_617",
            "name": "Michael E. Papka",
            "type": "sparse",
            "x": 9.712319374084473,
            "y": 5.14445161819458
        },
        {
            "id": "s_618",
            "name": "Joakim Kilby",
            "type": "sparse",
            "x": 10.69024658203125,
            "y": 4.618854522705078
        },
        {
            "id": "s_619",
            "name": "Paul A. Navr\u00e1til",
            "type": "sparse",
            "x": 11.234898567199707,
            "y": 4.302945137023926
        },
        {
            "id": "s_620",
            "name": "Carter Emmart",
            "type": "sparse",
            "x": 10.726186752319336,
            "y": 4.655077934265137
        },
        {
            "id": "s_621",
            "name": "Veronika Solt\u00e9szov\u00e1",
            "type": "sparse",
            "x": 9.74095344543457,
            "y": 3.124317169189453
        },
        {
            "id": "s_622",
            "name": "Corrado Cal\u00ec",
            "type": "sparse",
            "x": 11.295099258422852,
            "y": 3.2402255535125732
        },
        {
            "id": "s_623",
            "name": "Trenton Pulsipher",
            "type": "sparse",
            "x": 11.165047645568848,
            "y": 6.473668575286865
        },
        {
            "id": "s_624",
            "name": "Robin Bader",
            "type": "sparse",
            "x": 10.54450511932373,
            "y": 5.727587699890137
        },
        {
            "id": "s_625",
            "name": "Youssef S. G. Nashed",
            "type": "sparse",
            "x": 11.178451538085938,
            "y": 6.172502517700195
        },
        {
            "id": "s_626",
            "name": "Peter Mindek",
            "type": "sparse",
            "x": 11.721553802490234,
            "y": 3.7654879093170166
        },
        {
            "id": "s_627",
            "name": "David Duran",
            "type": "sparse",
            "x": 12.191610336303711,
            "y": 3.304269552230835
        },
        {
            "id": "s_628",
            "name": "Qiaomu Shen",
            "type": "sparse",
            "x": 12.077192306518555,
            "y": 6.150039196014404
        },
        {
            "id": "s_629",
            "name": "Vijay Natarajan",
            "type": "sparse",
            "x": 9.527721405029297,
            "y": 6.301450729370117
        },
        {
            "id": "s_630",
            "name": "Michael Sprenger",
            "type": "sparse",
            "x": 10.54450511932373,
            "y": 5.727587699890137
        },
        {
            "id": "s_631",
            "name": "Alec Jacobson",
            "type": "sparse",
            "x": 9.439054489135742,
            "y": 6.879550457000732
        },
        {
            "id": "s_632",
            "name": "Ingo Wald",
            "type": "sparse",
            "x": 10.258196830749512,
            "y": 4.736607551574707
        },
        {
            "id": "s_633",
            "name": "Noeska N. Smit",
            "type": "sparse",
            "x": 7.703056812286377,
            "y": 3.7510366439819336
        },
        {
            "id": "s_634",
            "name": "Helmut Doleisch",
            "type": "sparse",
            "x": 10.297612190246582,
            "y": 5.513439655303955
        },
        {
            "id": "s_635",
            "name": "Fan Hong",
            "type": "sparse",
            "x": 8.294970512390137,
            "y": 6.178958892822266
        },
        {
            "id": "s_636",
            "name": "Torsten M\u00f6ller",
            "type": "sparse",
            "x": 11.104812622070312,
            "y": 4.73069429397583
        },
        {
            "id": "s_637",
            "name": "Philipp Beck",
            "type": "sparse",
            "x": 9.232419967651367,
            "y": 5.177774429321289
        },
        {
            "id": "s_638",
            "name": "Samuel Vo\u00df",
            "type": "sparse",
            "x": 7.493898391723633,
            "y": 3.9540703296661377
        },
        {
            "id": "s_639",
            "name": "Mathias Hummel",
            "type": "sparse",
            "x": 11.122188568115234,
            "y": 6.574613094329834
        },
        {
            "id": "s_640",
            "name": "Thomas Auzinger",
            "type": "sparse",
            "x": 7.526188373565674,
            "y": 4.2119927406311035
        },
        {
            "id": "s_641",
            "name": "Filip Sadlo",
            "type": "sparse",
            "x": 9.364371299743652,
            "y": 5.213644027709961
        },
        {
            "id": "s_642",
            "name": "Nils Lichtenberg",
            "type": "sparse",
            "x": 7.476317882537842,
            "y": 4.20993709564209
        },
        {
            "id": "s_643",
            "name": "Fabio Dias 0001",
            "type": "sparse",
            "x": 7.815420627593994,
            "y": 5.328747272491455
        },
        {
            "id": "s_644",
            "name": "Lu Liu 0017",
            "type": "sparse",
            "x": 9.022489547729492,
            "y": 7.699234962463379
        },
        {
            "id": "s_645",
            "name": "Jun Tao 0002",
            "type": "sparse",
            "x": 10.165812492370605,
            "y": 6.638605117797852
        },
        {
            "id": "s_646",
            "name": "Harald Obermaier",
            "type": "sparse",
            "x": 10.09239387512207,
            "y": 6.063436508178711
        },
        {
            "id": "s_647",
            "name": "Kwan-Liu Ma",
            "type": "sparse",
            "x": 10.487311363220215,
            "y": 5.111478805541992
        },
        {
            "id": "s_648",
            "name": "Lin Yan 0003",
            "type": "sparse",
            "x": 10.1434907913208,
            "y": 7.183420181274414
        },
        {
            "id": "s_649",
            "name": "Robert Haimes",
            "type": "sparse",
            "x": 9.862457275390625,
            "y": 5.291882514953613
        },
        {
            "id": "s_650",
            "name": "Eric Liu",
            "type": "sparse",
            "x": 9.855810165405273,
            "y": 5.229278564453125
        },
        {
            "id": "s_651",
            "name": "Jonathas Costa",
            "type": "sparse",
            "x": 10.779613494873047,
            "y": 4.671551704406738
        },
        {
            "id": "s_652",
            "name": "Zhutian Chen",
            "type": "sparse",
            "x": 11.355864524841309,
            "y": 5.678099632263184
        },
        {
            "id": "s_653",
            "name": "Holger Theisel",
            "type": "sparse",
            "x": 7.76863956451416,
            "y": 5.2847208976745605
        },
        {
            "id": "s_654",
            "name": "David J. Nuckley",
            "type": "sparse",
            "x": 10.363268852233887,
            "y": 3.31115984916687
        },
        {
            "id": "s_655",
            "name": "David Schroeder",
            "type": "sparse",
            "x": 10.4664888381958,
            "y": 3.9003241062164307
        },
        {
            "id": "s_656",
            "name": "Andreas J. Lind",
            "type": "sparse",
            "x": 9.930131912231445,
            "y": 3.301217794418335
        },
        {
            "id": "s_657",
            "name": "Kuno Kurzhals",
            "type": "sparse",
            "x": 10.122787475585938,
            "y": 3.2606863975524902
        },
        {
            "id": "s_658",
            "name": "Kai Lawonn",
            "type": "sparse",
            "x": 7.807163715362549,
            "y": 4.21575403213501
        },
        {
            "id": "s_659",
            "name": "Michael Kern",
            "type": "sparse",
            "x": 9.193537712097168,
            "y": 5.438432216644287
        },
        {
            "id": "s_660",
            "name": "Attila Gyulassy",
            "type": "sparse",
            "x": 9.466789245605469,
            "y": 6.015759468078613
        },
        {
            "id": "s_661",
            "name": "Hui Fang 0003",
            "type": "sparse",
            "x": 11.72203254699707,
            "y": 5.292431354522705
        },
        {
            "id": "s_662",
            "name": "Ross Maciejewski",
            "type": "sparse",
            "x": 9.610389709472656,
            "y": 7.1069746017456055
        },
        {
            "id": "s_663",
            "name": "Jens Schneider 0002",
            "type": "sparse",
            "x": 9.463422775268555,
            "y": 7.746247291564941
        },
        {
            "id": "s_664",
            "name": "Gregory D. Abram",
            "type": "sparse",
            "x": 11.250597953796387,
            "y": 4.320864677429199
        },
        {
            "id": "s_665",
            "name": "Aaron Knoll",
            "type": "sparse",
            "x": 10.058449745178223,
            "y": 4.833157062530518
        },
        {
            "id": "s_666",
            "name": "Thomas Hoffmann 0002",
            "type": "sparse",
            "x": 7.339260101318359,
            "y": 4.169096946716309
        },
        {
            "id": "s_667",
            "name": "Jennifer L. Horsman",
            "type": "sparse",
            "x": 11.046210289001465,
            "y": 5.584549427032471
        },
        {
            "id": "s_668",
            "name": "Burkhard W\u00fcnsche",
            "type": "sparse",
            "x": 9.631333351135254,
            "y": 5.196542263031006
        },
        {
            "id": "s_669",
            "name": "Tushar M. Athawale",
            "type": "sparse",
            "x": 10.980676651000977,
            "y": 7.602097988128662
        },
        {
            "id": "s_670",
            "name": "Junyoung Choi",
            "type": "sparse",
            "x": 9.643988609313965,
            "y": 5.752618312835693
        },
        {
            "id": "s_671",
            "name": "Mathieu Le Muzic",
            "type": "sparse",
            "x": 11.033519744873047,
            "y": 3.245971202850342
        },
        {
            "id": "s_672",
            "name": "Mingxuan Yuan",
            "type": "sparse",
            "x": 12.0700044631958,
            "y": 6.137913227081299
        },
        {
            "id": "s_673",
            "name": "Daniel J\u00f6nsson",
            "type": "sparse",
            "x": 10.276692390441895,
            "y": 4.767055034637451
        },
        {
            "id": "s_674",
            "name": "Darren Treanor",
            "type": "sparse",
            "x": 8.00589370727539,
            "y": 3.8334102630615234
        }
    ],
    "links": [
        {
            "source": "r_0",
            "target": "s_255"
        },
        {
            "source": "r_1",
            "target": "s_429"
        },
        {
            "source": "r_1",
            "target": "s_269"
        },
        {
            "source": "r_1",
            "target": "s_350"
        },
        {
            "source": "r_1",
            "target": "s_57"
        },
        {
            "source": "r_1",
            "target": "s_636"
        },
        {
            "source": "r_2",
            "target": "s_341"
        },
        {
            "source": "r_2",
            "target": "s_16"
        },
        {
            "source": "r_2",
            "target": "s_453"
        },
        {
            "source": "r_3",
            "target": "s_572"
        },
        {
            "source": "r_3",
            "target": "s_191"
        },
        {
            "source": "r_3",
            "target": "s_577"
        },
        {
            "source": "r_3",
            "target": "s_10"
        },
        {
            "source": "r_3",
            "target": "s_481"
        },
        {
            "source": "r_4",
            "target": "s_16"
        },
        {
            "source": "r_4",
            "target": "s_341"
        },
        {
            "source": "r_4",
            "target": "s_453"
        },
        {
            "source": "r_5",
            "target": "s_632"
        },
        {
            "source": "r_5",
            "target": "s_243"
        },
        {
            "source": "r_5",
            "target": "s_597"
        },
        {
            "source": "r_5",
            "target": "s_322"
        },
        {
            "source": "r_5",
            "target": "s_665"
        },
        {
            "source": "r_5",
            "target": "s_528"
        },
        {
            "source": "r_5",
            "target": "s_467"
        },
        {
            "source": "r_5",
            "target": "s_619"
        },
        {
            "source": "r_6",
            "target": "s_473"
        },
        {
            "source": "r_6",
            "target": "s_616"
        },
        {
            "source": "r_6",
            "target": "s_102"
        },
        {
            "source": "r_7",
            "target": "s_628"
        },
        {
            "source": "r_7",
            "target": "s_518"
        },
        {
            "source": "r_7",
            "target": "s_83"
        },
        {
            "source": "r_7",
            "target": "s_210"
        },
        {
            "source": "r_7",
            "target": "s_258"
        },
        {
            "source": "r_7",
            "target": "s_260"
        },
        {
            "source": "r_7",
            "target": "s_129"
        },
        {
            "source": "r_8",
            "target": "s_426"
        },
        {
            "source": "r_8",
            "target": "s_27"
        },
        {
            "source": "r_8",
            "target": "s_165"
        },
        {
            "source": "r_8",
            "target": "s_200"
        },
        {
            "source": "r_8",
            "target": "s_603"
        },
        {
            "source": "r_8",
            "target": "s_33"
        },
        {
            "source": "r_8",
            "target": "s_568"
        },
        {
            "source": "r_8",
            "target": "s_344"
        },
        {
            "source": "r_9",
            "target": "s_221"
        },
        {
            "source": "r_9",
            "target": "s_381"
        },
        {
            "source": "r_9",
            "target": "s_285"
        },
        {
            "source": "r_9",
            "target": "s_13"
        },
        {
            "source": "r_9",
            "target": "s_342"
        },
        {
            "source": "r_9",
            "target": "s_281"
        },
        {
            "source": "r_9",
            "target": "s_330"
        },
        {
            "source": "r_10",
            "target": "s_473"
        },
        {
            "source": "r_10",
            "target": "s_93"
        },
        {
            "source": "r_10",
            "target": "s_595"
        },
        {
            "source": "r_10",
            "target": "s_102"
        },
        {
            "source": "r_11",
            "target": "s_223"
        },
        {
            "source": "r_11",
            "target": "s_378"
        },
        {
            "source": "r_11",
            "target": "s_292"
        },
        {
            "source": "r_11",
            "target": "s_227"
        },
        {
            "source": "r_11",
            "target": "s_129"
        },
        {
            "source": "r_11",
            "target": "s_355"
        },
        {
            "source": "r_11",
            "target": "s_672"
        },
        {
            "source": "r_11",
            "target": "s_248"
        },
        {
            "source": "r_12",
            "target": "s_24"
        },
        {
            "source": "r_12",
            "target": "s_271"
        },
        {
            "source": "r_12",
            "target": "s_170"
        },
        {
            "source": "r_12",
            "target": "s_333"
        },
        {
            "source": "r_12",
            "target": "s_69"
        },
        {
            "source": "r_12",
            "target": "s_299"
        },
        {
            "source": "r_13",
            "target": "s_576"
        },
        {
            "source": "r_13",
            "target": "s_72"
        },
        {
            "source": "r_13",
            "target": "s_272"
        },
        {
            "source": "r_13",
            "target": "s_392"
        },
        {
            "source": "r_13",
            "target": "s_665"
        },
        {
            "source": "r_13",
            "target": "s_525"
        },
        {
            "source": "r_13",
            "target": "s_486"
        },
        {
            "source": "r_13",
            "target": "s_273"
        },
        {
            "source": "r_14",
            "target": "s_300"
        },
        {
            "source": "r_14",
            "target": "s_557"
        },
        {
            "source": "r_14",
            "target": "s_352"
        },
        {
            "source": "r_14",
            "target": "s_561"
        },
        {
            "source": "r_15",
            "target": "s_254"
        },
        {
            "source": "r_15",
            "target": "s_178"
        },
        {
            "source": "r_15",
            "target": "s_43"
        },
        {
            "source": "r_15",
            "target": "s_246"
        },
        {
            "source": "r_15",
            "target": "s_572"
        },
        {
            "source": "r_16",
            "target": "s_70"
        },
        {
            "source": "r_16",
            "target": "s_521"
        },
        {
            "source": "r_16",
            "target": "s_318"
        },
        {
            "source": "r_16",
            "target": "s_608"
        },
        {
            "source": "r_17",
            "target": "s_420"
        },
        {
            "source": "r_17",
            "target": "s_23"
        },
        {
            "source": "r_17",
            "target": "s_102"
        },
        {
            "source": "r_18",
            "target": "s_557"
        },
        {
            "source": "r_18",
            "target": "s_544"
        },
        {
            "source": "r_18",
            "target": "s_82"
        },
        {
            "source": "r_18",
            "target": "s_274"
        },
        {
            "source": "r_18",
            "target": "s_561"
        },
        {
            "source": "r_18",
            "target": "s_300"
        },
        {
            "source": "r_19",
            "target": "s_639"
        },
        {
            "source": "r_19",
            "target": "s_646"
        },
        {
            "source": "r_19",
            "target": "s_220"
        },
        {
            "source": "r_19",
            "target": "s_332"
        },
        {
            "source": "r_20",
            "target": "s_657"
        },
        {
            "source": "r_20",
            "target": "s_533"
        },
        {
            "source": "r_20",
            "target": "s_55"
        },
        {
            "source": "r_20",
            "target": "s_553"
        },
        {
            "source": "r_20",
            "target": "s_277"
        },
        {
            "source": "r_20",
            "target": "s_130"
        },
        {
            "source": "r_21",
            "target": "s_325"
        },
        {
            "source": "r_21",
            "target": "s_290"
        },
        {
            "source": "r_21",
            "target": "s_59"
        },
        {
            "source": "r_21",
            "target": "s_653"
        },
        {
            "source": "r_21",
            "target": "s_335"
        },
        {
            "source": "r_21",
            "target": "s_585"
        },
        {
            "source": "r_22",
            "target": "s_375"
        },
        {
            "source": "r_22",
            "target": "s_418"
        },
        {
            "source": "r_22",
            "target": "s_655"
        },
        {
            "source": "r_22",
            "target": "s_80"
        },
        {
            "source": "r_22",
            "target": "s_421"
        },
        {
            "source": "r_23",
            "target": "s_269"
        },
        {
            "source": "r_23",
            "target": "s_429"
        },
        {
            "source": "r_23",
            "target": "s_57"
        },
        {
            "source": "r_23",
            "target": "s_350"
        },
        {
            "source": "r_23",
            "target": "s_636"
        },
        {
            "source": "r_24",
            "target": "s_27"
        },
        {
            "source": "r_24",
            "target": "s_600"
        },
        {
            "source": "r_24",
            "target": "s_104"
        },
        {
            "source": "r_24",
            "target": "s_592"
        },
        {
            "source": "r_24",
            "target": "s_344"
        },
        {
            "source": "r_25",
            "target": "s_669"
        },
        {
            "source": "r_25",
            "target": "s_89"
        },
        {
            "source": "r_25",
            "target": "s_152"
        },
        {
            "source": "r_26",
            "target": "s_608"
        },
        {
            "source": "r_26",
            "target": "s_236"
        },
        {
            "source": "r_26",
            "target": "s_510"
        },
        {
            "source": "r_26",
            "target": "s_374"
        },
        {
            "source": "r_26",
            "target": "s_299"
        },
        {
            "source": "r_26",
            "target": "s_365"
        },
        {
            "source": "r_27",
            "target": "s_415"
        },
        {
            "source": "r_27",
            "target": "s_437"
        },
        {
            "source": "r_27",
            "target": "s_487"
        },
        {
            "source": "r_27",
            "target": "s_421"
        },
        {
            "source": "r_28",
            "target": "s_387"
        },
        {
            "source": "r_28",
            "target": "s_324"
        },
        {
            "source": "r_28",
            "target": "s_269"
        },
        {
            "source": "r_28",
            "target": "s_429"
        },
        {
            "source": "r_29",
            "target": "s_52"
        },
        {
            "source": "r_29",
            "target": "s_609"
        },
        {
            "source": "r_29",
            "target": "s_506"
        },
        {
            "source": "r_29",
            "target": "s_429"
        },
        {
            "source": "r_30",
            "target": "s_521"
        },
        {
            "source": "r_30",
            "target": "s_529"
        },
        {
            "source": "r_30",
            "target": "s_606"
        },
        {
            "source": "r_30",
            "target": "s_318"
        },
        {
            "source": "r_30",
            "target": "s_345"
        },
        {
            "source": "r_31",
            "target": "s_208"
        },
        {
            "source": "r_31",
            "target": "s_472"
        },
        {
            "source": "r_31",
            "target": "s_116"
        },
        {
            "source": "r_32",
            "target": "s_387"
        },
        {
            "source": "r_32",
            "target": "s_324"
        },
        {
            "source": "r_32",
            "target": "s_269"
        },
        {
            "source": "r_32",
            "target": "s_429"
        },
        {
            "source": "r_33",
            "target": "s_136"
        },
        {
            "source": "r_33",
            "target": "s_434"
        },
        {
            "source": "r_33",
            "target": "s_364"
        },
        {
            "source": "r_33",
            "target": "s_228"
        },
        {
            "source": "r_34",
            "target": "s_28"
        },
        {
            "source": "r_34",
            "target": "s_647"
        },
        {
            "source": "r_35",
            "target": "s_47"
        },
        {
            "source": "r_35",
            "target": "s_573"
        },
        {
            "source": "r_35",
            "target": "s_30"
        },
        {
            "source": "r_35",
            "target": "s_35"
        },
        {
            "source": "r_36",
            "target": "s_88"
        },
        {
            "source": "r_36",
            "target": "s_544"
        },
        {
            "source": "r_36",
            "target": "s_557"
        },
        {
            "source": "r_36",
            "target": "s_622"
        },
        {
            "source": "r_36",
            "target": "s_327"
        },
        {
            "source": "r_36",
            "target": "s_561"
        },
        {
            "source": "r_36",
            "target": "s_300"
        },
        {
            "source": "r_37",
            "target": "s_390"
        },
        {
            "source": "r_37",
            "target": "s_394"
        },
        {
            "source": "r_37",
            "target": "s_461"
        },
        {
            "source": "r_37",
            "target": "s_557"
        },
        {
            "source": "r_37",
            "target": "s_82"
        },
        {
            "source": "r_37",
            "target": "s_274"
        },
        {
            "source": "r_37",
            "target": "s_561"
        },
        {
            "source": "r_38",
            "target": "s_660"
        },
        {
            "source": "r_38",
            "target": "s_392"
        },
        {
            "source": "r_38",
            "target": "s_273"
        },
        {
            "source": "r_39",
            "target": "s_669"
        },
        {
            "source": "r_39",
            "target": "s_152"
        },
        {
            "source": "r_40",
            "target": "s_572"
        },
        {
            "source": "r_40",
            "target": "s_273"
        },
        {
            "source": "r_41",
            "target": "s_410"
        },
        {
            "source": "r_42",
            "target": "s_571"
        },
        {
            "source": "r_42",
            "target": "s_161"
        },
        {
            "source": "r_42",
            "target": "s_190"
        },
        {
            "source": "r_42",
            "target": "s_62"
        },
        {
            "source": "r_42",
            "target": "s_537"
        },
        {
            "source": "r_42",
            "target": "s_237"
        },
        {
            "source": "r_43",
            "target": "s_300"
        },
        {
            "source": "r_43",
            "target": "s_544"
        },
        {
            "source": "r_43",
            "target": "s_557"
        },
        {
            "source": "r_43",
            "target": "s_578"
        },
        {
            "source": "r_43",
            "target": "s_561"
        },
        {
            "source": "r_44",
            "target": "s_610"
        },
        {
            "source": "r_44",
            "target": "s_558"
        },
        {
            "source": "r_44",
            "target": "s_658"
        },
        {
            "source": "r_44",
            "target": "s_134"
        },
        {
            "source": "r_44",
            "target": "s_372"
        },
        {
            "source": "r_45",
            "target": "s_422"
        },
        {
            "source": "r_45",
            "target": "s_318"
        },
        {
            "source": "r_46",
            "target": "s_252"
        },
        {
            "source": "r_46",
            "target": "s_318"
        },
        {
            "source": "r_47",
            "target": "s_47"
        },
        {
            "source": "r_47",
            "target": "s_297"
        },
        {
            "source": "r_47",
            "target": "s_35"
        },
        {
            "source": "r_48",
            "target": "s_247"
        },
        {
            "source": "r_48",
            "target": "s_44"
        },
        {
            "source": "r_48",
            "target": "s_136"
        },
        {
            "source": "r_48",
            "target": "s_320"
        },
        {
            "source": "r_48",
            "target": "s_318"
        },
        {
            "source": "r_48",
            "target": "s_388"
        },
        {
            "source": "r_48",
            "target": "s_625"
        },
        {
            "source": "r_48",
            "target": "s_9"
        },
        {
            "source": "r_49",
            "target": "s_402"
        },
        {
            "source": "r_49",
            "target": "s_283"
        },
        {
            "source": "r_49",
            "target": "s_448"
        },
        {
            "source": "r_49",
            "target": "s_454"
        },
        {
            "source": "r_49",
            "target": "s_119"
        },
        {
            "source": "r_49",
            "target": "s_474"
        },
        {
            "source": "r_49",
            "target": "s_395"
        },
        {
            "source": "r_50",
            "target": "s_70"
        },
        {
            "source": "r_50",
            "target": "s_196"
        },
        {
            "source": "r_50",
            "target": "s_422"
        },
        {
            "source": "r_50",
            "target": "s_318"
        },
        {
            "source": "r_51",
            "target": "s_544"
        },
        {
            "source": "r_51",
            "target": "s_557"
        },
        {
            "source": "r_51",
            "target": "s_390"
        },
        {
            "source": "r_51",
            "target": "s_82"
        },
        {
            "source": "r_51",
            "target": "s_274"
        },
        {
            "source": "r_51",
            "target": "s_561"
        },
        {
            "source": "r_51",
            "target": "s_300"
        },
        {
            "source": "r_52",
            "target": "s_521"
        },
        {
            "source": "r_52",
            "target": "s_318"
        },
        {
            "source": "r_53",
            "target": "s_484"
        },
        {
            "source": "r_53",
            "target": "s_612"
        },
        {
            "source": "r_53",
            "target": "s_559"
        },
        {
            "source": "r_53",
            "target": "s_585"
        },
        {
            "source": "r_54",
            "target": "s_443"
        },
        {
            "source": "r_54",
            "target": "s_545"
        },
        {
            "source": "r_54",
            "target": "s_653"
        },
        {
            "source": "r_55",
            "target": "s_660"
        },
        {
            "source": "r_55",
            "target": "s_254"
        },
        {
            "source": "r_55",
            "target": "s_577"
        },
        {
            "source": "r_55",
            "target": "s_572"
        },
        {
            "source": "r_55",
            "target": "s_273"
        },
        {
            "source": "r_56",
            "target": "s_385"
        },
        {
            "source": "r_56",
            "target": "s_629"
        },
        {
            "source": "r_57",
            "target": "s_27"
        },
        {
            "source": "r_57",
            "target": "s_629"
        },
        {
            "source": "r_57",
            "target": "s_543"
        },
        {
            "source": "r_58",
            "target": "s_652"
        },
        {
            "source": "r_58",
            "target": "s_518"
        },
        {
            "source": "r_58",
            "target": "s_202"
        },
        {
            "source": "r_58",
            "target": "s_150"
        },
        {
            "source": "r_58",
            "target": "s_554"
        },
        {
            "source": "r_58",
            "target": "s_129"
        },
        {
            "source": "r_59",
            "target": "s_660"
        },
        {
            "source": "r_59",
            "target": "s_392"
        },
        {
            "source": "r_59",
            "target": "s_273"
        },
        {
            "source": "r_60",
            "target": "s_143"
        },
        {
            "source": "r_60",
            "target": "s_445"
        },
        {
            "source": "r_60",
            "target": "s_665"
        },
        {
            "source": "r_60",
            "target": "s_225"
        },
        {
            "source": "r_60",
            "target": "s_339"
        },
        {
            "source": "r_60",
            "target": "s_8"
        },
        {
            "source": "r_61",
            "target": "s_125"
        },
        {
            "source": "r_61",
            "target": "s_70"
        },
        {
            "source": "r_61",
            "target": "s_318"
        },
        {
            "source": "r_62",
            "target": "s_457"
        },
        {
            "source": "r_62",
            "target": "s_27"
        },
        {
            "source": "r_62",
            "target": "s_128"
        },
        {
            "source": "r_62",
            "target": "s_344"
        },
        {
            "source": "r_63",
            "target": "s_661"
        },
        {
            "source": "r_63",
            "target": "s_359"
        },
        {
            "source": "r_63",
            "target": "s_301"
        },
        {
            "source": "r_63",
            "target": "s_219"
        },
        {
            "source": "r_63",
            "target": "s_266"
        },
        {
            "source": "r_63",
            "target": "s_249"
        },
        {
            "source": "r_64",
            "target": "s_572"
        },
        {
            "source": "r_64",
            "target": "s_445"
        },
        {
            "source": "r_65",
            "target": "s_658"
        },
        {
            "source": "r_65",
            "target": "s_124"
        },
        {
            "source": "r_65",
            "target": "s_372"
        },
        {
            "source": "r_65",
            "target": "s_585"
        },
        {
            "source": "r_65",
            "target": "s_429"
        },
        {
            "source": "r_66",
            "target": "s_147"
        },
        {
            "source": "r_66",
            "target": "s_641"
        },
        {
            "source": "r_66",
            "target": "s_130"
        },
        {
            "source": "r_67",
            "target": "s_140"
        },
        {
            "source": "r_67",
            "target": "s_433"
        },
        {
            "source": "r_67",
            "target": "s_126"
        },
        {
            "source": "r_67",
            "target": "s_620"
        },
        {
            "source": "r_67",
            "target": "s_511"
        },
        {
            "source": "r_67",
            "target": "s_457"
        },
        {
            "source": "r_67",
            "target": "s_244"
        },
        {
            "source": "r_68",
            "target": "s_286"
        },
        {
            "source": "r_68",
            "target": "s_647"
        },
        {
            "source": "r_69",
            "target": "s_438"
        },
        {
            "source": "r_69",
            "target": "s_416"
        },
        {
            "source": "r_69",
            "target": "s_585"
        },
        {
            "source": "r_69",
            "target": "s_515"
        },
        {
            "source": "r_70",
            "target": "s_673"
        },
        {
            "source": "r_70",
            "target": "s_14"
        },
        {
            "source": "r_70",
            "target": "s_183"
        },
        {
            "source": "r_70",
            "target": "s_244"
        },
        {
            "source": "r_71",
            "target": "s_648"
        },
        {
            "source": "r_71",
            "target": "s_31"
        },
        {
            "source": "r_71",
            "target": "s_380"
        },
        {
            "source": "r_71",
            "target": "s_114"
        },
        {
            "source": "r_71",
            "target": "s_3"
        },
        {
            "source": "r_72",
            "target": "s_300"
        },
        {
            "source": "r_72",
            "target": "s_366"
        },
        {
            "source": "r_72",
            "target": "s_570"
        },
        {
            "source": "r_72",
            "target": "s_145"
        },
        {
            "source": "r_73",
            "target": "s_97"
        },
        {
            "source": "r_73",
            "target": "s_638"
        },
        {
            "source": "r_73",
            "target": "s_224"
        },
        {
            "source": "r_73",
            "target": "s_585"
        },
        {
            "source": "r_73",
            "target": "s_658"
        },
        {
            "source": "r_74",
            "target": "s_350"
        },
        {
            "source": "r_74",
            "target": "s_384"
        },
        {
            "source": "r_74",
            "target": "s_110"
        },
        {
            "source": "r_74",
            "target": "s_363"
        },
        {
            "source": "r_75",
            "target": "s_158"
        },
        {
            "source": "r_75",
            "target": "s_485"
        },
        {
            "source": "r_76",
            "target": "s_581"
        },
        {
            "source": "r_76",
            "target": "s_671"
        },
        {
            "source": "r_76",
            "target": "s_432"
        },
        {
            "source": "r_76",
            "target": "s_0"
        },
        {
            "source": "r_76",
            "target": "s_395"
        },
        {
            "source": "r_77",
            "target": "s_367"
        },
        {
            "source": "r_77",
            "target": "s_556"
        },
        {
            "source": "r_77",
            "target": "s_523"
        },
        {
            "source": "r_77",
            "target": "s_337"
        },
        {
            "source": "r_77",
            "target": "s_561"
        },
        {
            "source": "r_77",
            "target": "s_352"
        },
        {
            "source": "r_78",
            "target": "s_470"
        },
        {
            "source": "r_78",
            "target": "s_616"
        },
        {
            "source": "r_78",
            "target": "s_222"
        },
        {
            "source": "r_78",
            "target": "s_63"
        },
        {
            "source": "r_78",
            "target": "s_343"
        },
        {
            "source": "r_78",
            "target": "s_102"
        },
        {
            "source": "r_79",
            "target": "s_84"
        },
        {
            "source": "r_79",
            "target": "s_443"
        },
        {
            "source": "r_80",
            "target": "s_278"
        },
        {
            "source": "r_80",
            "target": "s_650"
        },
        {
            "source": "r_80",
            "target": "s_453"
        },
        {
            "source": "r_80",
            "target": "s_649"
        },
        {
            "source": "r_81",
            "target": "s_289"
        },
        {
            "source": "r_81",
            "target": "s_560"
        },
        {
            "source": "r_81",
            "target": "s_402"
        },
        {
            "source": "r_81",
            "target": "s_588"
        },
        {
            "source": "r_81",
            "target": "s_193"
        },
        {
            "source": "r_81",
            "target": "s_491"
        },
        {
            "source": "r_81",
            "target": "s_153"
        },
        {
            "source": "r_81",
            "target": "s_626"
        },
        {
            "source": "r_81",
            "target": "s_283"
        },
        {
            "source": "r_81",
            "target": "s_454"
        },
        {
            "source": "r_81",
            "target": "s_395"
        },
        {
            "source": "r_82",
            "target": "s_158"
        },
        {
            "source": "r_82",
            "target": "s_397"
        },
        {
            "source": "r_82",
            "target": "s_313"
        },
        {
            "source": "r_82",
            "target": "s_475"
        },
        {
            "source": "r_82",
            "target": "s_485"
        },
        {
            "source": "r_83",
            "target": "s_302"
        },
        {
            "source": "r_83",
            "target": "s_562"
        },
        {
            "source": "r_83",
            "target": "s_443"
        },
        {
            "source": "r_84",
            "target": "s_191"
        },
        {
            "source": "r_84",
            "target": "s_482"
        },
        {
            "source": "r_84",
            "target": "s_356"
        },
        {
            "source": "r_84",
            "target": "s_572"
        },
        {
            "source": "r_85",
            "target": "s_108"
        },
        {
            "source": "r_85",
            "target": "s_136"
        },
        {
            "source": "r_85",
            "target": "s_635"
        },
        {
            "source": "r_85",
            "target": "s_434"
        },
        {
            "source": "r_85",
            "target": "s_9"
        },
        {
            "source": "r_86",
            "target": "s_659"
        },
        {
            "source": "r_86",
            "target": "s_36"
        },
        {
            "source": "r_86",
            "target": "s_641"
        },
        {
            "source": "r_86",
            "target": "s_102"
        },
        {
            "source": "r_86",
            "target": "s_595"
        },
        {
            "source": "r_87",
            "target": "s_124"
        },
        {
            "source": "r_87",
            "target": "s_658"
        },
        {
            "source": "r_87",
            "target": "s_666"
        },
        {
            "source": "r_87",
            "target": "s_239"
        },
        {
            "source": "r_87",
            "target": "s_585"
        },
        {
            "source": "r_88",
            "target": "s_240"
        },
        {
            "source": "r_88",
            "target": "s_641"
        },
        {
            "source": "r_88",
            "target": "s_647"
        },
        {
            "source": "r_88",
            "target": "s_277"
        },
        {
            "source": "r_89",
            "target": "s_240"
        },
        {
            "source": "r_89",
            "target": "s_641"
        },
        {
            "source": "r_89",
            "target": "s_277"
        },
        {
            "source": "r_90",
            "target": "s_290"
        },
        {
            "source": "r_90",
            "target": "s_112"
        },
        {
            "source": "r_90",
            "target": "s_563"
        },
        {
            "source": "r_90",
            "target": "s_559"
        },
        {
            "source": "r_90",
            "target": "s_224"
        },
        {
            "source": "r_90",
            "target": "s_372"
        },
        {
            "source": "r_90",
            "target": "s_653"
        },
        {
            "source": "r_90",
            "target": "s_585"
        },
        {
            "source": "r_91",
            "target": "s_633"
        },
        {
            "source": "r_91",
            "target": "s_658"
        },
        {
            "source": "r_91",
            "target": "s_307"
        },
        {
            "source": "r_91",
            "target": "s_12"
        },
        {
            "source": "r_91",
            "target": "s_349"
        },
        {
            "source": "r_91",
            "target": "s_162"
        },
        {
            "source": "r_91",
            "target": "s_134"
        },
        {
            "source": "r_91",
            "target": "s_372"
        },
        {
            "source": "r_92",
            "target": "s_254"
        },
        {
            "source": "r_92",
            "target": "s_631"
        },
        {
            "source": "r_92",
            "target": "s_32"
        },
        {
            "source": "r_92",
            "target": "s_406"
        },
        {
            "source": "r_92",
            "target": "s_354"
        },
        {
            "source": "r_92",
            "target": "s_19"
        },
        {
            "source": "r_93",
            "target": "s_256"
        },
        {
            "source": "r_93",
            "target": "s_427"
        },
        {
            "source": "r_93",
            "target": "s_636"
        },
        {
            "source": "r_93",
            "target": "s_300"
        },
        {
            "source": "r_94",
            "target": "s_145"
        },
        {
            "source": "r_94",
            "target": "s_162"
        },
        {
            "source": "r_94",
            "target": "s_474"
        },
        {
            "source": "r_94",
            "target": "s_300"
        },
        {
            "source": "r_95",
            "target": "s_457"
        },
        {
            "source": "r_95",
            "target": "s_399"
        },
        {
            "source": "r_95",
            "target": "s_169"
        },
        {
            "source": "r_95",
            "target": "s_403"
        },
        {
            "source": "r_95",
            "target": "s_183"
        },
        {
            "source": "r_95",
            "target": "s_244"
        },
        {
            "source": "r_96",
            "target": "s_312"
        },
        {
            "source": "r_96",
            "target": "s_276"
        },
        {
            "source": "r_96",
            "target": "s_615"
        },
        {
            "source": "r_96",
            "target": "s_133"
        },
        {
            "source": "r_96",
            "target": "s_410"
        },
        {
            "source": "r_97",
            "target": "s_147"
        },
        {
            "source": "r_97",
            "target": "s_641"
        },
        {
            "source": "r_97",
            "target": "s_411"
        },
        {
            "source": "r_97",
            "target": "s_130"
        },
        {
            "source": "r_98",
            "target": "s_385"
        },
        {
            "source": "r_98",
            "target": "s_629"
        },
        {
            "source": "r_99",
            "target": "s_632"
        },
        {
            "source": "r_99",
            "target": "s_665"
        },
        {
            "source": "r_99",
            "target": "s_243"
        },
        {
            "source": "r_99",
            "target": "s_576"
        },
        {
            "source": "r_99",
            "target": "s_273"
        },
        {
            "source": "r_99",
            "target": "s_617"
        },
        {
            "source": "r_100",
            "target": "s_522"
        },
        {
            "source": "r_100",
            "target": "s_131"
        },
        {
            "source": "r_100",
            "target": "s_590"
        },
        {
            "source": "r_100",
            "target": "s_96"
        },
        {
            "source": "r_100",
            "target": "s_353"
        },
        {
            "source": "r_100",
            "target": "s_213"
        },
        {
            "source": "r_100",
            "target": "s_293"
        },
        {
            "source": "r_100",
            "target": "s_116"
        },
        {
            "source": "r_101",
            "target": "s_280"
        },
        {
            "source": "r_101",
            "target": "s_218"
        },
        {
            "source": "r_101",
            "target": "s_477"
        },
        {
            "source": "r_101",
            "target": "s_531"
        },
        {
            "source": "r_101",
            "target": "s_160"
        },
        {
            "source": "r_101",
            "target": "s_429"
        },
        {
            "source": "r_101",
            "target": "s_474"
        },
        {
            "source": "r_101",
            "target": "s_360"
        },
        {
            "source": "r_101",
            "target": "s_395"
        },
        {
            "source": "r_102",
            "target": "s_660"
        },
        {
            "source": "r_102",
            "target": "s_665"
        },
        {
            "source": "r_102",
            "target": "s_551"
        },
        {
            "source": "r_102",
            "target": "s_3"
        },
        {
            "source": "r_102",
            "target": "s_392"
        },
        {
            "source": "r_102",
            "target": "s_617"
        },
        {
            "source": "r_102",
            "target": "s_582"
        },
        {
            "source": "r_102",
            "target": "s_273"
        },
        {
            "source": "r_103",
            "target": "s_136"
        },
        {
            "source": "r_103",
            "target": "s_108"
        },
        {
            "source": "r_103",
            "target": "s_78"
        },
        {
            "source": "r_103",
            "target": "s_644"
        },
        {
            "source": "r_103",
            "target": "s_434"
        },
        {
            "source": "r_103",
            "target": "s_364"
        },
        {
            "source": "r_103",
            "target": "s_279"
        },
        {
            "source": "r_103",
            "target": "s_137"
        },
        {
            "source": "r_104",
            "target": "s_455"
        },
        {
            "source": "r_104",
            "target": "s_166"
        },
        {
            "source": "r_104",
            "target": "s_115"
        },
        {
            "source": "r_104",
            "target": "s_474"
        },
        {
            "source": "r_104",
            "target": "s_18"
        },
        {
            "source": "r_105",
            "target": "s_262"
        },
        {
            "source": "r_105",
            "target": "s_203"
        },
        {
            "source": "r_105",
            "target": "s_440"
        },
        {
            "source": "r_105",
            "target": "s_547"
        },
        {
            "source": "r_105",
            "target": "s_541"
        },
        {
            "source": "r_105",
            "target": "s_465"
        },
        {
            "source": "r_105",
            "target": "s_348"
        },
        {
            "source": "r_105",
            "target": "s_410"
        },
        {
            "source": "r_106",
            "target": "s_659"
        },
        {
            "source": "r_106",
            "target": "s_36"
        },
        {
            "source": "r_106",
            "target": "s_45"
        },
        {
            "source": "r_106",
            "target": "s_102"
        },
        {
            "source": "r_106",
            "target": "s_595"
        },
        {
            "source": "r_107",
            "target": "s_552"
        },
        {
            "source": "r_107",
            "target": "s_407"
        },
        {
            "source": "r_107",
            "target": "s_474"
        },
        {
            "source": "r_107",
            "target": "s_115"
        },
        {
            "source": "r_107",
            "target": "s_18"
        },
        {
            "source": "r_108",
            "target": "s_141"
        },
        {
            "source": "r_108",
            "target": "s_671"
        },
        {
            "source": "r_108",
            "target": "s_474"
        },
        {
            "source": "r_108",
            "target": "s_395"
        },
        {
            "source": "r_108",
            "target": "s_448"
        },
        {
            "source": "r_109",
            "target": "s_655"
        },
        {
            "source": "r_109",
            "target": "s_421"
        },
        {
            "source": "r_110",
            "target": "s_423"
        },
        {
            "source": "r_110",
            "target": "s_151"
        },
        {
            "source": "r_110",
            "target": "s_647"
        },
        {
            "source": "r_111",
            "target": "s_199"
        },
        {
            "source": "r_111",
            "target": "s_587"
        },
        {
            "source": "r_111",
            "target": "s_623"
        },
        {
            "source": "r_111",
            "target": "s_646"
        },
        {
            "source": "r_111",
            "target": "s_291"
        },
        {
            "source": "r_111",
            "target": "s_405"
        },
        {
            "source": "r_111",
            "target": "s_332"
        },
        {
            "source": "r_112",
            "target": "s_546"
        },
        {
            "source": "r_112",
            "target": "s_244"
        },
        {
            "source": "r_112",
            "target": "s_674"
        },
        {
            "source": "r_112",
            "target": "s_206"
        },
        {
            "source": "r_113",
            "target": "s_635"
        },
        {
            "source": "r_113",
            "target": "s_386"
        },
        {
            "source": "r_113",
            "target": "s_136"
        },
        {
            "source": "r_113",
            "target": "s_517"
        },
        {
            "source": "r_113",
            "target": "s_434"
        },
        {
            "source": "r_113",
            "target": "s_144"
        },
        {
            "source": "r_114",
            "target": "s_534"
        },
        {
            "source": "r_114",
            "target": "s_356"
        },
        {
            "source": "r_114",
            "target": "s_186"
        },
        {
            "source": "r_114",
            "target": "s_255"
        },
        {
            "source": "r_114",
            "target": "s_72"
        },
        {
            "source": "r_114",
            "target": "s_576"
        },
        {
            "source": "r_114",
            "target": "s_392"
        },
        {
            "source": "r_114",
            "target": "s_273"
        },
        {
            "source": "r_115",
            "target": "s_30"
        },
        {
            "source": "r_115",
            "target": "s_220"
        },
        {
            "source": "r_115",
            "target": "s_190"
        },
        {
            "source": "r_115",
            "target": "s_94"
        },
        {
            "source": "r_115",
            "target": "s_662"
        },
        {
            "source": "r_115",
            "target": "s_35"
        },
        {
            "source": "r_116",
            "target": "s_497"
        },
        {
            "source": "r_116",
            "target": "s_181"
        },
        {
            "source": "r_116",
            "target": "s_572"
        },
        {
            "source": "r_117",
            "target": "s_230"
        },
        {
            "source": "r_117",
            "target": "s_77"
        },
        {
            "source": "r_117",
            "target": "s_448"
        },
        {
            "source": "r_117",
            "target": "s_450"
        },
        {
            "source": "r_117",
            "target": "s_574"
        },
        {
            "source": "r_117",
            "target": "s_454"
        },
        {
            "source": "r_117",
            "target": "s_119"
        },
        {
            "source": "r_117",
            "target": "s_474"
        },
        {
            "source": "r_117",
            "target": "s_395"
        },
        {
            "source": "r_118",
            "target": "s_447"
        },
        {
            "source": "r_118",
            "target": "s_304"
        },
        {
            "source": "r_118",
            "target": "s_318"
        },
        {
            "source": "r_119",
            "target": "s_658"
        },
        {
            "source": "r_119",
            "target": "s_148"
        },
        {
            "source": "r_119",
            "target": "s_585"
        },
        {
            "source": "r_119",
            "target": "s_589"
        },
        {
            "source": "r_120",
            "target": "s_586"
        },
        {
            "source": "r_120",
            "target": "s_245"
        },
        {
            "source": "r_120",
            "target": "s_558"
        },
        {
            "source": "r_120",
            "target": "s_530"
        },
        {
            "source": "r_121",
            "target": "s_469"
        },
        {
            "source": "r_121",
            "target": "s_417"
        },
        {
            "source": "r_121",
            "target": "s_586"
        },
        {
            "source": "r_121",
            "target": "s_558"
        },
        {
            "source": "r_122",
            "target": "s_28"
        },
        {
            "source": "r_122",
            "target": "s_647"
        },
        {
            "source": "r_123",
            "target": "s_188"
        },
        {
            "source": "r_123",
            "target": "s_309"
        },
        {
            "source": "r_123",
            "target": "s_130"
        },
        {
            "source": "r_124",
            "target": "s_30"
        },
        {
            "source": "r_124",
            "target": "s_220"
        },
        {
            "source": "r_124",
            "target": "s_662"
        },
        {
            "source": "r_124",
            "target": "s_572"
        },
        {
            "source": "r_125",
            "target": "s_548"
        },
        {
            "source": "r_125",
            "target": "s_282"
        },
        {
            "source": "r_125",
            "target": "s_296"
        },
        {
            "source": "r_125",
            "target": "s_183"
        },
        {
            "source": "r_125",
            "target": "s_1"
        },
        {
            "source": "r_125",
            "target": "s_567"
        },
        {
            "source": "r_126",
            "target": "s_673"
        },
        {
            "source": "r_126",
            "target": "s_244"
        },
        {
            "source": "r_127",
            "target": "s_673"
        },
        {
            "source": "r_127",
            "target": "s_546"
        },
        {
            "source": "r_127",
            "target": "s_244"
        },
        {
            "source": "r_128",
            "target": "s_534"
        },
        {
            "source": "r_128",
            "target": "s_72"
        },
        {
            "source": "r_128",
            "target": "s_186"
        },
        {
            "source": "r_128",
            "target": "s_392"
        },
        {
            "source": "r_128",
            "target": "s_255"
        },
        {
            "source": "r_128",
            "target": "s_273"
        },
        {
            "source": "r_129",
            "target": "s_626"
        },
        {
            "source": "r_129",
            "target": "s_230"
        },
        {
            "source": "r_129",
            "target": "s_477"
        },
        {
            "source": "r_129",
            "target": "s_275"
        },
        {
            "source": "r_129",
            "target": "s_594"
        },
        {
            "source": "r_129",
            "target": "s_574"
        },
        {
            "source": "r_129",
            "target": "s_474"
        },
        {
            "source": "r_129",
            "target": "s_395"
        },
        {
            "source": "r_130",
            "target": "s_163"
        },
        {
            "source": "r_130",
            "target": "s_101"
        },
        {
            "source": "r_130",
            "target": "s_653"
        },
        {
            "source": "r_131",
            "target": "s_187"
        },
        {
            "source": "r_131",
            "target": "s_71"
        },
        {
            "source": "r_131",
            "target": "s_321"
        },
        {
            "source": "r_131",
            "target": "s_15"
        },
        {
            "source": "r_131",
            "target": "s_177"
        },
        {
            "source": "r_131",
            "target": "s_598"
        },
        {
            "source": "r_131",
            "target": "s_495"
        },
        {
            "source": "r_131",
            "target": "s_277"
        },
        {
            "source": "r_132",
            "target": "s_464"
        },
        {
            "source": "r_132",
            "target": "s_54"
        },
        {
            "source": "r_132",
            "target": "s_412"
        },
        {
            "source": "r_132",
            "target": "s_251"
        },
        {
            "source": "r_132",
            "target": "s_13"
        },
        {
            "source": "r_133",
            "target": "s_669"
        },
        {
            "source": "r_133",
            "target": "s_168"
        },
        {
            "source": "r_133",
            "target": "s_89"
        },
        {
            "source": "r_133",
            "target": "s_309"
        },
        {
            "source": "r_133",
            "target": "s_152"
        },
        {
            "source": "r_134",
            "target": "s_346"
        },
        {
            "source": "r_134",
            "target": "s_183"
        },
        {
            "source": "r_135",
            "target": "s_91"
        },
        {
            "source": "r_135",
            "target": "s_179"
        },
        {
            "source": "r_135",
            "target": "s_164"
        },
        {
            "source": "r_135",
            "target": "s_535"
        },
        {
            "source": "r_135",
            "target": "s_377"
        },
        {
            "source": "r_135",
            "target": "s_13"
        },
        {
            "source": "r_136",
            "target": "s_627"
        },
        {
            "source": "r_136",
            "target": "s_548"
        },
        {
            "source": "r_136",
            "target": "s_183"
        },
        {
            "source": "r_136",
            "target": "s_448"
        },
        {
            "source": "r_136",
            "target": "s_1"
        },
        {
            "source": "r_136",
            "target": "s_567"
        },
        {
            "source": "r_137",
            "target": "s_645"
        },
        {
            "source": "r_137",
            "target": "s_314"
        },
        {
            "source": "r_137",
            "target": "s_485"
        },
        {
            "source": "r_137",
            "target": "s_507"
        },
        {
            "source": "r_137",
            "target": "s_136"
        },
        {
            "source": "r_137",
            "target": "s_579"
        },
        {
            "source": "r_137",
            "target": "s_490"
        },
        {
            "source": "r_138",
            "target": "s_49"
        },
        {
            "source": "r_138",
            "target": "s_162"
        },
        {
            "source": "r_139",
            "target": "s_41"
        },
        {
            "source": "r_139",
            "target": "s_17"
        },
        {
            "source": "r_139",
            "target": "s_251"
        },
        {
            "source": "r_139",
            "target": "s_13"
        },
        {
            "source": "r_140",
            "target": "s_17"
        },
        {
            "source": "r_140",
            "target": "s_13"
        },
        {
            "source": "r_141",
            "target": "s_443"
        },
        {
            "source": "r_141",
            "target": "s_653"
        },
        {
            "source": "r_142",
            "target": "s_156"
        },
        {
            "source": "r_142",
            "target": "s_657"
        },
        {
            "source": "r_142",
            "target": "s_173"
        },
        {
            "source": "r_142",
            "target": "s_122"
        },
        {
            "source": "r_142",
            "target": "s_130"
        },
        {
            "source": "r_143",
            "target": "s_231"
        },
        {
            "source": "r_143",
            "target": "s_280"
        },
        {
            "source": "r_143",
            "target": "s_230"
        },
        {
            "source": "r_143",
            "target": "s_474"
        },
        {
            "source": "r_143",
            "target": "s_395"
        },
        {
            "source": "r_143",
            "target": "s_429"
        },
        {
            "source": "r_144",
            "target": "s_155"
        },
        {
            "source": "r_144",
            "target": "s_632"
        },
        {
            "source": "r_144",
            "target": "s_38"
        },
        {
            "source": "r_144",
            "target": "s_576"
        },
        {
            "source": "r_144",
            "target": "s_309"
        },
        {
            "source": "r_145",
            "target": "s_502"
        },
        {
            "source": "r_145",
            "target": "s_162"
        },
        {
            "source": "r_146",
            "target": "s_65"
        },
        {
            "source": "r_146",
            "target": "s_485"
        },
        {
            "source": "r_146",
            "target": "s_9"
        },
        {
            "source": "r_146",
            "target": "s_456"
        },
        {
            "source": "r_146",
            "target": "s_490"
        },
        {
            "source": "r_147",
            "target": "s_61"
        },
        {
            "source": "r_147",
            "target": "s_162"
        },
        {
            "source": "r_147",
            "target": "s_474"
        },
        {
            "source": "r_147",
            "target": "s_300"
        },
        {
            "source": "r_147",
            "target": "s_145"
        },
        {
            "source": "r_148",
            "target": "s_446"
        },
        {
            "source": "r_148",
            "target": "s_286"
        },
        {
            "source": "r_148",
            "target": "s_647"
        },
        {
            "source": "r_149",
            "target": "s_527"
        },
        {
            "source": "r_149",
            "target": "s_637"
        },
        {
            "source": "r_149",
            "target": "s_92"
        },
        {
            "source": "r_149",
            "target": "s_15"
        },
        {
            "source": "r_149",
            "target": "s_435"
        },
        {
            "source": "r_149",
            "target": "s_471"
        },
        {
            "source": "r_149",
            "target": "s_277"
        },
        {
            "source": "r_150",
            "target": "s_25"
        },
        {
            "source": "r_150",
            "target": "s_389"
        },
        {
            "source": "r_150",
            "target": "s_519"
        },
        {
            "source": "r_150",
            "target": "s_458"
        },
        {
            "source": "r_150",
            "target": "s_532"
        },
        {
            "source": "r_151",
            "target": "s_145"
        },
        {
            "source": "r_151",
            "target": "s_366"
        },
        {
            "source": "r_151",
            "target": "s_557"
        },
        {
            "source": "r_151",
            "target": "s_123"
        },
        {
            "source": "r_151",
            "target": "s_561"
        },
        {
            "source": "r_151",
            "target": "s_570"
        },
        {
            "source": "r_151",
            "target": "s_300"
        },
        {
            "source": "r_152",
            "target": "s_27"
        },
        {
            "source": "r_152",
            "target": "s_572"
        },
        {
            "source": "r_152",
            "target": "s_198"
        },
        {
            "source": "r_152",
            "target": "s_315"
        },
        {
            "source": "r_152",
            "target": "s_344"
        },
        {
            "source": "r_153",
            "target": "s_241"
        },
        {
            "source": "r_153",
            "target": "s_329"
        },
        {
            "source": "r_153",
            "target": "s_312"
        },
        {
            "source": "r_153",
            "target": "s_316"
        },
        {
            "source": "r_153",
            "target": "s_508"
        },
        {
            "source": "r_153",
            "target": "s_113"
        },
        {
            "source": "r_153",
            "target": "s_514"
        },
        {
            "source": "r_153",
            "target": "s_383"
        },
        {
            "source": "r_153",
            "target": "s_410"
        },
        {
            "source": "r_154",
            "target": "s_217"
        },
        {
            "source": "r_154",
            "target": "s_170"
        },
        {
            "source": "r_154",
            "target": "s_664"
        },
        {
            "source": "r_154",
            "target": "s_175"
        },
        {
            "source": "r_154",
            "target": "s_425"
        },
        {
            "source": "r_154",
            "target": "s_234"
        },
        {
            "source": "r_154",
            "target": "s_409"
        },
        {
            "source": "r_154",
            "target": "s_284"
        },
        {
            "source": "r_154",
            "target": "s_421"
        },
        {
            "source": "r_155",
            "target": "s_270"
        },
        {
            "source": "r_155",
            "target": "s_101"
        },
        {
            "source": "r_155",
            "target": "s_653"
        },
        {
            "source": "r_156",
            "target": "s_125"
        },
        {
            "source": "r_156",
            "target": "s_521"
        },
        {
            "source": "r_156",
            "target": "s_318"
        },
        {
            "source": "r_156",
            "target": "s_345"
        },
        {
            "source": "r_157",
            "target": "s_539"
        },
        {
            "source": "r_157",
            "target": "s_340"
        },
        {
            "source": "r_157",
            "target": "s_211"
        },
        {
            "source": "r_157",
            "target": "s_641"
        },
        {
            "source": "r_158",
            "target": "s_607"
        },
        {
            "source": "r_158",
            "target": "s_500"
        },
        {
            "source": "r_158",
            "target": "s_220"
        },
        {
            "source": "r_159",
            "target": "s_640"
        },
        {
            "source": "r_159",
            "target": "s_591"
        },
        {
            "source": "r_159",
            "target": "s_117"
        },
        {
            "source": "r_159",
            "target": "s_81"
        },
        {
            "source": "r_159",
            "target": "s_154"
        },
        {
            "source": "r_159",
            "target": "s_207"
        },
        {
            "source": "r_159",
            "target": "s_474"
        },
        {
            "source": "r_159",
            "target": "s_162"
        },
        {
            "source": "r_160",
            "target": "s_261"
        },
        {
            "source": "r_160",
            "target": "s_538"
        },
        {
            "source": "r_160",
            "target": "s_106"
        },
        {
            "source": "r_160",
            "target": "s_73"
        },
        {
            "source": "r_160",
            "target": "s_474"
        },
        {
            "source": "r_161",
            "target": "s_168"
        },
        {
            "source": "r_161",
            "target": "s_152"
        },
        {
            "source": "r_162",
            "target": "s_97"
        },
        {
            "source": "r_162",
            "target": "s_443"
        },
        {
            "source": "r_162",
            "target": "s_20"
        },
        {
            "source": "r_162",
            "target": "s_555"
        },
        {
            "source": "r_162",
            "target": "s_585"
        },
        {
            "source": "r_162",
            "target": "s_658"
        },
        {
            "source": "r_163",
            "target": "s_669"
        },
        {
            "source": "r_163",
            "target": "s_309"
        },
        {
            "source": "r_164",
            "target": "s_523"
        },
        {
            "source": "r_164",
            "target": "s_670"
        },
        {
            "source": "r_164",
            "target": "s_503"
        },
        {
            "source": "r_164",
            "target": "s_352"
        },
        {
            "source": "r_165",
            "target": "s_240"
        },
        {
            "source": "r_165",
            "target": "s_277"
        },
        {
            "source": "r_166",
            "target": "s_39"
        },
        {
            "source": "r_166",
            "target": "s_665"
        },
        {
            "source": "r_166",
            "target": "s_229"
        },
        {
            "source": "r_166",
            "target": "s_445"
        },
        {
            "source": "r_166",
            "target": "s_273"
        },
        {
            "source": "r_167",
            "target": "s_539"
        },
        {
            "source": "r_167",
            "target": "s_340"
        },
        {
            "source": "r_167",
            "target": "s_146"
        },
        {
            "source": "r_167",
            "target": "s_643"
        },
        {
            "source": "r_167",
            "target": "s_315"
        },
        {
            "source": "r_167",
            "target": "s_641"
        },
        {
            "source": "r_168",
            "target": "s_444"
        },
        {
            "source": "r_168",
            "target": "s_567"
        },
        {
            "source": "r_168",
            "target": "s_296"
        },
        {
            "source": "r_168",
            "target": "s_183"
        },
        {
            "source": "r_169",
            "target": "s_136"
        },
        {
            "source": "r_169",
            "target": "s_331"
        },
        {
            "source": "r_169",
            "target": "s_9"
        },
        {
            "source": "r_169",
            "target": "s_459"
        },
        {
            "source": "r_169",
            "target": "s_56"
        },
        {
            "source": "r_170",
            "target": "s_655"
        },
        {
            "source": "r_170",
            "target": "s_391"
        },
        {
            "source": "r_170",
            "target": "s_118"
        },
        {
            "source": "r_170",
            "target": "s_317"
        },
        {
            "source": "r_170",
            "target": "s_310"
        },
        {
            "source": "r_170",
            "target": "s_654"
        },
        {
            "source": "r_170",
            "target": "s_611"
        },
        {
            "source": "r_170",
            "target": "s_421"
        },
        {
            "source": "r_171",
            "target": "s_438"
        },
        {
            "source": "r_171",
            "target": "s_566"
        },
        {
            "source": "r_171",
            "target": "s_37"
        },
        {
            "source": "r_171",
            "target": "s_442"
        },
        {
            "source": "r_171",
            "target": "s_585"
        },
        {
            "source": "r_171",
            "target": "s_515"
        },
        {
            "source": "r_172",
            "target": "s_369"
        },
        {
            "source": "r_172",
            "target": "s_540"
        },
        {
            "source": "r_172",
            "target": "s_550"
        },
        {
            "source": "r_172",
            "target": "s_634"
        },
        {
            "source": "r_172",
            "target": "s_509"
        },
        {
            "source": "r_172",
            "target": "s_300"
        },
        {
            "source": "r_173",
            "target": "s_651"
        },
        {
            "source": "r_173",
            "target": "s_457"
        },
        {
            "source": "r_173",
            "target": "s_620"
        },
        {
            "source": "r_173",
            "target": "s_599"
        },
        {
            "source": "r_173",
            "target": "s_244"
        },
        {
            "source": "r_173",
            "target": "s_344"
        },
        {
            "source": "r_174",
            "target": "s_53"
        },
        {
            "source": "r_174",
            "target": "s_516"
        },
        {
            "source": "r_174",
            "target": "s_26"
        },
        {
            "source": "r_174",
            "target": "s_427"
        },
        {
            "source": "r_175",
            "target": "s_489"
        },
        {
            "source": "r_175",
            "target": "s_542"
        },
        {
            "source": "r_175",
            "target": "s_68"
        },
        {
            "source": "r_175",
            "target": "s_649"
        },
        {
            "source": "r_175",
            "target": "s_453"
        },
        {
            "source": "r_176",
            "target": "s_250"
        },
        {
            "source": "r_176",
            "target": "s_197"
        },
        {
            "source": "r_176",
            "target": "s_142"
        },
        {
            "source": "r_176",
            "target": "s_673"
        },
        {
            "source": "r_176",
            "target": "s_66"
        },
        {
            "source": "r_176",
            "target": "s_546"
        },
        {
            "source": "r_176",
            "target": "s_183"
        },
        {
            "source": "r_177",
            "target": "s_167"
        },
        {
            "source": "r_177",
            "target": "s_226"
        },
        {
            "source": "r_177",
            "target": "s_363"
        },
        {
            "source": "r_177",
            "target": "s_5"
        },
        {
            "source": "r_178",
            "target": "s_298"
        },
        {
            "source": "r_178",
            "target": "s_576"
        },
        {
            "source": "r_178",
            "target": "s_100"
        },
        {
            "source": "r_178",
            "target": "s_660"
        },
        {
            "source": "r_178",
            "target": "s_466"
        },
        {
            "source": "r_178",
            "target": "s_272"
        },
        {
            "source": "r_178",
            "target": "s_486"
        },
        {
            "source": "r_178",
            "target": "s_273"
        },
        {
            "source": "r_179",
            "target": "s_457"
        },
        {
            "source": "r_179",
            "target": "s_244"
        },
        {
            "source": "r_179",
            "target": "s_433"
        },
        {
            "source": "r_179",
            "target": "s_651"
        },
        {
            "source": "r_179",
            "target": "s_501"
        },
        {
            "source": "r_179",
            "target": "s_79"
        },
        {
            "source": "r_179",
            "target": "s_476"
        },
        {
            "source": "r_179",
            "target": "s_620"
        },
        {
            "source": "r_179",
            "target": "s_344"
        },
        {
            "source": "r_179",
            "target": "s_599"
        },
        {
            "source": "r_180",
            "target": "s_147"
        },
        {
            "source": "r_180",
            "target": "s_411"
        },
        {
            "source": "r_181",
            "target": "s_524"
        },
        {
            "source": "r_181",
            "target": "s_147"
        },
        {
            "source": "r_181",
            "target": "s_431"
        },
        {
            "source": "r_181",
            "target": "s_536"
        },
        {
            "source": "r_181",
            "target": "s_139"
        },
        {
            "source": "r_181",
            "target": "s_130"
        },
        {
            "source": "r_181",
            "target": "s_238"
        },
        {
            "source": "r_182",
            "target": "s_98"
        },
        {
            "source": "r_182",
            "target": "s_413"
        },
        {
            "source": "r_182",
            "target": "s_220"
        },
        {
            "source": "r_182",
            "target": "s_361"
        },
        {
            "source": "r_182",
            "target": "s_483"
        },
        {
            "source": "r_182",
            "target": "s_295"
        },
        {
            "source": "r_182",
            "target": "s_365"
        },
        {
            "source": "r_183",
            "target": "s_462"
        },
        {
            "source": "r_183",
            "target": "s_336"
        },
        {
            "source": "r_183",
            "target": "s_379"
        },
        {
            "source": "r_183",
            "target": "s_538"
        },
        {
            "source": "r_183",
            "target": "s_564"
        },
        {
            "source": "r_183",
            "target": "s_430"
        },
        {
            "source": "r_183",
            "target": "s_103"
        },
        {
            "source": "r_183",
            "target": "s_215"
        },
        {
            "source": "r_184",
            "target": "s_48"
        },
        {
            "source": "r_184",
            "target": "s_376"
        },
        {
            "source": "r_184",
            "target": "s_263"
        },
        {
            "source": "r_184",
            "target": "s_141"
        },
        {
            "source": "r_184",
            "target": "s_306"
        },
        {
            "source": "r_184",
            "target": "s_419"
        },
        {
            "source": "r_184",
            "target": "s_583"
        },
        {
            "source": "r_184",
            "target": "s_580"
        },
        {
            "source": "r_184",
            "target": "s_448"
        },
        {
            "source": "r_185",
            "target": "s_51"
        },
        {
            "source": "r_185",
            "target": "s_424"
        },
        {
            "source": "r_185",
            "target": "s_157"
        },
        {
            "source": "r_186",
            "target": "s_452"
        },
        {
            "source": "r_186",
            "target": "s_492"
        },
        {
            "source": "r_186",
            "target": "s_642"
        },
        {
            "source": "r_186",
            "target": "s_334"
        },
        {
            "source": "r_186",
            "target": "s_658"
        },
        {
            "source": "r_187",
            "target": "s_557"
        },
        {
            "source": "r_187",
            "target": "s_88"
        },
        {
            "source": "r_187",
            "target": "s_578"
        },
        {
            "source": "r_187",
            "target": "s_544"
        },
        {
            "source": "r_187",
            "target": "s_561"
        },
        {
            "source": "r_187",
            "target": "s_300"
        },
        {
            "source": "r_188",
            "target": "s_53"
        },
        {
            "source": "r_188",
            "target": "s_427"
        },
        {
            "source": "r_189",
            "target": "s_308"
        },
        {
            "source": "r_189",
            "target": "s_498"
        },
        {
            "source": "r_189",
            "target": "s_647"
        },
        {
            "source": "r_189",
            "target": "s_441"
        },
        {
            "source": "r_189",
            "target": "s_371"
        },
        {
            "source": "r_189",
            "target": "s_182"
        },
        {
            "source": "r_189",
            "target": "s_569"
        },
        {
            "source": "r_189",
            "target": "s_75"
        },
        {
            "source": "r_190",
            "target": "s_257"
        },
        {
            "source": "r_190",
            "target": "s_406"
        },
        {
            "source": "r_190",
            "target": "s_19"
        },
        {
            "source": "r_191",
            "target": "s_389"
        },
        {
            "source": "r_191",
            "target": "s_673"
        },
        {
            "source": "r_191",
            "target": "s_599"
        },
        {
            "source": "r_191",
            "target": "s_244"
        },
        {
            "source": "r_192",
            "target": "s_646"
        },
        {
            "source": "r_192",
            "target": "s_332"
        },
        {
            "source": "r_193",
            "target": "s_632"
        },
        {
            "source": "r_193",
            "target": "s_105"
        },
        {
            "source": "r_193",
            "target": "s_576"
        },
        {
            "source": "r_193",
            "target": "s_100"
        },
        {
            "source": "r_193",
            "target": "s_259"
        },
        {
            "source": "r_193",
            "target": "s_273"
        },
        {
            "source": "r_194",
            "target": "s_34"
        },
        {
            "source": "r_194",
            "target": "s_195"
        },
        {
            "source": "r_194",
            "target": "s_428"
        },
        {
            "source": "r_194",
            "target": "s_434"
        },
        {
            "source": "r_194",
            "target": "s_460"
        },
        {
            "source": "r_195",
            "target": "s_466"
        },
        {
            "source": "r_195",
            "target": "s_660"
        },
        {
            "source": "r_195",
            "target": "s_214"
        },
        {
            "source": "r_195",
            "target": "s_171"
        },
        {
            "source": "r_195",
            "target": "s_50"
        },
        {
            "source": "r_195",
            "target": "s_159"
        },
        {
            "source": "r_195",
            "target": "s_273"
        },
        {
            "source": "r_196",
            "target": "s_624"
        },
        {
            "source": "r_196",
            "target": "s_630"
        },
        {
            "source": "r_196",
            "target": "s_109"
        },
        {
            "source": "r_196",
            "target": "s_520"
        },
        {
            "source": "r_196",
            "target": "s_184"
        },
        {
            "source": "r_196",
            "target": "s_443"
        },
        {
            "source": "r_197",
            "target": "s_596"
        },
        {
            "source": "r_197",
            "target": "s_326"
        },
        {
            "source": "r_197",
            "target": "s_647"
        },
        {
            "source": "r_198",
            "target": "s_398"
        },
        {
            "source": "r_198",
            "target": "s_157"
        },
        {
            "source": "r_199",
            "target": "s_4"
        },
        {
            "source": "r_199",
            "target": "s_60"
        },
        {
            "source": "r_199",
            "target": "s_120"
        },
        {
            "source": "r_199",
            "target": "s_311"
        },
        {
            "source": "r_200",
            "target": "s_358"
        },
        {
            "source": "r_200",
            "target": "s_162"
        },
        {
            "source": "r_200",
            "target": "s_395"
        },
        {
            "source": "r_200",
            "target": "s_338"
        },
        {
            "source": "r_201",
            "target": "s_529"
        },
        {
            "source": "r_201",
            "target": "s_521"
        },
        {
            "source": "r_201",
            "target": "s_422"
        },
        {
            "source": "r_201",
            "target": "s_606"
        },
        {
            "source": "r_201",
            "target": "s_318"
        },
        {
            "source": "r_201",
            "target": "s_345"
        },
        {
            "source": "r_202",
            "target": "s_76"
        },
        {
            "source": "r_202",
            "target": "s_13"
        },
        {
            "source": "r_203",
            "target": "s_621"
        },
        {
            "source": "r_203",
            "target": "s_74"
        },
        {
            "source": "r_203",
            "target": "s_480"
        },
        {
            "source": "r_203",
            "target": "s_395"
        },
        {
            "source": "r_204",
            "target": "s_242"
        },
        {
            "source": "r_204",
            "target": "s_647"
        },
        {
            "source": "r_204",
            "target": "s_565"
        },
        {
            "source": "r_204",
            "target": "s_400"
        },
        {
            "source": "r_205",
            "target": "s_42"
        },
        {
            "source": "r_205",
            "target": "s_149"
        },
        {
            "source": "r_205",
            "target": "s_411"
        },
        {
            "source": "r_206",
            "target": "s_72"
        },
        {
            "source": "r_206",
            "target": "s_660"
        },
        {
            "source": "r_206",
            "target": "s_392"
        },
        {
            "source": "r_206",
            "target": "s_273"
        },
        {
            "source": "r_207",
            "target": "s_443"
        },
        {
            "source": "r_207",
            "target": "s_653"
        },
        {
            "source": "r_208",
            "target": "s_174"
        },
        {
            "source": "r_208",
            "target": "s_424"
        },
        {
            "source": "r_208",
            "target": "s_505"
        },
        {
            "source": "r_208",
            "target": "s_157"
        },
        {
            "source": "r_209",
            "target": "s_443"
        },
        {
            "source": "r_209",
            "target": "s_653"
        },
        {
            "source": "r_210",
            "target": "s_67"
        },
        {
            "source": "r_210",
            "target": "s_499"
        },
        {
            "source": "r_210",
            "target": "s_195"
        },
        {
            "source": "r_210",
            "target": "s_85"
        },
        {
            "source": "r_210",
            "target": "s_288"
        },
        {
            "source": "r_210",
            "target": "s_401"
        },
        {
            "source": "r_210",
            "target": "s_512"
        },
        {
            "source": "r_210",
            "target": "s_478"
        },
        {
            "source": "r_211",
            "target": "s_212"
        },
        {
            "source": "r_211",
            "target": "s_578"
        },
        {
            "source": "r_211",
            "target": "s_663"
        },
        {
            "source": "r_212",
            "target": "s_452"
        },
        {
            "source": "r_212",
            "target": "s_95"
        },
        {
            "source": "r_212",
            "target": "s_439"
        },
        {
            "source": "r_212",
            "target": "s_658"
        },
        {
            "source": "r_213",
            "target": "s_42"
        },
        {
            "source": "r_213",
            "target": "s_149"
        },
        {
            "source": "r_213",
            "target": "s_411"
        },
        {
            "source": "r_214",
            "target": "s_449"
        },
        {
            "source": "r_214",
            "target": "s_141"
        },
        {
            "source": "r_214",
            "target": "s_162"
        },
        {
            "source": "r_214",
            "target": "s_338"
        },
        {
            "source": "r_215",
            "target": "s_663"
        },
        {
            "source": "r_215",
            "target": "s_145"
        },
        {
            "source": "r_216",
            "target": "s_347"
        },
        {
            "source": "r_216",
            "target": "s_414"
        },
        {
            "source": "r_216",
            "target": "s_445"
        },
        {
            "source": "r_216",
            "target": "s_450"
        },
        {
            "source": "r_216",
            "target": "s_29"
        },
        {
            "source": "r_216",
            "target": "s_143"
        },
        {
            "source": "r_216",
            "target": "s_233"
        },
        {
            "source": "r_217",
            "target": "s_593"
        },
        {
            "source": "r_217",
            "target": "s_6"
        },
        {
            "source": "r_217",
            "target": "s_209"
        },
        {
            "source": "r_217",
            "target": "s_488"
        },
        {
            "source": "r_217",
            "target": "s_319"
        },
        {
            "source": "r_217",
            "target": "s_35"
        },
        {
            "source": "r_218",
            "target": "s_121"
        },
        {
            "source": "r_218",
            "target": "s_237"
        },
        {
            "source": "r_218",
            "target": "s_667"
        },
        {
            "source": "r_218",
            "target": "s_496"
        },
        {
            "source": "r_218",
            "target": "s_357"
        },
        {
            "source": "r_218",
            "target": "s_58"
        },
        {
            "source": "r_218",
            "target": "s_11"
        },
        {
            "source": "r_218",
            "target": "s_185"
        },
        {
            "source": "r_218",
            "target": "s_463"
        },
        {
            "source": "r_218",
            "target": "s_404"
        },
        {
            "source": "r_218",
            "target": "s_526"
        },
        {
            "source": "r_218",
            "target": "s_7"
        },
        {
            "source": "r_218",
            "target": "s_393"
        },
        {
            "source": "r_218",
            "target": "s_294"
        },
        {
            "source": "r_219",
            "target": "s_351"
        },
        {
            "source": "r_219",
            "target": "s_293"
        },
        {
            "source": "r_219",
            "target": "s_116"
        },
        {
            "source": "r_220",
            "target": "s_86"
        },
        {
            "source": "r_220",
            "target": "s_205"
        },
        {
            "source": "r_220",
            "target": "s_395"
        },
        {
            "source": "r_221",
            "target": "s_201"
        },
        {
            "source": "r_221",
            "target": "s_4"
        },
        {
            "source": "r_221",
            "target": "s_120"
        },
        {
            "source": "r_221",
            "target": "s_311"
        },
        {
            "source": "r_222",
            "target": "s_305"
        },
        {
            "source": "r_222",
            "target": "s_249"
        },
        {
            "source": "r_222",
            "target": "s_24"
        },
        {
            "source": "r_222",
            "target": "s_493"
        },
        {
            "source": "r_222",
            "target": "s_116"
        },
        {
            "source": "r_223",
            "target": "s_613"
        },
        {
            "source": "r_223",
            "target": "s_4"
        },
        {
            "source": "r_223",
            "target": "s_311"
        },
        {
            "source": "r_223",
            "target": "s_201"
        },
        {
            "source": "r_223",
            "target": "s_504"
        },
        {
            "source": "r_223",
            "target": "s_204"
        },
        {
            "source": "r_223",
            "target": "s_505"
        },
        {
            "source": "r_223",
            "target": "s_120"
        },
        {
            "source": "r_224",
            "target": "s_46"
        },
        {
            "source": "r_224",
            "target": "s_2"
        },
        {
            "source": "r_224",
            "target": "s_468"
        },
        {
            "source": "r_224",
            "target": "s_183"
        },
        {
            "source": "r_225",
            "target": "s_368"
        },
        {
            "source": "r_225",
            "target": "s_255"
        },
        {
            "source": "r_226",
            "target": "s_457"
        },
        {
            "source": "r_226",
            "target": "s_250"
        },
        {
            "source": "r_226",
            "target": "s_604"
        },
        {
            "source": "r_226",
            "target": "s_668"
        },
        {
            "source": "r_226",
            "target": "s_183"
        },
        {
            "source": "r_227",
            "target": "s_172"
        },
        {
            "source": "r_227",
            "target": "s_134"
        },
        {
            "source": "r_228",
            "target": "s_549"
        },
        {
            "source": "r_228",
            "target": "s_189"
        },
        {
            "source": "r_229",
            "target": "s_479"
        },
        {
            "source": "r_229",
            "target": "s_240"
        },
        {
            "source": "r_229",
            "target": "s_436"
        },
        {
            "source": "r_229",
            "target": "s_614"
        },
        {
            "source": "r_229",
            "target": "s_277"
        },
        {
            "source": "r_229",
            "target": "s_192"
        },
        {
            "source": "r_230",
            "target": "s_4"
        },
        {
            "source": "r_230",
            "target": "s_60"
        },
        {
            "source": "r_230",
            "target": "s_602"
        },
        {
            "source": "r_230",
            "target": "s_120"
        },
        {
            "source": "r_230",
            "target": "s_311"
        },
        {
            "source": "r_231",
            "target": "s_21"
        },
        {
            "source": "r_231",
            "target": "s_107"
        },
        {
            "source": "r_231",
            "target": "s_145"
        },
        {
            "source": "r_231",
            "target": "s_15"
        },
        {
            "source": "r_231",
            "target": "s_300"
        },
        {
            "source": "r_232",
            "target": "s_235"
        },
        {
            "source": "r_232",
            "target": "s_356"
        },
        {
            "source": "r_232",
            "target": "s_264"
        },
        {
            "source": "r_232",
            "target": "s_392"
        },
        {
            "source": "r_232",
            "target": "s_273"
        },
        {
            "source": "r_233",
            "target": "s_457"
        },
        {
            "source": "r_233",
            "target": "s_138"
        },
        {
            "source": "r_233",
            "target": "s_618"
        },
        {
            "source": "r_233",
            "target": "s_620"
        },
        {
            "source": "r_233",
            "target": "s_244"
        },
        {
            "source": "r_234",
            "target": "s_64"
        },
        {
            "source": "r_234",
            "target": "s_116"
        },
        {
            "source": "r_234",
            "target": "s_189"
        },
        {
            "source": "r_234",
            "target": "s_267"
        },
        {
            "source": "r_234",
            "target": "s_127"
        },
        {
            "source": "r_234",
            "target": "s_328"
        },
        {
            "source": "r_235",
            "target": "s_268"
        },
        {
            "source": "r_235",
            "target": "s_253"
        },
        {
            "source": "r_235",
            "target": "s_448"
        },
        {
            "source": "r_235",
            "target": "s_338"
        },
        {
            "source": "r_235",
            "target": "s_141"
        },
        {
            "source": "r_236",
            "target": "s_99"
        },
        {
            "source": "r_236",
            "target": "s_513"
        },
        {
            "source": "r_236",
            "target": "s_646"
        },
        {
            "source": "r_236",
            "target": "s_601"
        },
        {
            "source": "r_236",
            "target": "s_332"
        },
        {
            "source": "r_236",
            "target": "s_365"
        },
        {
            "source": "r_237",
            "target": "s_464"
        },
        {
            "source": "r_237",
            "target": "s_176"
        },
        {
            "source": "r_237",
            "target": "s_13"
        },
        {
            "source": "r_238",
            "target": "s_370"
        },
        {
            "source": "r_238",
            "target": "s_116"
        },
        {
            "source": "r_239",
            "target": "s_575"
        },
        {
            "source": "r_239",
            "target": "s_641"
        },
        {
            "source": "r_240",
            "target": "s_449"
        },
        {
            "source": "r_240",
            "target": "s_408"
        },
        {
            "source": "r_240",
            "target": "s_338"
        },
        {
            "source": "r_241",
            "target": "s_402"
        },
        {
            "source": "r_241",
            "target": "s_395"
        },
        {
            "source": "r_241",
            "target": "s_474"
        },
        {
            "source": "r_241",
            "target": "s_626"
        },
        {
            "source": "r_242",
            "target": "s_489"
        },
        {
            "source": "r_242",
            "target": "s_577"
        },
        {
            "source": "r_242",
            "target": "s_453"
        },
        {
            "source": "r_243",
            "target": "s_84"
        },
        {
            "source": "r_243",
            "target": "s_562"
        },
        {
            "source": "r_243",
            "target": "s_443"
        },
        {
            "source": "r_244",
            "target": "s_180"
        },
        {
            "source": "r_244",
            "target": "s_558"
        },
        {
            "source": "r_245",
            "target": "s_502"
        },
        {
            "source": "r_245",
            "target": "s_135"
        },
        {
            "source": "r_245",
            "target": "s_162"
        },
        {
            "source": "r_246",
            "target": "s_605"
        },
        {
            "source": "r_246",
            "target": "s_303"
        },
        {
            "source": "r_247",
            "target": "s_194"
        },
        {
            "source": "r_247",
            "target": "s_382"
        },
        {
            "source": "r_247",
            "target": "s_396"
        },
        {
            "source": "r_247",
            "target": "s_584"
        },
        {
            "source": "r_247",
            "target": "s_87"
        },
        {
            "source": "r_247",
            "target": "s_295"
        },
        {
            "source": "r_247",
            "target": "s_451"
        },
        {
            "source": "r_247",
            "target": "s_365"
        },
        {
            "source": "r_248",
            "target": "s_265"
        },
        {
            "source": "r_248",
            "target": "s_27"
        },
        {
            "source": "r_248",
            "target": "s_323"
        },
        {
            "source": "r_248",
            "target": "s_232"
        },
        {
            "source": "r_248",
            "target": "s_344"
        },
        {
            "source": "r_249",
            "target": "s_656"
        },
        {
            "source": "r_249",
            "target": "s_162"
        },
        {
            "source": "r_250",
            "target": "s_303"
        },
        {
            "source": "r_250",
            "target": "s_605"
        },
        {
            "source": "r_250",
            "target": "s_333"
        },
        {
            "source": "r_251",
            "target": "s_90"
        },
        {
            "source": "r_251",
            "target": "s_641"
        },
        {
            "source": "r_251",
            "target": "s_211"
        },
        {
            "source": "r_251",
            "target": "s_277"
        },
        {
            "source": "r_252",
            "target": "s_362"
        },
        {
            "source": "r_252",
            "target": "s_494"
        },
        {
            "source": "r_252",
            "target": "s_363"
        },
        {
            "source": "r_253",
            "target": "s_111"
        },
        {
            "source": "r_253",
            "target": "s_427"
        },
        {
            "source": "r_254",
            "target": "s_108"
        },
        {
            "source": "r_254",
            "target": "s_136"
        },
        {
            "source": "r_254",
            "target": "s_434"
        },
        {
            "source": "r_255",
            "target": "s_333"
        },
        {
            "source": "r_255",
            "target": "s_303"
        },
        {
            "source": "r_256",
            "target": "s_373"
        },
        {
            "source": "r_256",
            "target": "s_300"
        },
        {
            "source": "r_256",
            "target": "s_22"
        },
        {
            "source": "r_257",
            "target": "s_78"
        },
        {
            "source": "r_257",
            "target": "s_136"
        },
        {
            "source": "r_257",
            "target": "s_434"
        },
        {
            "source": "r_258",
            "target": "s_287"
        },
        {
            "source": "r_258",
            "target": "s_216"
        },
        {
            "source": "r_258",
            "target": "s_132"
        },
        {
            "source": "r_258",
            "target": "s_44"
        },
        {
            "source": "r_258",
            "target": "s_40"
        }
    ]
}